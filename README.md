# Daily AI Papers

These summaries are automatically generated from [HuggingFace's Daily Papers](https://huggingface.co/papers), using Gemini and GitHub actions based on the following categories of interest: Multimodal, Text Generation, Text Classification, Text2Text Generation, Summarization, Question Answering, Natural Language Processing, Audio, Text-to-Speech, Audio-to-Audio. All credits go to the research community for sharing and the HuggingFace community for curating these papers.

Please note:
- Authors may be listed by their HuggingFace user id. This will be rectified soon. 
- These summaries are entirely generated by the LLM. You can refer to the basic prompt [here](templates/prompt_template.md).

Last updated: 2024-09-27 
 


## Papers for 2024-09-27

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [MaskLLM: Learnable Semi-Structured Sparsity for Large Language Models](https://arxiv.org/abs/2409.17481) | wxcTest, gheinrich, srvm, yinhongxu, Vinnnf |  - This research introduces MaskLLM, a novel learnable pruning method that generates semi-structured (N:M) sparsity in Large Language Models (LLMs) for enhanced inference efficiency. - MaskLLM distinguishes itself from previous methods by directly learning the distribution of N:M sparsity patterns using Gumbel Softmax sampling, enabling end-to-end training on large datasets and addressing limitations of hand-crafted importance criteria. -  Empirical evaluations on various LLMs, including LLaMA-2, Nemotron-4, and GPT-3, demonstrate that MaskLLM surpasses state-of-the-art techniques, achieving a perplexity of 6.72 on LLaMA2-7B compared to SparseGPT's 10.42. - The research underscores the efficacy of learning sparsity patterns directly from data, leading to more accurate and efficient compression of LLMs without compromising performance. - The adaptability of MaskLLM to downstream tasks and its ability to achieve lossless compression in certain scenarios highlight its potential for practical applications. | ['Natural Language Processing', 'Text Generation'] | [Link](https://github.com/NVlabs/MaskLLM) | N/A |
| [LLaVA-3D: A Simple yet Effective Pathway to Empowering LMMs with 3D-awareness](https://arxiv.org/abs/2409.18125) | Wenwei Zhang, XihuiLiu, Jiangmiao, taiwang, ChaimZhu | This research proposes LLaVA-3D, a novel framework for building 3D-aware Large Multimodal Models (LMMs) by adapting the existing 2D LLaVA model.  LLaVA-3D introduces the concept of "3D Patches," which inject 3D positional embeddings into 2D image features, enhancing the model's spatial understanding without complex 3D processing pipelines.  Evaluations demonstrate LLaVA-3D's state-of-the-art performance on various 3D tasks, including question answering, dense captioning, and visual grounding, surpassing existing 3D LMMs while maintaining comparable 2D image understanding capabilities to its 2D counterpart. The research highlights the advantages of leveraging pre-trained 2D LMMs for 3D scene understanding and the benefits of integrating 3D spatial information into 2D visual features. | ['Multimodal', 'Image-Text-to-Text', 'Visual Question Answering', 'Image-to-Text', 'Text-to-3D'] | N/A | N/A |
| [EMOVA: Empowering Language Models to See, Hear and Speak with Vivid Emotions](https://arxiv.org/abs/2409.18042) | vikyzeng2, 17day, zhili-liu, gyhdog, KaiChen1998 | This paper introduces EMOVA, a novel end-to-end multimodal large language model capable of perceiving and generating images, text, and speech with emotional expressiveness. EMOVA utilizes a continuous vision encoder for detailed visual understanding and a semantic-acoustic disentangled speech tokenizer/detokenizer for end-to-end speech processing.  The model achieves state-of-the-art performance on both vision-language and speech benchmarks, outperforming models like GPT-4V and Gemini Pro 1.5 on 10 out of 14 vision-language tasks and surpassing the speech LLM Mini-Omni in ASR tasks. EMOVA also enables emotional spoken dialogue by explicitly predicting speech style labels (emotions and pitches) and leveraging a lightweight style module for controllable speech synthesis. This is achieved through a novel text-centric multimodal alignment approach, which leverages publicly available bimodal data and eliminates the reliance on scarce trimodal data. | ['Multimodal', 'Text-to-Speech', 'Automatic Speech Recognition', 'Image-to-Text', 'Visual Question Answering'] | N/A | N/A |
| [Discovering the Gems in Early Layers: Accelerating Long-Context LLMs with 1000x Input Token Reduction](https://arxiv.org/abs/2409.17422) | Shafiq Joty, Yingyu Liang, Xuan-Phi Nguyen, Zhenmei Shi, alvinming | This research paper introduces GemFilter, a novel approach to reduce the computational cost and latency of processing long context inputs with Large Language Models (LLMs). GemFilter leverages the ability of early LLM layers to identify relevant tokens and compresses the input sequence by a factor of 1000x for subsequent processing by the full model. Empirical evaluations show that GemFilter achieves a 2.4x speedup and 30% reduction in GPU memory consumption compared to state-of-the-art methods, while maintaining comparable performance on benchmarks like LongBench and outperforming them on the Needle in a Haystack task. GemFilter is simple, training-free, applicable to various LLMs, and offers enhanced interpretability by directly inspecting the selected input sequence. | ['Natural Language Processing', 'Text Generation'] | [Link](https://github.com/SalesforceAIResearch/GemFilter) | N/A |
| [Instruction Following without Instruction Tuning](https://arxiv.org/abs/2409.14254) | Christopher D. Manning, Percy Liang, Nelson F. Liu, John Hewitt |  - This research paper investigates implicit instruction tuning, demonstrating that instruction following can emerge without explicit instruction-response training.  - The authors show that training solely on responses (response tuning) and on narrow-domain data (single-task finetuning) leads to broad instruction-following abilities in language models.  - For instance, response-tuned models achieve a 43% win rate against explicitly instruction-tuned models in head-to-head evaluations.  - Furthermore, they introduce a simple rule-based language model that, when combined with a pretrained model, exhibits instruction-following behavior.  - These findings highlight that adaptation methods not explicitly designed for instruction following can implicitly induce such capabilities. | ['Natural Language Processing', 'Text Generation'] | N/A | N/A |
| [Reducing the Footprint of Multi-Vector Retrieval with Minimal Performance Impact via Token Pooling](https://arxiv.org/abs/2409.14683) | Griffin Adams, Benjamin Clavié, NohTow | This research paper introduces a novel technique named "TOKEN POOLING" for enhancing the efficiency of multi-vector retrieval models, especially focusing on ColBERT, without significantly affecting performance.  The method uses clustering techniques to group together similar token representations and then applies mean pooling to create a single, representative vector, effectively reducing the overall storage footprint. Experiments show that this approach reduces the required vector count by 50% without compromising accuracy, and a 66% reduction still yields strong performance. The paper also demonstrates that TOKEN POOLING can be effectively combined with existing quantization methods, leading to even more significant compression rates while maintaining reasonable retrieval performance.  | ['Natural Language Processing', 'Question Answering'] | N/A | N/A |
| [The Imperative of Conversation Analysis in the Era of LLMs: A Survey of Tasks, Techniques, and Trends](https://arxiv.org/abs/2409.14195) | Longze Chen, Minzheng Wang, Yongbin Li, Haiyang Yu, Xinghua Zhang |  - This paper presents a comprehensive review of the emerging field of Conversation Analysis (CA), a process designed to extract critical information from conversational data and leverage it for system optimization and decision-making.  - The paper systematically defines CA as a four-step procedure: Scene Reconstruction, Causality Analysis, Skill Enhancement, and Conversation Generation, and discusses the challenges and trends within each step. - The paper further argues that while previous CA efforts focused on atomic tasks with limited business impact, the rise of Large Language Models (LLMs) enables deeper, more insightful analysis and strategic decision-making from conversations.  - The authors compile and categorize existing benchmark datasets for CA but highlight a significant gap in comprehensive benchmarks containing fine-grained conversation elements and long-context modeling capabilities.  - The paper concludes by outlining future research directions, including the development of LLM-based conversation simulators, fine-grained CA benchmarks, long-context conversation modeling, in-depth attribution analysis, and advanced goal-directed optimization and evaluation methods. | ['Natural Language Processing', 'Text2Text Generation', 'Question Answering'] | N/A | N/A |
| [Enhancing Structured-Data Retrieval with GraphRAG: Soccer Data Case Study](https://arxiv.org/abs/2409.17580) | Pål Halvorsen, Michael A. Riegler, Cise Midoglu, Sushant Gautam, Zahra Sepasdar | This paper introduces Structured-GraphRAG, a novel framework designed to enhance data retrieval from structured datasets by leveraging Knowledge Graphs (KGs) and graph-based architectures. The authors demonstrate the effectiveness of their framework by applying it to the SoccerNet dataset, a large dataset of soccer videos. Their findings show that Structured-GraphRAG significantly improves query processing efficiency, reduces response times, and enhances accuracy compared to traditional RAG methods. The structured nature of KGs reduces hallucinations in LLMs, making the responses more consistent and reliable. The authors highlight that their framework can be applied to a broad range of applications due to its flexible design. | ['Question Answering', 'Graph Machine Learning'] | N/A | N/A |


