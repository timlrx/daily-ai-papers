

## Papers for 2024-10-02

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [Law of the Weakest Link: Cross Capabilities of Large Language Models](https://arxiv.org/abs/2409.19951) | xwhan, ruihou16, xwwang, astonzhang, MingZhong |  - This research paper explores the intersection of multiple abilities, termed "cross capabilities," in Large Language Models (LLMs), which are essential for real-world tasks but often overlooked in current evaluations that focus on individual capabilities. - It introduces CROSSEVAL, a benchmark with 1,400 human-annotated prompts and 8,400 human ratings, designed to evaluate both individual and cross capabilities, revealing that current LLMs underperform in cross-capability tasks. - The study finds that LLM cross-capability performance adheres to the "Law of the Weakest Link," being significantly limited by the weakest individual capability, regardless of improvements in other areas. - The results highlight that tool use is a major challenge for LLMs and suggest that prioritizing the enhancement of weaker capabilities is more crucial for improving overall performance than focusing on already strong ones. -  The work emphasizes the importance of shifting focus towards cross-capability evaluation and development to improve LLM effectiveness in complex, real-world scenarios rather than just on individual capabilities. | ['Natural Language Processing', 'Question Answering'] | [Link](https://github.com/facebookresearch/llm-cross-capabilities) | N/A |
| [TPI-LLM: Serving 70B-scale LLMs Efficiently on Low-resource Edge Devices](https://arxiv.org/abs/2410.00531) | Hongfang Yu, Mohsen Guizani, Jiaoshen, LIKirin | TPI-LLM is a tensor parallel inference system designed for serving 70B-scale LLMs efficiently on low-resource edge devices. - It addresses memory limitations by introducing a sliding window memory scheduler that dynamically manages layer weights during inference, overlapping disk I/O with computation and communication. - TPI-LLM prioritizes tensor parallelism over pipeline parallelism for single-user scenarios on edge devices and implements a star-based allreduce algorithm to minimize link latency. - Experimental results show significant reductions in time-to-first-token, token latency, and peak memory footprint compared to benchmarks like Transformers, Accelerate, and Galaxy. - TPI-LLM successfully runs Llama 2-70B with a peak memory footprint of 3.1GB across 8 low-resource devices, enabling larger models to run on edge devices while preserving user privacy. | ['Natural Language Processing', 'Text Generation'] | [Link](https://github.com/Lizonghang/TPI-LLM) | N/A |
| [Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect](https://arxiv.org/abs/2409.17912) | imomayiz, amr-mohamed, khoubrane-yousef, habdine, guokan-shang | Atlas-Chat introduces the first Large Language Models (LLMs) for Moroccan Arabic, a low-resource dialectal Arabic (DA) variant also known as Darija. - A new instruction dataset, Darija-SFT-Mixture, was created by combining existing and new manually and synthetically created Darija resources, as well as translated English instructions. - Atlas-Chat-9B and 2B models, fine-tuned on this dataset, outperform existing LLMs, including Arabic-specific and state-of-the-art models like LLaMa, Jais, and AceGPT, achieving a 13% improvement over a 13B model on a new Darija benchmark. - A new evaluation suite, including DarijaMMLU, DarijaHellaSwag, and DarijaBench, was developed for comprehensive LLM assessment in Darija, focusing on discriminative and generative tasks.  - An experimental analysis was conducted on fine-tuning strategies and base model choices, finding that instruction-tuned Gemma 2 models with LoRA performed optimally. | ['Natural Language Processing', 'Translation', 'Summarization'] | N/A | [Link](https://hf.co/MBZUAI-Paris/Atlas-Chat-9B), [Link](https://hf.co/datasets/MBZUAI-Paris/Darija-SFT-Mixture) |
| [ACE: All-round Creator and Editor Following Instructions via Diffusion Transformer](https://arxiv.org/abs/2410.00086) | Jingren, chenweix7, chaojiemao, jingfengzhang, jiangzeyinzi |  - ACE, a unified framework based on a Diffusion Transformer, supports a wide range of visual generation and editing tasks through natural language instructions, including text-guided generation, low-level visual analysis, controllable generation, semantic editing, element editing, repainting, layer editing, and reference generation. - ACE introduces the Long-context Condition Unit (LCU) to incorporate historical information from previous generation rounds, enabling multi-turn and long-context generation. - A meticulous data collection workflow is established to construct a 0.7 billion-scale dataset covering various generation and editing tasks. - Evaluation on benchmarks such as MagicBrush and a user study on a manually curated benchmark demonstrates ACEâ€™s superior performance in various visual generation tasks. - ACE can be easily integrated into a multimodal chat system to streamline image creation and editing, avoiding cumbersome pipelines typically employed in visual agents. | ['Text-to-Image', 'Image-to-Image', 'Multimodal'] | N/A | [Link](https://huggingface.co/runwayml/stable-diffusion-v1-5), [Link](https://huggingface.co/runwayml/stable-diffusion-inpainting) |
| [Visual Context Window Extension: A New Perspective for Long Video Understanding](https://arxiv.org/abs/2409.20018) | Zhenzhong Chen, hcwei | This research paper proposes a novel approach to enhance long video understanding by extending the visual context window of Large Multimodal Models (LMMs). - It redefines the context window in LMMs as two distinct windows: visual and language, addressing the discrepancies between these modalities. - The study introduces a method to extend positional embeddings within the visual context window, enabling LMMs to handle lengthy videos without retraining on large video-text datasets. - A progressive pooling strategy is implemented to reduce memory consumption by selectively adjusting the spatial resolution of frame embeddings. - Experimental results on benchmarks like MLVU, VideoMME, and LongVideoBench demonstrate consistent performance improvements with increasing video frames, outperforming models like GPT-40 and achieving memory savings of approximately 45%. | ['Multimodal', 'Video-Text-to-Text'] | N/A | N/A |
