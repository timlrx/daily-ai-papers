

## Papers for 2024-10-08

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [Differential Transformer](https://arxiv.org/abs/2410.05258) | Li Dong, thegenerality, sunyt32, yuqxia, ytz20 | • This paper introduces the Differential Transformer (DIFF Transformer), a novel architecture for large language models (LLMs) designed to improve attention to relevant context and mitigate noise. • The core innovation is the differential attention mechanism, which calculates attention scores as the difference between two separate softmax attention maps, thus canceling noise and promoting sparse attention patterns. • Experimental results on language modeling demonstrate that DIFF Transformer outperforms standard Transformer models in various scaling settings, requiring only about 65% of the model size or training tokens to achieve comparable performance. • The model also exhibits advantages in downstream tasks such as long-context modeling, key information retrieval, hallucination mitigation, and in-context learning. • Additionally, DIFF Transformer demonstrates increased robustness to order permutation in in-context learning and a reduction in activation outliers, which presents opportunities for model quantization. | ['Natural Language Processing', 'Question Answering', 'Summarization'] | N/A | N/A |
| [LLMs Know More Than They Show: On the Intrinsic Representation of LLM Hallucinations](https://arxiv.org/abs/2410.02707) | Roi Reichart, Zorik Gekhman, belinkov, tokeron, hadasor |   - This paper investigates the internal representations of large language models (LLMs) and their connection to the phenomenon of hallucinations. - The research finds that truthfulness information is highly localized within exact answer tokens, leading to improved error detection when probing these specific tokens. - The study demonstrates that while error detection is enhanced by focusing on these tokens, probing classifiers trained on one dataset often fail to generalize effectively to others, indicating that truthfulness mechanisms are skill-specific. - The authors further categorize LLM errors based on repeated sampling, showing that error types are predictable from internal representations. - Finally, they highlight a discrepancy between LLM internal encoding and external behavior, revealing that models may internally identify the correct answer but consistently generate an incorrect one, suggesting the potential for harnessing this existing knowledge to reduce errors. | ['Natural Language Processing', 'Question Answering'] | [Link](https://github.com/technion-cs-nlp/LLMsKnow) | N/A |
| [FAN: Fourier Analysis Networks](https://arxiv.org/abs/2410.02675) | Yongding Tao, Ge Li, Jingjingxu, zkcpku, dongyh | - This paper introduces the Fourier Analysis Network (FAN), a novel neural network architecture designed to effectively model and reason about periodic phenomena by incorporating Fourier Series into its structure and computational process. - FAN aims to address the limitations of existing neural networks, such as MLPs and Transformers, which often struggle to generalize periodic functions beyond the training data domain. - The architecture consists of stacking FAN layers where each layer outputs a concatenation of cosine, sine transformations, and an activation function applied to a linear transformation of the input. - Experimental results demonstrate FAN's superior performance compared to MLP, KAN, and Transformer on various tasks, including symbolic formula representation, time series forecasting, and language modeling tasks. - By seamlessly replacing MLP layers with FAN layers, models achieve improved generalization while reducing parameters and FLOPs. | ['Time Series Forecasting', 'Natural Language Processing'] | [Link](https://github.com/YihongDong/FAN) | N/A |
| [Presto! Distilling Steps and Layers for Accelerating Music Generation](https://arxiv.org/abs/2410.05167) | Jonah Casebeer, Ge Zhu, Njb, tberg12, ZacharyNovack |  - Presto! is a new dual-faceted distillation approach for accelerating score-based diffusion transformers by reducing sampling steps and the cost per step. - Presto includes score-based distribution-matching distillation for continuous-time diffusion (EDM) using a GAN, improved conditional layer distillation with better-preserved hidden-state variance, and combined layer-step distillation. - For step distillation, Presto-S achieves best-in-class performance among step distillation techniques and matches the original model quality with 4-step inference. - When combined with the novel layer distillation Presto-L, which independently outperforms SOTA layer dropping and base diffusion sampling, the resulting Presto-LS approach accelerates the model by 10-18x, generating 32-second mono audio in 230ms and stereo audio in 435ms on an A100 40GB GPU, outperforming Stable Audio Open by 15x. | ['Audio', 'Text-to-Audio'] | [Link](https://presto-music.github.io/web/) | N/A |
| [Named Clinical Entity Recognition Benchmark](https://arxiv.org/abs/2410.05046) | Clément Christophe, Tathagata Raha, Muhammad Umar Salman, Marco AF Pimentel, Wadood M Abdul | - This paper introduces a Named Clinical Entity Recognition (NER) benchmark designed for evaluating language models in healthcare. - This benchmark encompasses a curated selection of publicly accessible medical datasets with standardized entities adhering to the Observational Medical Outcomes Partnership (OMOP) Common Data Model. - The leaderboard accommodates various language model architectures, including encoder, decoder, and GLiNER models, and employs standardized evaluation metrics, predominantly the F1-score, to ensure consistent performance comparisons. - Initial findings from the leaderboard indicate superior performance by GLiNER-based models over decoder-only architectures, commonly used in Large Language Models (LLMs). - The choice of evaluation strategy, token-based or span-based, has been found to influence model ranking. | ['Natural Language Processing', 'Token Classification'] | [Link](https://github.com/WadoodAbdul/clinical_ner_benchmark) | [Link](https://huggingface.co/m42-health/clinical_ner_leaderboard), [Link](https://huggingface.co/spaces/m42-health/clinical_ner_leaderboard) |
| [TLDR: Token-Level Detective Reward Model for Large Vision Language Models](https://arxiv.org/abs/2410.04734) | Rui Wang, Tong Xiao, tbpangolin, pzzhang, deqing |  - This paper introduces TLDR, a novel token-level reward model designed to improve the performance and interpretability of large vision-language models (VLMs). - The TLDR model assigns rewards to individual tokens rather than entire sequences, enabling finer-grained feedback and more precise identification of errors, like hallucinations. - A perturbation-based method is used to generate synthetic hard negatives for training TLDR, enhancing its robustness. - Experiments demonstrate that TLDR significantly improves VLM performance in various tasks and reduces human annotation time by approximately threefold. - The study shows that the proposed model speeds up human annotation by 3 times in acquiring high-quality vision-language data. | ['Multimodal', 'Image-Text-to-Text', 'Reinforcement Learning'] | N/A | N/A |
| [UniMuMo: Unified Text, Music and Motion Generation](https://arxiv.org/abs/2410.04534) | Yutong Zhang, Kun Su, Han Yang, auspicious3000, Jiaben |   - UniMuMo is a unified multimodal model that uses a transformer-based encoder-decoder architecture to generate music, motion, and text from any combination of the three modalities as input. - The model bridges the modalities through a unified encoder-decoder architecture after converting inputs to a token-based representation and addresses the lack of time-synchronized data by aligning unpaired music and motion data based on rhythmic patterns and using existing large-scale datasets of single modalities.  - It utilizes a music codebook to encode motion and introduces a music-motion parallel generation scheme. - This design unifies all music and motion generation tasks into a single transformer decoder architecture with one training task of music-motion joint generation and can be efficiently achieved by fine-tuning existing pre-trained single-modality models. - Extensive evaluations shows that UniMuMo achieves competitive results across all unidirectional generation benchmarks including text-to-music, music-to-motion, motion-to-music, music captioning and motion captioning. | ['Multimodal', 'Text-to-Audio', 'Text-to-Video', 'Audio-to-Audio', 'Audio-to-Audio', 'Video-Text-to-Text'] | [Link](https://hanyangclarence.github.io/unimumo_demo/) | N/A |
| [LLaMA-Berry: Pairwise Optimization for O1-like Olympiad-Level Mathematical Reasoning](https://arxiv.org/abs/2410.02884) | Tong Che, Jingdi Lei, schrodingers-tiger, jwu323, qq8933 | LLaMA-Berry is a new framework for enhancing the mathematical reasoning ability of Large Language Models (LLMs) by combining Monte Carlo Tree Search (MCTS) with iterative Self-Refine and a pairwise reward model. - The framework uses Self-Refine applied to MCTS (SR-MCTS) to optimize the reasoning path by leveraging the self-critic and rewriting capabilities of LLMs. - A Pairwise Preference Reward Model (PPRM), inspired by Reinforcement Learning from Human Feedback (RLHF), is used to evaluate different reasoning paths globally. - An Enhanced Borda Count (EBC) method synthesizes pairwise preferences between solutions into a global ranking score to identify better answers. - Experimental results on benchmarks like GSM8K, MATH, AIME24, AMC23, and GPQA Diamond demonstrate that LLaMA-Berry significantly improves the performance of LLaMA-3.1-8B, achieving results competitive with GPT-4 Turbo without additional training. | ['Natural Language Processing', 'Question Answering'] | N/A | N/A |
| [MathHay: An Automated Benchmark for Long-Context Mathematical Reasoning in LLMs](https://arxiv.org/abs/2410.04698) | cxiong, lunshi, hendrydong, yuhuixu, demolei | **- MATHHAY: An automated benchmark designed to assess the long-context mathematical reasoning capabilities of LLMs.** **- Unlike previous benchmarks, MATHHAY requires both information retrieval and complex mathematical reasoning, focusing on real-world scenarios within a specified time period.** **- Includes questions of varying difficulty levels across different input lengths (32K, 64K, 128K) and utilizes a combination of rule-based exact matching and LLM-based judgment for evaluation.** **- Experimental results reveal that even top-performing LLMs like Gemini struggle with long contexts in mathematical reasoning, indicating room for improvement.** **- Open-source models significantly underperform compared to closed-source models.** | ['Question Answering'] | N/A | N/A |
| [TurtleBench: Evaluating Top Language Models via Real-World Yes/No Puzzles](https://arxiv.org/abs/2410.05262) | siminniu, fan2goa1, WinfredShi, Ki-Seki, Duguce |  - TurtleBench is a new benchmark for evaluating the reasoning abilities of Large Language Models (LLMs) using real user guesses from an online Turtle Soup Puzzle game. - This dynamic approach creates a bilingual dataset (Chinese and English) with 1532 annotated user guesses, which are then used to test the reasoning abilities of the LLMs.  - The benchmark emphasizes reasoning ability and minimizes reliance on memorization and background knowledge.  - Nine advanced LLMs, including open and closed-source models, were tested on TurtleBench.  - The results show that Claude-3.5-Sonnet and GPT-4 performed best but that OpenAI's o1 series models performed sub-optimally. | ['Natural Language Processing', 'Question Answering'] | [Link](https://github.com/mazzzystar/TurtleBench) | N/A |
| [Grounding Language in Multi-Perspective Referential Communication](https://arxiv.org/abs/2410.03959) | alsuhr, mao1207, ZinengTang | This paper introduces a new task and dataset for evaluating referring expression generation and comprehension in multi-agent embodied environments. The dataset, comprising 2,970 human-written referring expressions, requires agents to consider each other's perspective when generating and understanding references to objects.  The authors find that model performance lags behind that of human agents in both generation and comprehension tasks.  A speaker model fine-tuned using communicative success significantly improves performance, surpassing even a strong proprietary model (GPT-40). The contributions include a novel platform for generating 3D scenes, a new dataset, and analysis of language strategies in embodied referential communication. | ['Multimodal'] | [Link](https://github.com/zinengtang/MulAgentRef) | N/A |
