

## Papers for 2024-10-17

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [HumanEval-V: Evaluating Visual Understanding and Reasoning Abilities of Large Multimodal Models Through Coding Tasks](https://arxiv.org/abs/2410.12381) | Xiao Li, Guancheng Lin, Huiyu Bai, Linquan Wu, zfj1998 | - HumanEval-V is introduced; a novel benchmark designed to evaluate the visual understanding and reasoning abilities of Large Multimodal Models (LMMs) through Python code generation tasks.  - The benchmark comprises 108 coding tasks adapted from platforms like CodeForces and Stack Overflow, each requiring LMMs to integrate visual and textual information to generate functional code.  - Evaluation results for 19 state-of-the-art LMMs reveal that even leading proprietary models struggle, with GPT-4o achieving 13% pass@1, highlighting limitations in visual reasoning and coding abilities.  -  Ablation studies indicate current LMMs have limitations in vision reasoning and coding capabilities, showing significant performance improvement when image descriptions are provided. - Further analysis reveals that open-weight LMMs suffer deteriorated coding performance after vision-encoder integration, suggesting areas for future LMM research. | ['Multimodal', 'Computer Vision', 'Natural Language Processing', 'Text2Text Generation'] | [Link](https://github.com/HumanEval-V/HumanEval-V-Benchmark) | N/A |
| [VidEgoThink: Assessing Egocentric Video Understanding Capabilities for Embodied AI](https://arxiv.org/abs/2410.11623) | Sicheng Zhou, Yangyang Yu, Kechen Fang, yetian, SijieCheng |  - VidEgoThink is introduced; a benchmark designed to assess egocentric video understanding capabilities for embodied AI, focusing on bridging the gap between Multimodal Large Language Models (MLLMs) and low-level control. - It incorporates four tasks: video question answering, hierarchical planning, visual grounding, and reward modeling.  - Leverages GPT-4 to generate data automatically, which is filtered by human annotators.  This pipeline is based on the Ego4D dataset. - Experimental evaluation of various MLLMs, including GPT-4, open-source image and video-based models, reveals poor performance across all tasks, particularly in sequence and order understanding.  - Findings indicate a need for significant advancements in foundational models for first-person Embodied AI applications. | ['Visual Question Answering', 'Multimodal', 'Video-Text-to-Text', 'Robotics'] | N/A | N/A |
| [The Curse of Multi-Modalities: Evaluating Hallucinations of Large Multimodal Models across Language, Visual, and Audio](https://arxiv.org/abs/2410.12787) | Hang Zhang, Yang Zhou, Yun Xing, Sicong Leng, ClownRat | - This paper investigates hallucinations in Large Multimodal Models (LMMs) across language, visual, and audio modalities. - Two key contributors to hallucinations are identified: overreliance on unimodal priors and spurious inter-modality correlations. - The Curse of Multi-Modalities (CMM) benchmark is introduced, which provides a detailed analysis of these underlying issues. - CMM converts hallucination evaluation into a binary classification task with object-level and event-level probing across 1200 samples with 2400 probing questions. - Experimental results reveal key vulnerabilities, including imbalances in modality integration and biases from training data. | ['Multimodal'] | [Link](github.com/DAMO-NLP-SG/CMM) | [Link](cmm-damovl.site) |
| [Revealing the Barriers of Language Agents in Planning](https://arxiv.org/abs/2410.12409) | Kai Zhang, Siyu Yuan, jiangjiechen, kexunz, hsaest |  - This paper investigates the limitations of current large language models (LLMs) in planning tasks using feature attribution analysis.  - It identifies two key weaknesses: a limited understanding of constraints and the diminishing influence of questions as the planning horizon expands. - The study explores episodic and parametric memory updating strategies, finding that while they improve constraint and question utilization, they do not fully resolve the core issues. - The episodic memory updating reiterates constraints, making them easier for agents to recognize, but agents primarily understand it on a global level. -  Parametric memory updating enhances the impact of questions, yet agents still lose focus on them as the horizon increases; both strategies resemble shortcut learning and are insufficient for high-level planning. | ['Natural Language Processing', 'Question Answering'] | N/A | N/A |
| [Exploring Model Kinship for Merging Large Language Models](https://arxiv.org/abs/2410.12613) | Huajun Chen, Shumin Deng, Ningyu Zhang, Yunzhi Yao, Yedi Hu |  - This paper introduces "model kinship", a metric to assess the similarity between Large Language Models (LLMs), drawing an analogy to biological kinship, for enhanced model merging. - It is shown empirically that model kinship correlates with performance gains after merging, which helps guide the selection of candidate models for merging and escape local optima. - A novel merging strategy, "Top-k Greedy Merging with Model Kinship", is proposed, demonstrating improved performance on benchmark datasets by mitigating performance degradation and avoiding local optima during model evolution. - The analysis of model evolution through iterative merging reveals two distinct stages: a learning stage with rapid performance improvement and a saturation stage where improvements plateau, with the latter attributed to weight space convergence and high kinship values. - Model kinship is further suggested as a criterion for early stopping in the merging process, which improves efficiency without compromising performance gains.  | ['Natural Language Processing'] | [Link](https://github.com/zjunlp/ModelKinship) | N/A |
| [Large Language Model Evaluation via Matrix Nuclear-Norm](https://arxiv.org/abs/2410.10672) | Yi Chang, Yahan Li, WhiteCatY, xiatingyu | • This paper introduces Matrix Nuclear-Norm, a novel metric for evaluating the information compression and redundancy reduction capabilities of Large Language Models (LLMs). • The metric leverages the nuclear norm and its L1,2-norm approximation to quantify the data compression proficiency of LLMs. • Matrix Nuclear-Norm addresses the computational limitations of existing metrics like Matrix Entropy by reducing the time complexity from O(n³) to O(n²), eliminating the need for Singular Value Decomposition (SVD). • Experimental results on various LLMs, including Cerebras-GPT and Pythia, demonstrate that Matrix Nuclear-Norm effectively captures compression capabilities with values decreasing as model size increases. • Evaluations on benchmark datasets like AlpacaEval and Chatbot Arena confirm that the proposed metric reliably assesses and ranks model performance, achieving a balance between accuracy and computational efficiency. | ['Natural Language Processing'] | [Link](https://github.com/MLGroupJLU/MatrixNuclearNorm) | N/A |
| [ProSA: Assessing and Understanding the Prompt Sensitivity of LLMs](https://arxiv.org/abs/2410.12405) | Dahua Lin, Xinyu Fang, KennyUTC, zsytony, JingmingZ | • ProSA, a framework designed to evaluate and understand prompt sensitivity in LLMs, is introduced, incorporating a novel sensitivity metric, PromptSensiScore (PSS), and leveraging decoding confidence. • PSS quantifies the average discrepancy in LLM responses when given different semantic variants of the same instruction. • The study, spanning multiple tasks and models, reveals that prompt sensitivity varies across datasets and models, with larger models generally exhibiting better robustness, and few-shot examples, especially for larger models, mitigate sensitivity. • Subjective evaluations highlight increased sensitivity in complex reasoning tasks compared to straightforward ones, with higher model confidence correlating with increased prompt robustness. • Prompt sensitivity is linked to decoding confidence, where greater confidence corresponds to higher robustness against prompt variations. | ['Natural Language Processing', 'Question Answering'] | [Link](https://github.com/open-compass/ProSA) | N/A |
| [ZipVL: Efficient Large Vision-Language Models with Dynamic Token Sparsification and KV Cache Compression](https://arxiv.org/abs/2410.08584) | Wenqi Shao, Jing Liu, Feng Chen, Yefei He, kpzhang996 | - ZipVL is an efficient inference framework for Large Vision-Language Models (LVLMs) that addresses computational and memory bottlenecks through dynamic token sparsification and KV cache compression. - It employs a layer-wise adaptive ratio assignment for important tokens based on attention score distribution, optimizing both prefill and decoding phases. - The prefill phase is accelerated by performing attention only on important tokens, seamlessly integrating with existing attention implementations. - Mixed-precision quantization is applied to the KV cache, using higher bit-width for important tokens and lower bit-width for others, reducing memory usage without significant performance loss. - Experiments show ZipVL accelerates prefill by 2.6x and reduces GPU memory by 50% with minimal accuracy reduction on Video-MME, outperforming fixed-ratio methods like FastV. | ['Multimodal', 'Visual Question Answering', 'Image-to-Text', 'Video-Text-to-Text'] | N/A | N/A |
| [Insights from the Inverse: Reconstructing LLM Training Goals Through Inverse RL](https://arxiv.org/abs/2410.12491) | Sonali Parbhoo, Arjun Jagota, Jared Joselowitz, skrishna | • This paper introduces a novel approach to interpreting Large Language Models (LLMs) by applying Inverse Reinforcement Learning (IRL) to recover their implicit reward functions, focusing on toxicity-aligned LLMs. • Experiments conducted on toxicity-aligned LLMs of varying sizes extracted reward models that achieved up to 80.40% accuracy in predicting human preferences. • The analysis reveals insights into the non-identifiability of reward functions, the relationship between model size and interpretability, and potential pitfalls in the Reinforcement Learning from Human Feedback (RLHF) process. • The study demonstrates that IRL-derived reward models can be used to fine-tune new LLMs, resulting in comparable or improved performance on toxicity benchmarks. • The paper proposes that this work provides a new perspective for understanding and improving LLM alignment, with implications for responsible development. | ['Natural Language Processing', 'Reinforcement Learning'] | N/A | N/A |
| [WorldMedQA-V: a multilingual, multimodal medical examination dataset for multimodal language models evaluation](https://arxiv.org/abs/2410.12722) | Juan Carlos Climent Pardo, Yingya Li, Siena Placino, João Matos, shanchen |  - WorldMedQA-V is a new multilingual and multimodal dataset designed to evaluate the performance of multimodal language models (VLMs) on medical question answering tasks. - The dataset consists of 568 multiple-choice questions with images from real medical exams in Brazil, Israel, Japan, and Spain. - Evaluations of several popular open and closed-source VLMs reveal that GPT4o achieved the best performance, generally exceeding passing thresholds across countries and both local languages and English translations. - Including the associated image with the medical question generally improves the model performance, particularly for models with lower baseline accuracies. - The results also highlight persistent language disparities, where models showed relatively lower performance on Hebrew, potentially due to underrepresentation in pre-training datasets. | ['Multimodal', 'Visual Question Answering', 'Question Answering'] | [Link](https://github.com/WorldMedQA/V) | [Link](https://huggingface.co/datasets/WorldMedQA/V) |
| [OMCAT: Omni Context Aware Transformer](https://arxiv.org/abs/2410.12109) | Andrew Tao, Rafael Valle, Matthieu Le, Karan Sapra, goarushi27 |  - The paper introduces OMCAT (Omni Context Aware Transformer), a novel multimodal large language model designed for enhanced temporal understanding and cross-modal alignment in audio-visual contexts.  - OMCAT leverages ROTE (Rotary Time Embeddings), a modification of RoPE (Rotary Position Embeddings), to encode absolute and relative temporal information, improving performance on time-anchored tasks. -  A new dataset, OCTAV (Omni Context and Temporal Audio Video), is also introduced, focusing on event transitions within videos and their correlation with audio cues, facilitating training for fine-grained temporal reasoning.  -  OMCAT undergoes a three-stage training process: feature alignment, instruction tuning, and OCTAV-specific training, achieving state-of-the-art results on Audio-Visual Question Answering (AVQA) and temporal video grounding benchmarks, surpassing existing models on the OCTAV dataset by a significant margin.  - The paper's contributions include a new model and dataset, demonstrating significant advancements in multimodal LLMs' capacity for fine-grained temporal and cross-modal understanding. | ['Multimodal', 'Visual Question Answering'] | N/A | N/A |
| [Tracking Universal Features Through Fine-Tuning and Model Merging](https://arxiv.org/abs/2410.12391) | Desmond Elliott, nilq |  - This paper investigates the evolution of features in one-layer Transformer language models during fine-tuning and merging. - The study uses sparse autoencoders to extract and track features across models trained on different domains (English text, Python, Lua, TinyStories). - Findings reveal that few features persist across models, but those that do are often interpretable, relating to code-related elements like punctuation and formatting. - Case studies highlight a persistent variable assignment feature and a disappearing Python exception-handling feature. - The paper contributes to understanding feature dynamics in transfer learning scenarios. | ['Natural Language Processing', 'Feature Extraction'] | N/A | N/A |
| [DyVo: Dynamic Vocabularies for Learned Sparse Retrieval with Entities](https://arxiv.org/abs/2410.07722) | Jeff Dalton, Iain Mackie, Sean MacAvaney, Shubham Chatterjee, Thong Nguyen | - DyVo, a novel dynamic vocabulary model, is introduced to enhance Learned Sparse Retrieval (LSR) by incorporating Wikipedia entities into the vocabulary. - The model utilizes a Dynamic Vocabulary (DyVo) head which leverages existing entity embeddings and an entity retrieval component to generate entity weights. - These weights are merged with word piece weights and used for efficient indexing and retrieval using an inverted index. - Experiments on three entity-rich document ranking datasets show DyVo consistently outperforms state-of-the-art baselines, demonstrating significant improvements over traditional LSR models by incorporating entities. - A few-shot generative entity retrieval approach using LLMs like Mixtral and GPT-4 is introduced, generating highly relevant entity candidates leading to superior performance compared to using linked entities or entities found by human annotators. | ['Natural Language Processing', 'Question Answering'] | [Link](https://github.com/thongnt99/DyVo) | N/A |
