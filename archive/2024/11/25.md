

## Papers for 2024-11-25

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [TÜLU 3: Pushing Frontiers in Open Language Model Post-Training](https://arxiv.org/abs/2411.15124) | Hamish Ivison, Shengyi Huang, Valentina Pyatkin, Jacob Morrison, Nathan Lambert | - TÜLU 3 is a family of open-source, state-of-the-art language models fine-tuned from Llama 3.1 using a novel four-stage post-training recipe. - The recipe includes supervised fine-tuning, preference tuning using Direct Preference Optimization, and a novel Reinforcement Learning with Verifiable Rewards (RLVR) stage. - RLVR trains models against ground truth rewards for specific skills with verifiable answers (e.g., math, precise instruction following).  - TÜLU 3 models outperform existing open-weight models and some closed models, like GPT 3.5 Turbo and GPT 40 mini, in terms of average performance across benchmarks. - The release includes model weights, training code, evaluation suite, and datasets related to various core skills. | ['Natural Language Processing', 'Text Generation', 'Text2Text Generation', 'Question Answering', 'Reinforcement Learning'] | [Link](https://github.com/allenai/open-instruct), [Link](https://github.com/allenai/olmes) | [Link](https://hf.co/allenai/Llama-3.1-Tulu-3-70B), [Link](https://hf.co/allenai/Llama-3.1-Tulu-3-8B), [Link](https://hf.co/collections/allenai/tulu-3-datasets-673b8df14442393f7213f372) |
| [A Flexible Large Language Models Guardrail Development Methodology Applied to Off-Topic Prompt Detection](https://arxiv.org/abs/2411.12946) | Shaun Khoo, shingurding, gabrielchua | - This paper introduces a flexible, data-free methodology for developing guardrails for Large Language Models (LLMs) to prevent off-topic misuse. - The methodology involves using an LLM to generate a synthetic dataset of on-topic and off-topic prompts based on a qualitative problem analysis, then fine-tuning embedding (jina-embeddings-v2-small-en) or cross-encoder (stsb-roberta-base) models on this data to create off-topic classifiers. - The resulting guardrails outperform baseline methods, including cosine similarity, KNN, and zero-shot classification using LLMs, demonstrating higher precision in identifying off-topic prompts. - By framing the detection task as assessing relevance between system and user prompts, the guardrail effectively generalizes to other misuse categories such as jailbreak and harmful prompts. - The synthetic dataset and trained models are open-sourced to facilitate research and development in LLM safety. | ['Natural Language Processing', 'Text Classification'] | N/A | [Link](https://huggingface.co/datasets/gabrielchua/off-topic), [Link](https://huggingface.co/collections/govtech/off-topic-guardrail-673838a62e4c661f248e81a4) |
| [Large Multi-modal Models Can Interpret Features in Large Multi-modal Models](https://arxiv.org/abs/2411.14982) | Ziwei Liu, Bo Li, Yifei Shen, Kaichen Zhang | - This paper introduces a framework to interpret the internal representations of Large Multimodal Models (LMMs), focusing on understanding their open-semantic features. - It employs Sparse Autoencoders (SAE) to disentangle complex representations into simpler, human-understandable features. - An automatic interpretation pipeline leverages larger LMMs to provide zero-shot explanations of these features, offering insights into model behavior. - The framework demonstrates the ability to steer LMM behavior by manipulating specific features, enabling targeted interventions and analysis of model decisions. - The authors analyze LLaVA-NeXT-8B using LLaVA-OV-72B and demonstrate effective feature interpretation and behavior steering, contributing to a deeper understanding of LMMs' strengths and weaknesses. | ['Multimodal', 'Image Feature Extraction'] | N/A | N/A |
| [VideoEspresso: A Large-Scale Chain-of-Thought Dataset for Fine-Grained Video Reasoning via Core Frame Selection](https://arxiv.org/abs/2411.14794) | Xiu Su, Le Zhuo, Hairong Shi, Wei Huang, Songhao Han | - VideoEspresso, a large-scale video question-answering (VideoQA) dataset, is introduced, focusing on fine-grained video reasoning and featuring VideoQA pairs that retain spatial and temporal context. - An automatic pipeline is used to construct the dataset, employing semantic key-frame extraction and GPT-40 for generating QA pairs and enriching them with Chain-of-Thought annotations. - A Hybrid LVLMs Collaboration framework is proposed, incorporating a Frame Selector and a two-stage reasoning LVLM to address cost-effectiveness and accuracy in video reasoning. - Evaluation on a 14-task benchmark against popular LVLMs shows superior performance, highlighting improved video reasoning capabilities compared to baseline methods. - Both objective and subjective evaluations, incorporating metrics such as logic, factuality, accuracy, and conciseness, showcase the dataset and model efficacy. | ['Visual Question Answering', 'Multimodal'] | [Link](https://github.com/hshjerry/VideoEspresso) | N/A |
| [One to rule them all: natural language to bind communication, perception and action](https://arxiv.org/abs/2411.15033) | Giuseppe Boccignone, Dimitri Ognibene, colo286 | - This research presents a novel architecture for robot action planning which integrates Large Language Models (LLMs), perception, and action planning using a modified ReAct framework. - The core component, the Planner Module, translates natural language commands into executable actions and uses LLMs in a modified ReAct framework to dynamically adjust plans based on real-time feedback and environmental perception.  - The system leverages scene graphs for semantic mapping and context understanding while utilizing an execution control mechanism and a failure management system to enable robust error handling.  - Preliminary testing on RoBee, a humanoid robot, in a simulated kitchen and bedroom environment demonstrates the efficacy of the architecture. - It is able to handle simple, and moderately complex requests with good success rates, with future work directed to improve performance on complex, and open-ended requests and refining real-world integration. | ['Robotics', 'Natural Language Processing'] | N/A | N/A |
