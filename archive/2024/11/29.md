

## Papers for 2024-11-29

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [Critic-V: VLM Critics Help Catch VLM Errors in Multimodal Reasoning](https://arxiv.org/abs/2411.18203) | Jingdi Lei, jwu323, ZonglinY, Duke-de-Artois, qq8933 | - This paper introduces Critic-V, a novel framework designed to enhance the reasoning capabilities of Vision-Language Models (VLMs) by incorporating a critic model that provides feedback during the reasoning process. - Critic-V features a Reasoner-Critic architecture where the Reasoner generates reasoning paths, and the Critic offers natural language critiques for refinement, inspired by the Actor-Critic paradigm and leveraging in-context reinforcement learning. - The Critic model is trained using Direct Preference Optimization (DPO) on a new dataset with critiques ranked by a Rule-based Reward (RBR) function to enhance its critic capabilities.  - Evaluation results show that Critic-V significantly improves the performance of existing VLMs, like Qwen2-VL-7B and DeepSeek-VL-7B, on 5 out of 8 benchmarks, surpassing even GPT-4V on several datasets and particularly improving mathematical reasoning tasks. - Critic-V integrates a dynamic text-based policy for the Reasoner and uses constructive feedback from the preference-optimized Critic to create a reliable and context-sensitive multimodal reasoning process. | ['Multimodal', 'Visual Question Answering'] | N/A | N/A |
| [ChatGen: Automatic Text-to-Image Generation From FreeStyle Chatting](https://arxiv.org/abs/2411.17176) | Hangwei Qian, Weijia Wu, Zhuohang Dang, Changliang Xia, ChengyouJia | - This paper introduces ChatGen, a novel framework for automating the text-to-image generation process from freestyle chat inputs. - It proposes a multi-stage evolution strategy (ChatGen-Evo) that equips language models with essential skills for prompt crafting, model selection, and argument configuration. - This approach outperforms baseline methods on a new benchmark dataset, ChatGenBench, which features diverse freestyle chat inputs paired with desired image outputs and generation parameters. - ChatGen-Evo with 2B parameters achieves comparable performance to a larger 8B parameter supervised baseline model. - The multi-stage evolution strategy results in high-quality images aligning with the diverse requirements from freestyle chat instructions. | ['Text-to-Image', 'Multimodal'] | [Link](https://chengyou-jia.github.io/ChatGen-Home) | N/A |
| [Free$^2$Guide: Gradient-Free Path Integral Control for Enhancing Text-to-Video Generation with Large Vision-Language Models](https://arxiv.org/abs/2411.17041) | Jong Chul Ye, Bryan S Kim, kjm981995 | - Free$^2$Guide is a novel gradient-free framework designed to enhance text-video alignment in diffusion-based generative models by leveraging Large Vision-Language Models (LVLMs). - The framework uses path integral control to approximate guidance during video generation, eliminating the need for gradients from reward functions and accommodating non-differentiable reward models like LVLMs. - Free$^2$Guide improves text alignment by processing multiple video frames and incorporates temporal understanding into the reward mechanism, allowing the use of powerful black-box vision-language model APIs. - It allows the ensembling of multiple reward models like LVLMs and image-based models to synergistically guide video generation, enhancing both text alignment and overall video quality. - Experiments demonstrate that using LVLMs in Free$^2$Guide significantly improved text alignment in video generation when compared to baseline models in various metrics, and exhibits improved general video quality across a range of attributes. | ['Text-to-Video', 'Multimodal'] | [Link](https://kjm981995.github.io/free2guide/) | N/A |
| [Morph: A Motion-free Physics Optimization Framework for Human Motion Generation](https://arxiv.org/abs/2411.14951) | Hao Liu, Xin Zhao, Ruibing Hou, Mingshuang Luo, Zhuo Li | - Morph is a novel motion-free physics optimization framework for generating realistic human motion from text or music, comprising a Motion Generator (MG) and a Motion Physics Refinement (MPR) module. - The MG synthesizes motion data, while the MPR, trained on this synthetic data, uses a motion imitator within a physics simulator to refine the generated motion, enforcing physical constraints and aligning its distribution with a discriminator using reinforcement learning. - This physics-refined data then fine-tunes the MG to enhance its realism. - Experiments on HumanML3D and AIST++ datasets show Morph improves physical plausibility metrics (e.g. Penetration, floating) drastically, while achieving competitive generation quality (FID, R-Precision) compared to state-of-the-art methods, across different generator architectures (diffusion, autoregressive, masked modeling). - This framework addresses the challenge of physically implausible artifacts in generated motion by leveraging synthetic data, making it a cost-effective and versatile solution. | ['Text-to-Video', 'Text-to-3D', 'Multimodal'] | N/A | N/A |
| [LongKey: Keyphrase Extraction for Long Documents](https://arxiv.org/abs/2411.17863) | Jean Paul Barddal, Cinthia Obladen de Almendra Freitas, Jeovane Honorio Alves, RaduState | - LongKey, a novel framework for keyphrase extraction from lengthy documents, leverages an encoder-based language model, specifically Longformer, to capture extended text intricacies, supporting up to 96K tokens. - It employs a max-pooling embedder to consolidate context across the document, refining keyphrase candidate representation. - Validated on LDKP datasets and six diverse unseen datasets, LongKey consistently outperforms existing unsupervised and language model-based methods, achieving an F1@5 of 39.55% on LDKP3K and 41.81% on LDKP10K. - A component analysis confirmed the significant contribution of the keyphrase embedding pooler in enhancing performance. - While robust on long documents, LongKey's performance on short-context datasets suggests further development for broader applicability. | ['Natural Language Processing', 'Feature Extraction'] | [Link](https://github.com/jeohalves/longkey) | N/A |
