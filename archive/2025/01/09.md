

## Papers for 2025-01-09

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking](https://arxiv.org/abs/2501.04519) | Youran Sun, Yifei Liu, Xinyu Guan, J-shang, lynazhang | - rStar-Math is a novel framework that allows smaller language models to achieve state-of-the-art mathematical reasoning capabilities comparable to OpenAI's models. - It employs Monte Carlo Tree Search (MCTS) with a math policy SLM and a process reward model (PRM), and introduces innovations in data synthesis, reward modeling, and self-evolution. - A code-augmented chain-of-thought data synthesis method generates verifiable reasoning steps, and a process preference model (PPM) is trained using a pairwise ranking loss, eliminating the need for precise step-level reward annotation. - The system iteratively evolves the policy SLM and PPM to improve reasoning capabilities without relying on distillation from larger models. - Evaluations on various benchmarks show significant performance boosts, rivaling or exceeding OpenAI ol on competition-level problems, even with smaller model sizes. | ['Question Answering', 'Natural Language Processing'] | [Link](https://github.com/microsoft/rStar) | N/A |
| [URSA: Understanding and Verifying Chain-of-thought Reasoning in Multimodal Mathematics](https://arxiv.org/abs/2501.04686) | Xinzhe Ni, Yiyao Yu, Yifan Wang, fun6668, AntimageTHU | - This paper introduces URSA-7B, a multimodal large language model (MLLM) designed for enhanced mathematical reasoning, using a three-module synthesis strategy integrating chain-of-thought (CoT) distillation, trajectory format rewriting, and format unification for training data creation. - The model architecture comprises a hybrid vision encoder (SAM-B and SigLIP-L) combined with Qwen2.5-Math-7B-Instruct and trained with an MLP projector aligner between the vision and language models. - URSA-7B achieves state-of-the-art performance on several multimodal mathematical reasoning benchmarks, including MathVista, MathVerse, and DYNAMATH, outperforming other open-source models and some closed-source models. - For test-time scaling, a dual-view process supervision data synthesis strategy is proposed, generating the DualMath-1.1M dataset and URSA-RM-7B, a verifier model that improves URSA-7B's reasoning path selection and accuracy. - URSA-RM-7B shows strong out-of-distribution (OOD) verification capabilities, particularly on the Multimath-7B CoT solutions, indicating improved robustness and generalisation in multimodal mathematical reasoning | ['Multimodal', 'Question Answering'] | N/A | N/A |
| [Towards System 2 Reasoning in LLMs: Learning How to Think With Meta Chain-of-Though](https://arxiv.org/abs/2501.04682) | Kanishk Gandhi, Charlie Snell, Violet Xiang, nlile, Asap7772 | - This paper proposes Meta Chain-of-Thought (Meta-CoT), a framework extending traditional Chain-of-Thought (CoT) by explicitly modeling the underlying reasoning process. - Meta-CoT models the latent "thinking" process involved in complex reasoning, addressing the limitations of traditional CoT in capturing non-linear, iterative, and latent exploration and verification. - Empirical evidence from state-of-the-art models like OpenAI's "o1" and DeepSeek-R1 shows behaviors consistent with internalized search, supporting the Meta-CoT hypothesis. - The authors outline a training pipeline for Meta-CoT, incorporating instruction tuning with linearized search traces and reinforcement learning. -  A "Big MATH" project is introduced, aiming to create a dataset of over 1,000,000 verifiable math problems to facilitate research in this area. | ['Natural Language Processing', 'Question Answering', 'Reinforcement Learning'] | N/A | N/A |
| [LLM4SR: A Survey on Large Language Models for Scientific Research](https://arxiv.org/abs/2501.04306) | Xinya Du, Wei Yang, Ziming Luo, Ason-jay, ZonglinY | - This survey paper explores the transformative role of Large Language Models (LLMs) in the scientific research process, covering hypothesis discovery, experiment planning and implementation, scientific writing, and peer reviewing. - The paper analyzes how LLMs contribute to each stage, summarizing methodologies, benchmarks, and evaluation methods, and identifying current challenges and future research directions. - It provides a comprehensive overview of LLM applications across the entire scientific workflow, unlike previous surveys that focused on specific LLM capabilities or individual research stages. - The survey identifies key components and trends in each application area, such as feedback modules in hypothesis discovery, agent-based automation in experiment implementation, and multi-model architectures in peer review generation. - The authors conclude that while LLMs face limitations in areas like planning, prompt robustness, and domain-specific expertise, their ongoing development holds immense potential to revolutionize scientific research by enhancing productivity, fostering innovation, and promoting collaboration. | ['Natural Language Processing'] | [Link](https://github.com/du-nlp-lab/LLM4SR) | N/A |
| [GeAR: Generation Augmented Retrieval](https://arxiv.org/abs/2501.02772) | Hao Sun, Yuefeng Zhan, Jianfeng Liu, Shaohan Huang, noobimp | - This paper introduces Generation Augmented Retrieval (GeAR), a novel retrieval method that incorporates fusion and decoding modules to generate relevant text from documents based on the fused representation of the query and the document, enhancing fine-grained information retrieval. - GeAR consists of a bi-encoder for initial encoding of queries and documents, a fusion encoder utilizing cross-attention to combine query and document embeddings, and a text decoder to generate relevant information from the fused representation. - The model is trained using contrastive learning loss for retrieval and language modeling loss for generation, enabling joint optimization of retrieval and fine-grained understanding. - Experimental results demonstrate competitive performance in document retrieval and units localization tasks across various datasets, showing improvements over traditional retrieval methods, especially in capturing fine-grained semantic relationships. - GeAR also exhibits promising information generation capabilities and offers insights into the interpretation of retrieval results through visualization of information localization and cross-attention weights. | ['Question Answering', 'Natural Language Processing'] | N/A | N/A |
| [InfiGUIAgent: A Multimodal Generalist GUI Agent with Native Reasoning and Reflection](https://arxiv.org/abs/2501.04575) | Xueyu Hu, Congkai Xie, Zishu Wei, Yuhang Liu, pengxiang | - InfiGUIAgent, a Multimodal Large Language Model (MLLM)-based Graphical User Interface (GUI) agent, is introduced for enhanced task automation on computing devices. - The agent employs a two-stage supervised fine-tuning approach where the first stage focuses on fundamental GUI understanding, grounding, and visual-language comprehension, while the second stage integrates advanced reasoning skills, including hierarchical and expectation-reflection reasoning, using synthesized trajectory data. - InfiGUIAgent leverages a modular action space design enabling flexible action combinations and utilizes reference-augmented annotation for precise spatial referencing in GUI interactions. - Experimental results on ScreenSpot and AndroidWorld benchmarks demonstrate InfiGUIAgent's superior performance compared to several open-source baselines. - The model achieves a 76.3% accuracy on ScreenSpot, surpassing models like ShowUI and UGround-7B, and a 0.09 overall success rate on AndroidWorld, outperforming similar-sized models and some with larger parameter sizes, showcasing its effective GUI task automation capabilities without relying on additional GUI metadata. | ['Multimodal'] | [Link](https://github.com/Reallm-Labs/InfiGUIAgent) | N/A |
| [DPO Kernels: A Semantically-Aware, Kernel-Enhanced, and Divergence-Rich Paradigm for Direct Preference Optimization](https://arxiv.org/abs/2501.03271) | Rajarshi Roy, Danush Khanna, Suranjana Trivedy, Amitava Das, amanchadha | - This paper introduces DPO-Kernels, a framework enhancing Direct Preference Optimization (DPO) for aligning large language models (LLMs) with human preferences by integrating kernel methods and diverse divergence measures. - DPO-Kernels incorporates kernelized representations, divergence alternatives (Jensen-Shannon, Hellinger, RÃ©nyi, Bhattacharyya, Wasserstein, and f-divergences), and data-driven selection of optimal kernel-divergence pairs. - It introduces a Hierarchical Mixture of Kernels (HMK) to combine local and global kernels for precise and large-scale semantic modeling, automatically selecting the optimal kernel mixture during training. - Evaluations on 12 datasets demonstrate state-of-the-art generalization across various alignment tasks, including factuality, safety, reasoning, and instruction following. - Despite increased computational cost (3-4x higher than standard DPO), the improvements in alignment and generalization justify the overhead, with future work aiming to address scalability challenges. | ['Natural Language Processing', 'Text Generation'] | N/A | [Link](https://huggingface.co/datasets/Anthropic/hh-rlhf), [Link](https://huggingface.co/datasets/nvidia/HelpSteer), [Link](https://huggingface.co/datasets/lmsys/chatbot_arena_conversations), [Link](https://huggingface.co/datasets/lmsys/lmsys-arena-human-preference-55k), [Link](https://huggingface.co/datasets/tatsu-lab/alpaca_farm/viewer/alpaca_human_preference), [Link](https://huggingface.co/datasets/stanfordnlp/SHP-2), [Link](https://huggingface.co/datasets/HuggingFaceH4/ultrafeedback_binarized), [Link](https://huggingface.co/datasets/argilla/distilabel-intel-orca-dpo-pairs) |
