

## Papers for 2025-01-17

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [OmniThink: Expanding Knowledge Boundaries in Machine Writing through Thinking](https://arxiv.org/abs/2501.09751) | Ningyu, Runnaning, callanwu, JizhanFang, ZekunXi | - OmniThink, a novel machine writing framework, enhances knowledge density in generated long-form articles by emulating human-like iterative expansion and reflection. - It simulates the cognitive process of learners progressively deepening their knowledge, iteratively adjusting retrieval strategies for thorough information exploration. - This framework incorporates expansion and reflection, outline structuring, and article composition stages, utilizing search engines and LLMs to generate nuanced, original content. - Evaluation on WildSeek dataset with GPT-40 and Qwen-Plus demonstrates improved knowledge density and overall quality compared to baselines like RAG, ORAG, STORM, and Co-STORM. - Human evaluations confirm enhanced breadth and depth, though automated and human novelty assessments diverge, suggesting areas for future evaluation refinement. | ['Natural Language Processing', 'Text Generation', 'Summarization'] | N/A | N/A |
| [Exploring the Inquiry-Diagnosis Relationship with Advanced Patient Simulators](https://arxiv.org/abs/2501.09484) | Quan Tu, hsaest, ShizhengLi, sdujq, zhaocheng | - This paper introduces a novel patient simulator trained on synthetic doctor-patient dialogue data generated using real patient dialogue strategies and medical records. - The simulator aims to address the limitations of prompt engineering in accurately representing patient behavior in online medical consultations (OMCs). - Experiments demonstrate that the simulator exhibits a lower hallucination rate and improved anthropomorphism compared to baselines, although the irrelevant response rate is slightly higher. - The study investigates the relationship between inquiry and diagnosis in OMCs and finds that they adhere to Liebig's law: poor inquiry limits effective diagnosis, and vice-versa. - By categorizing inquiries into four types, the research analyzes inquiry differences among models and reveals the importance of effective inquiry allocation within limited consultation rounds. | ['Natural Language Processing', 'Question Answering', 'Text Generation', 'Text2Text Generation'] | [Link](https://github.com/LIO-H-ZEN/PatientSimulator) | N/A |
| [FAST: Efficient Action Tokenization for Vision-Language-Action Models](https://arxiv.org/abs/2501.09747) | oier-mees, dannydriess, brianichter, kylestach, KarlP | - This paper introduces FAST (Frequency-space Action Sequence Tokenization), a novel compression-based tokenization scheme for robot actions, utilizing Discrete Cosine Transform (DCT) and Byte Pair Encoding (BPE) to improve the training of Vision-Language-Action (VLA) models, especially with high-frequency data. - It addresses the limitations of per-dimension binning, which struggles with high-frequency, correlated action sequences by compressing redundant data into fewer, high-information tokens. - Based on FAST, they introduce FAST+, a universal pre-trained tokenizer effective across different robot morphologies, action spaces, and control frequencies, offering a strong default for robot action tokenization. - Combining FAST with the π0 VLA model, they demonstrate performance comparable to state-of-the-art diffusion-based VLAs on long-horizon, dexterous manipulation tasks while achieving up to 5x faster training speeds. - The π0-FAST model trained with the proposed tokenization also successfully learns a generalist manipulation policy that generalizes to unseen environments in a zero-shot setting based on natural language prompts, the first of its kind on the DROID dataset. | ['Robotics', 'Multimodal'] | N/A | [Link](https://huggingface.co/physical-intelligence/fast) |
| [Towards Large Reasoning Models: A Survey of Reinforced Reasoning with Large Language Models](https://arxiv.org/abs/2501.09686) | Ouyangtj, zhazhahui7, berserkerko, zzfoutofspace, haohao11 | - This paper surveys recent advancements in Large Language Model (LLM) reasoning, focusing on reinforced learning methods and prompting techniques. - The survey explores how "thought" sequences, representing intermediate reasoning steps, enhance LLM's reasoning abilities, moving beyond simple token generation. - It reviews techniques like Chain-of-Thought prompting, Tree-of-Thoughts, and reinforcement learning methods using Process Reward Models (PRMs) for training and test-time scaling. - The paper analyzes OpenAI's o1 series and open-source projects like OpenR, LLaMA-Berry, and Journey Learning, showcasing their approaches to achieving strong reasoning capabilities. - Finally, it discusses open challenges and future research directions, including refining test-time scaling, developing more advanced reasoning models, and exploring potential applications in diverse domains. | ['Natural Language Processing', 'Question Answering'] | N/A | N/A |
