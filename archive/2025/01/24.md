

## Papers for 2025-01-24

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [Improving Video Generation with Human Feedback](https://arxiv.org/abs/2501.13918) | Ziyang Yuan, Jiajun Liang, Gongye Liu, Xintao, jieliu | - This paper introduces a new framework for aligning text-to-video (T2V) generation models with human preferences using reinforcement learning from human feedback (RLHF). - A new 182k-example multi-dimensional human preference dataset focused on modern video generation models is constructed, along with VideoReward, a multi-dimensional video reward model. - Three new alignment algorithms for flow-based video generation models are derived: Flow-DPO, Flow-RWR (training-time algorithms), and Flow-NRG (inference-time algorithm).  - Flow-DPO outperforms standard supervised fine-tuning and Flow-RWR on automatic and human preference evaluations when the KL-divergence parameter \(\beta\) is fixed.  - Flow-NRG enables personalized video generation by allowing users to adjust weights for multiple alignment objectives during inference. | ['Text-to-Video', 'Reinforcement Learning', 'Multimodal'] | [Link](https://gongyeliu.github.io/videoalign) | N/A |
| [Sigma: Differential Rescaling of Query, Key and Value for Efficient Language Models](https://arxiv.org/abs/2501.13629) | hanglics, yegong, lx865712528, tzh94588, Lin0 | - SIGMA, a new large language model specializing in the system domain, is introduced, featuring DiffQKV attention for enhanced inference efficiency. - DiffQKV differentially optimizes Query, Key, and Value components: using compressed K and V and augmented Q, balancing performance and efficiency. - SIGMA is pre-trained on 6 trillion tokens, including 19.5 billion system domain data and 1 trillion synthesized/rewritten data. - In general domains, SIGMA's performance is comparable to state-of-the-art models. - On AIMICIUS, a new system domain benchmark, SIGMA significantly outperforms existing models, including GPT-4, with up to a 52.5% absolute improvement. | ['Natural Language Processing', 'Text Generation'] | N/A | N/A |
| [Temporal Preference Optimization for Long-Form Video Understanding](https://arxiv.org/abs/2501.13919) | Zeyu Wang, yeunglevy, yuhuizhang, nicholswang, ruili0 | - This paper introduces Temporal Preference Optimization (TPO), a novel post-training framework designed to enhance the temporal grounding capabilities of video Large MultiModal Models (LMMs). - TPO leverages preference learning at two granularities: localized temporal grounding, focusing on specific video segments, and comprehensive temporal grounding, addressing broader temporal dependencies. - By curating preference data at these two levels, TPO trains video-LMMs to differentiate between temporally grounded and ungrounded responses, improving their ability to capture nuanced temporal relationships in videos. - Experiments on LongVideoBench, MLVU, and Video-MME benchmarks demonstrate significant performance improvements with TPO across two state-of-the-art video-LMMs (LongVA-7B and LLaVA-Video-7B). - Notably, LLaVA-Video with TPO achieves state-of-the-art results on Video-MME among 7B models, highlighting the effectiveness of TPO in enhancing long-form video understanding. | ['Video-Text-to-Text', 'Multimodal'] | N/A | N/A |
| [IMAGINE-E: Image Generation Intelligence Evaluation of State-of-the-art Text-to-Image Models](https://arxiv.org/abs/2501.13920) | lzyhha, JackyZhuo, RuoyiDu, Afeng-x, jyjyjyjy | - IMAGINE-E, a comprehensive evaluation framework, is introduced to benchmark text-to-image (T2I) models across five key domains. - Six prominent models, including FLUX.1 and Ideogram2.0, were evaluated on tasks related to structured output generation, realism and physical consistency, specific domain generation, challenging scenarios, and multi-style creation. - FLUX.1 and Ideogram2.0 show superior performance, especially in structured and specific domain tasks. - The evaluation reveals that existing evaluation frameworks need to be improved to better assess these advanced models and that T2I models show progress towards becoming foundational AI tools. - The evaluation also highlights ongoing limitations in complex areas like 3D and code generation. | ['Text-to-Image', 'Multimodal'] | [Link](https://github.com/jylei16/Imagine-e) | N/A |
| [Step-KTO: Optimizing Mathematical Reasoning through Stepwise Binary Feedback](https://arxiv.org/abs/2501.10799) | spermwhale, yunhe, sainbar, jindi, yentinglin | - This paper introduces Step-KTO (Stepwise Kahneman-Tversky-inspired Optimization), a novel training framework designed to enhance the mathematical reasoning capabilities of Large Language Models (LLMs). - Step-KTO integrates both process-level and outcome-level binary feedback signals to guide LLMs in generating not only correct final answers but also logically sound intermediate reasoning steps. - By incorporating a Kahneman-Tversky-inspired value function, Step-KTO prioritizes correctness and coherence in the reasoning process. - Experimental results on benchmark mathematical reasoning datasets demonstrate that Step-KTO surpasses existing state-of-the-art methods, achieving a notable improvement in accuracy (e.g., 63.2% Pass@1 on MATH-500 vs. 53.4% for the baseline model) alongside producing more reliable intermediate solutions. | ['Natural Language Processing', 'Question Answering'] | N/A | N/A |
| [Debate Helps Weak-to-Strong Generalization](https://arxiv.org/abs/2501.13124) | Yongbin-Li, hzhwcmhf, langnick | - This paper proposes a novel approach to improve weak-to-strong generalization in natural language processing by leveraging debate between two large language models (LLMs). - The debate mechanism extracts trustworthy information from the LLMs, which is then used to train a better weak supervisor. - An ensemble of weak models is employed to process the long arguments generated during the debate, leading to more robust supervision estimates. - The proposed combination of scalable oversight and weak-to-strong generalization approaches results in improved alignment on OpenAI's weak-to-strong NLP benchmarks. - Experimental results show that the debate-enhanced weak supervision significantly outperforms baseline approaches in terms of performance gap recovered (PGR) and test accuracy on various question-answering datasets, including SciQ, BoolQ, CosmosQA, and AnthropicHH. | ['Natural Language Processing', 'Question Answering'] | N/A | N/A |
| [Evolution and The Knightian Blindspot of Machine Learning](https://arxiv.org/abs/2501.13075) | Tarin Ziyaee, Kenneth O. Stanley, Tarek El-Gaaly, ekmeyerson, jal278 | - This paper argues that machine learning (ML), and reinforcement learning (RL) in particular, overlooks the critical aspect of robustness to Knightian uncertainty (KU), or unknown unknowns, which is essential for general intelligence in open worlds. - By contrasting RL with biological evolution, the authors highlight how evolution's mechanisms, such as diversification, adaptation to novelty, and persistence as a filter for robustness, enable it to thrive in open-ended, unpredictable environments, unlike current RL agents, which struggle with out-of-distribution scenarios. - The paper identifies specific limitations in RL's core formalisms, including closed-world assumptions in MDPs, fixed time horizons in reward functions, episodic boundaries, and the treatment of training data as timeless, arguing that these limitations contribute to RL's blindness to KU.  - The authors suggest that incorporating principles from evolution, such as open-endedness, artificial life, and revisiting core RL formalisms, might help address KU and lead to more robust AI. - The implications of KU for foundation models, RLHF, AI safety, and potential pathways to integrate KU into RL algorithms are discussed. | ['Reinforcement Learning', 'Natural Language Processing'] | N/A | N/A |
| [Video-MMMU: Evaluating Knowledge Acquisition from Multi-Discipline Professional Videos](https://arxiv.org/abs/2501.13826) | ZhangYuanhan, wangxiao1208, pufanyi, craigwu, KairuiHu | - Introduces Video-MMMU, a benchmark designed to evaluate large multimodal models' (LMMs) ability to acquire and apply knowledge from professional educational videos. - The benchmark includes 300 videos spanning six disciplines, each accompanied by three question-answer pairs aligned with Bloom’s Taxonomy: Perception, Comprehension, and Adaptation. - A new metric, called *Δknowledge*, is proposed to quantify the models' performance improvement on practice exam questions after viewing a video. - Evaluation results of several LMMs revealed a progressive decline in model performance as the cognitive level increases from perception to comprehension to adaptation. - Analysis reveals that even top-performing models like Claude-3.5-Sonnet exhibit significant performance decline in complex scenarios, highlighting the limitations of current models in adapting video-based knowledge to solve real-world problems. | ['Multimodal', 'Question Answering', 'Video-Text-to-Text'] | N/A | N/A |
