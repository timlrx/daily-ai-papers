

## Papers for 2025-02-03

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [s1: Simple test-time scaling](https://arxiv.org/abs/2501.19393) | Xiang Lisa Li, percyliang, swj0419, zitongyang, Muennighoff | - This paper introduces s1-32B, a language model fine-tuned for enhanced reasoning by using test-time scaling. - The model is trained on s1K, a curated dataset of 1,000 reasoning questions and solutions distilled from Google's Gemini. - Budget forcing, a novel technique to control test-time computation, improves the model's reasoning abilities allowing it to extrapolate beyond performance achieved without test-time intervention. - Evaluation on benchmarks such as AIME24, MATH500, and GPQA Diamond shows s1-32B's superior sample efficiency and competitive performance compared to existing models, including OpenAI's o1-preview. - The authors emphasize the importance of dataset curation using criteria like difficulty, diversity, and quality, as well as the effectiveness of budget forcing for test-time scaling. | ['Question Answering', 'Natural Language Processing'] | [Link](https://github.com/simplescaling/s1) | N/A |
| [Reward-Guided Speculative Decoding for Efficient LLM Reasoning](https://arxiv.org/abs/2501.19324) | doyensahoo, JunnanLi, hendrydong, yuhuixu, baohao | - This paper introduces Reward-Guided Speculative Decoding (RSD), a novel framework designed to enhance the efficiency of Large Language Model (LLM) inference, especially in reasoning tasks. - RSD combines a "draft" model with a "target" model and uses a process reward model to evaluate intermediate steps, dynamically deciding when to invoke the target model based on these rewards. - By selectively refining high-reward draft outputs, RSD minimizes computational costs compared to traditional speculative decoding which enforces strict unbiasedness. - Experimental results on reasoning benchmarks demonstrate significant computational savings (up to 4.4x fewer FLOPs) while improving accuracy compared to target-only or parallel decoding methods (up to +3.5 on average). - The paper explores different threshold-based criteria and weighting functions, highlighting the effectiveness of the approach across math and general LLMs for a range of reasoning tasks. | ['Natural Language Processing', 'Question Answering', 'Text Generation'] | N/A | N/A |
| [Self-supervised Quantized Representation for Seamlessly Integrating Knowledge Graphs with Large Language Models](https://arxiv.org/abs/2501.18119) | Fangzhi Xu, Zhen Peng, Kai He, Tianzhe Zhao, Qika | - This paper proposes a two-stage framework called Self-Supervised Quantized Representation (SSQR) to seamlessly integrate Knowledge Graphs (KGs) with Large Language Models (LLMs). - The SSQR method compresses KG structural and semantic knowledge into discrete codes (tokens) through a self-supervised quantization process using a Graph Convolutional Network (GCN) encoder and vector quantization. - In the second stage, KG instruction-following data is created using the learned codes as input features, allowing LLMs to be fine-tuned for KG tasks like link prediction and triple classification. - Experimental results show that SSQR outperforms existing unsupervised quantized methods, and fine-tuned LLMs using SSQR achieve superior performance on KG link prediction and triple classification with fewer tokens per entity. - The learned quantized representations are more distinguishable and allow LLMs to better differentiate between entities in KGs. | ['Graph Machine Learning', 'Question Answering', 'Natural Language Processing'] | N/A | N/A |
| [Constitutional Classifiers: Defending against Universal Jailbreaks across Thousands of Hours of Red Teaming](https://arxiv.org/abs/2501.18837) | Primusa, euanong, sgoodfriend, jayelm, meg-tong | - This paper introduces Constitutional Classifiers, a new method for defending large language models (LLMs) against universal jailbreaks, which are prompting strategies that bypass model safeguards. - The approach involves training classifier safeguards on synthetic data generated using explicit constitutional rules that define permitted and restricted content categories. - This framework also employs data-augmentation techniques and leverages pool sets of benign data. - In over 3,000 estimated hours of red teaming, no red teamer found a universal jailbreak that could extract information from an early classifier-guarded LLM at a similar level of detail to an unguarded model. - On automated evaluations, enhanced classifiers showed strong defense against held-out, domain-specific jailbreaks while maintaining deployment viability with a small increase in production-traffic refusals and moderate inference overhead. | ['Natural Language Processing'] | N/A | N/A |
| [Trading Inference-Time Compute for Adversarial Robustness](https://arxiv.org/abs/2501.18841) | Sam Toyer, Stephanie Lin, Boaz Barak, Evgenia Nitishinskaya, Wojciech Zaremba | - This research investigates the impact of increased inference-time compute on the robustness of large language models (specifically OpenAI's 01-preview and 01-mini) against adversarial attacks. - Across various attacks, increased inference-time compute leads to improved robustness, often reducing the attack success rate to zero as computational resources increase, without explicit adversarial training. - The study introduces new attacks for reasoning models and explores scenarios where more compute does not guarantee reliability, and provides explanations. - The paper demonstrates that scaling inference-time compute, rather than pre-training compute, may be key to enhancing adversarial robustness in LLMs. - The analysis reveals limitations, such as the potential for adversaries to exploit policy ambiguities and introduce attacks like "Think Less" and "nerd sniping," highlighting the need for further research. | ['Natural Language Processing', 'Computer Vision'] | N/A | N/A |
| [INT: Instance-Specific Negative Mining for Task-Generic Promptable Segmentation](https://arxiv.org/abs/2501.18753) | Shaogang Gong, Zixu Cheng, Jian Hu | - INT, a training-free, cycle-generation model, introduces instance-specific negative mining for task-generic promptable image segmentation, enhancing the accuracy of instance-specific prompts derived from generic prompts. - By comparing VLM outputs before and after masking image regions, INT iteratively refines prompts and masks, addressing challenges like camouflaged objects and medical images where traditional methods struggle. - INT outperforms existing point and scribble-supervised methods on datasets like COD10K, CHAMELEON, and CAMO in camouflaged object detection and achieves competitive results on medical image segmentation datasets like CVC-ColonDB, Kvasir, and ISIC using only a task-generic prompt, demonstrating effectiveness, robustness, and scalability. - The model involves splitting the image into patches, generating candidate prompts with a VLM, using an inpainting module to mask potential objects, and selecting the prompt with the highest output difference for segmentation using SAM. - Progressive negative mining refines prompts by accumulating scores from each iteration, normalizing differences for stability and excluding the influence of unstable changes caused by incorrect prompt predictions, improving segmentation accuracy in complex scenes where objects blend into their backgrounds. | ['Image Segmentation', 'Multimodal'] | N/A | N/A |
| [Unraveling the Capabilities of Language Models in News Summarization](https://arxiv.org/abs/2501.18128) | GÃ¶ksel Biricik, odabashi | - This research paper benchmarks 20 different language models (LLMs), both large and small, on their news summarization capabilities using zero-shot and few-shot learning. - The study employs three commonly used news summarization datasets: CNN/Daily Mail, Newsroom, and XSum, and evaluates the models using automatic metrics (ROUGE, METEOR, BERTScore), human evaluation, and LLM-based evaluation. - The results indicate that while larger models like GPT-3.5-Turbo and Gemini generally outperform smaller models, certain smaller models, such as Qwen1.5-7B, SOLAR-10.7B-Instruct-v1.0, Meta-Llama-3-8B, and Zephyr-7B-Beta, show competitive performance. - The paper finds that including demonstration examples in the few-shot learning setting does not necessarily improve performance and can even hinder it due to the sometimes low quality of the gold standard summaries in the datasets used. - The study highlights some common issues encountered with generated summaries, including early termination of text generation, redundancy and repetitive sequence generation, generation of prompts instead of task completions, inappropriate continuations and hallucinations and non-text outputs. | ['Summarization', 'Natural Language Processing'] | N/A | N/A |
