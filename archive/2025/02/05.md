

## Papers for 2025-02-05

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [ACECODER: Acing Coder RL via Automated Test-Case Synthesis](https://arxiv.org/abs/2502.01718) | Xiaotong Chen, Haozhe Wang, Huaye Zeng, pingnieuk, DongfuJiang | - This paper introduces ACECODER, a novel approach to improve code generation models using reinforcement learning (RL) and automated test-case synthesis. - ACECODER synthesizes a large-scale dataset (ACECODE-89K) of coding questions and test cases, enabling effective RL training. - The method utilizes a Bradley-Terry loss function to train reward models based on pass rates of generated programs over the synthesized test cases. - Experiments show that ACECODER consistently improves the performance of various code generation models across multiple benchmarks. Notably, it improves the model's performance on HumanEval-plus by over 25% and MBPP-plus by 6% with only 80 optimization steps. - The authors believe that ACECODER highlights the significant potential of RL in improving code generation models. | ['Reinforcement Learning', 'Text Generation'] | [Link](https://tiger-ai-lab.github.io/AceCoder) | N/A |
| [Can LLMs Maintain Fundamental Abilities under KV Cache Compression?](https://arxiv.org/abs/2502.01941) | Zeyu Li, Peijie Dong, Hong Chen, Zhenheng Tang, Dominic789654 |  - This paper introduces ShotKV, a novel KV cache compression method that distinctly manages prefill and decoding phases to maintain shot-level semantic coherence, improving performance on long-context tasks. - The study reveals that arithmetic reasoning tasks are particularly sensitive to aggressive compression, while multi-step reasoning LLMs exhibit more robust compression tolerance. -  Empirical results demonstrate that ShotKV achieves performance improvements of 9%-18% on long-context generation tasks under aggressive compression. - The authors analyze attention patterns and cross-task compression performance to identify key factors influencing compression sensitivity, including model training dynamics, prompt length, and task-specific requirements. - The findings provide valuable insights into the relationship between KV cache compression methods and LLMs' fundamental abilities. | ['Natural Language Processing'] | N/A | N/A |
| [Satori: Reinforcement Learning with Chain-of-Action-Thought Enhances LLM Reasoning via Autoregressive Search](https://arxiv.org/abs/2502.02508) | Zhenfang Chen, Zhang-Wei Hong, Zhenting Qi, Guangtao Zeng, maohaos2 | This paper introduces Satori, a 7B parameter LLM enhanced with a Chain-of-Action-Thought (COAT) reasoning mechanism and a two-stage training paradigm (format tuning and self-improvement via reinforcement learning).  Satori achieves state-of-the-art performance on mathematical reasoning benchmarks and exhibits strong generalization to out-of-domain tasks.  The COAT mechanism allows for self-reflection and exploration of alternative solutions, improving reasoning capabilities.  The two-stage training paradigm effectively leverages a small-scale imitation learning stage for format tuning followed by a large-scale reinforcement learning stage for self-improvement.  Experimental results demonstrate Satori's superiority over existing methods. | ['Natural Language Processing', 'Reinforcement Learning', 'Text Generation', 'Question Answering'] | [Link](https://satori-reasoning.github.io/) | N/A |
