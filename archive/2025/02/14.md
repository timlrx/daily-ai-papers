

## Papers for 2025-02-14

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [InfiniteHiP: Extending Language Model Context Up to 3 Million Tokens on a Single GPU](https://arxiv.org/abs/2502.08910) | Sung Ju Hwang, Losif63, geonp, gmlwns5176 | - InfiniteHiP is a novel framework for long-context Language Model (LLM) inference that extends context length up to 3 million tokens on a single 48GB GPU by dynamically pruning irrelevant context and offloading key-value cache to host memory. - It employs a modular, hierarchical token pruning algorithm to accelerate processing by discarding less relevant tokens and utilizes various Rotary Positional Embeddings (RoPE) adjustments to generalize to sequences longer than the LLM's training length. - InfiniteHiP achieves an 18.95x speedup on attention decoding with a 1-million token context on a single GPU without requiring any additional training compared to standard attention. - Evaluation on LongBench and âˆžBench benchmarks shows improved performance over state-of-the-art efficient long-context methods such as InfLLM, especially with longer contexts and on short-context LLMs tested on extended contexts. - The framework is implemented within the SGLang LLM serving framework, demonstrating its practicality for real-world use cases, and uses a specialized LRU-based cache policy. | ['Natural Language Processing', 'Question Answering', 'Text Generation', 'Summarization'] | N/A | N/A |
| [SelfCite: Self-Supervised Alignment for Context Attribution in Large Language Models](https://arxiv.org/abs/2502.09604) | Hu Xu, Shannon Zejiang Shen, ZhaofengWu, bencw, voidism | - SelfCite, a novel self-supervised framework, enhances the quality of citations in large language models (LLMs) without human annotations. - It leverages a reward system based on context ablation, calculating necessity (probability drop when cited text is removed) and sufficiency (probability hold when only cited text is retained) scores. - SelfCite employs best-of-N sampling and preference optimization with SimPO for improved citation quality, boosting F1 scores by up to 5.3 points on LongBench-Cite across various long-form question answering tasks, surpassing previous state-of-the-art and proprietary model prompting. - The method excels in producing shorter yet more precise citations, addressing the challenge of hallucination in LLMs by linking generated text to specific evidence. - Length balancing is applied during training to prevent models from simply generating longer citations as a shortcut, and further iterative SimPO training has been studied with improved performance. | ['Natural Language Processing', 'Question Answering'] | [Link](https://github.com/voidism/SelfCite) | N/A |
| [Exploring the Potential of Encoder-free Architectures in 3D LMMs](https://arxiv.org/abs/2502.09620) | delinqu, Tavish9, zhuhaow, Purple1288, IvanTang | - This paper introduces ENEL, an encoder-free 3D Large Multimodal Model (LMM) that addresses the limitations of encoder-based 3D LMMs, such as fixed point cloud resolution and mismatched semantic embedding with Large Language Models (LLMs). - ENEL utilizes an LLM-embedded Semantic Encoding strategy with a Hybrid Semantic Loss during pre-training to enable the LLM to learn high-level 3D semantics directly from point cloud tokens. - It employs a Hierarchical Geometry Aggregation strategy during instruction tuning to enhance the LLM's perception of 3D geometric structures. - The 7B ENEL model achieves state-of-the-art performance on the Objaverse 3D captioning benchmark with a GPT-4 score of 50.92% and competitive results on classification and VQA tasks, rivaling or exceeding the performance of larger, encoder-based models like ShapeLLM-13B. - This demonstrates the potential of encoder-free architectures for efficient and scalable 3D LMMs. | ['Multimodal', 'Text-to-3D', 'Text-to-Image', 'Computer Vision'] | [Link](https://github.com/Ivan-Tang-3D/ENEL) | N/A |
| [An Open Recipe: Adapting Language-Specific LLMs to a Reasoning Model in One Day via Model Merging](https://arxiv.org/abs/2502.09056) | Kasima Tharnpipitchai, Potsawee Manakul, Kunat Pipatanakul, pittawat | - This paper introduces a method for enhancing the reasoning capabilities of language-specific Large Language Models (LLMs) by merging them with a reasoning-focused LLM (DeepSeek R1 70B Distill). - The method involves a two-stage process: (1) representation alignment via supervised fine-tuning (SFT) on a combined dataset of translated reasoning traces and general instructions; (2) ability-aware model merging, where the merging ratio is optimized based on layer depth, giving higher weight to DeepSeek R1 in earlier layers and to the language-specific LLM in later layers. - Applying this method to a 70B Thai LLM (Typhoon2 70B Instruct) with Deepseek R1 70B and a budget of $120 demonstrates performance comparable to DeepSeek R1 on reasoning tasks while maintaining strong performance on Thai language tasks, with an average score of 76.5/100. - Experiments also validate that merging alone and sft alone performs worse than merging with sft. - Results show that merging model improved overall average metric by 41.6% over Typhoon2 70B Instruct and 12.8% over DeepSeek R1 70B Distill. | ['Natural Language Processing', 'Question Answering', 'Text Generation'] | N/A | [Link](https://huggingface.co/spaces/ThaiLLM-Leaderboard/leaderboard), [Link](https://huggingface.co/datasets/scb10x/ifeval-th), [Link](https://huggingface.co/datasets/HuggingFaceH4/aime_2024), [Link](https://huggingface.co/datasets/Suraponn/thai_instruction_sft), [Link](https://huggingface.co/datasets/LDJnr/Capybara), [Link](https://huggingface.co/datasets/ThaiLLM-Leaderboard/mt-bench-thai), [Link](https://huggingface.co/datasets/airesearch/WangchanThaiInstruct), [Link](https://huggingface.co/aisingapore/llama3.1-70b-cpt-sea-lionv3-instruct) |
| [Can this Model Also Recognize Dogs? Zero-Shot Model Search from Weights](https://arxiv.org/abs/2502.09619) | Yedid Hoshen, Or Nathan, Jonathan Kahana, Eliahu | - This paper introduces ProbeLog, a method for retrieving classification models that can recognize a target concept (e.g., "Dog") without access to model metadata or training data. - ProbeLog computes a descriptor for each output logit of a model by observing its responses on a fixed set of input probes and normalizing the response vector.  - It supports both logit-based retrieval ("find more logits like this") and zero-shot, text-based retrieval ("find all logits corresponding to dogs") using text alignment with probes.  - A collaborative filtering method is introduced to reduce the cost of encoding repositories by probing models with fewer samples and imputing missing data.  - Experiments show ProbeLog achieves high retrieval accuracy on real-world and fine-grained search tasks, outperforming model-level baselines and generalizing to real-world models from Hugging Face. | ['Zero-Shot Classification', 'Multimodal', 'Image Classification'] | N/A | N/A |
| [CoSER: Coordinating LLM-Based Persona Simulation of Established Roles](https://arxiv.org/abs/2502.09082) | Rui Xu, Xinfeng Yuan, Yifei Zhang, Heng Wang, Xintao Wang | - Introduces COSER, a dataset, model, and evaluation framework for role-playing language agents (RPLAs) focused on established characters from literature. - The COSER dataset includes nearly 30,000 authentic multi-character conversations from 771 books, along with character profiles, plot summaries, and internal thoughts. - CoSER 8B and CoSER 70B are open role-playing LLMs trained on the COSER dataset and based on LLaMA-3.1. - Given-circumstance acting (GCA) is used for training and evaluation, where LLMs simulate conversations with defined characters and contexts. - COSER 70B shows state-of-the-art performance on the InCharacter and LifeChoice benchmarks and achieves or surpasses GPT-40 on other RPLA benchmarks. | ['Natural Language Processing', 'Question Answering'] | N/A | [Link](https://huggingface.co/datasets/allenai/tulu-3-sft-mixture/tree/main/data) |
| [EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language Models for Vision-Driven Embodied Agents](https://arxiv.org/abs/2502.09560) | Cheng Qian, Mark Zhao, Junyu Zhang, Rui Yang, Hanyang81 | - Introduces EMBODIEDBENCH, a comprehensive benchmark for evaluating vision-driven embodied agents powered by Multimodal Large Language Models (MLLMs). - The benchmark includes 1,128 testing tasks across four environments: EB-ALFRED, EB-Habitat, EB-Navigation, and EB-Manipulation, encompassing both high-level and low-level tasks. - Evaluates 13 leading MLLMs and finds that they excel in high-level tasks but struggle with low-level manipulation, with the best model, GPT-4, achieving only a 28.9% success rate on average. - Proposes a novel capability-oriented evaluation across six subsets: basic task solving, common sense reasoning, complex instruction understanding, spatial awareness, visual perception, and long-term planning. - Demonstrates the importance of vision for embodied agents, particularly in low-level tasks, with performance significantly degrading when vision is removed. | ['Robotics', 'Multimodal'] | N/A | N/A |
| [Logical Reasoning in Large Language Models: A Survey](https://arxiv.org/abs/2502.09100) | Chaoli Zhang, Mengru Ding, Hanmeng Liu, ruoxining, HarryFu | - This survey paper explores the advancements and challenges in integrating logical reasoning capabilities into Large Language Models (LLMs). - The paper categorizes logical reasoning into four paradigms: deductive, inductive, abductive, and analogical, analyzing existing benchmarks and evaluation methods for each. - Several state-of-the-art techniques for enhancing logical reasoning in LLMs are discussed, including data-centric approaches, model-centric approaches, external knowledge utilization, and neuro-symbolic methods. - The paper highlights unresolved tensions in the field, such as the trade-off between robustness and generalization, the balance between interpretability and performance, and the need for more rigorous evaluation metrics. - Future research directions are proposed, emphasizing the need for hybrid architectures, robust evaluation frameworks, and exploration of multimodal reasoning. | ['Natural Language Processing', 'Question Answering'] | N/A | N/A |
| [MME-CoT: Benchmarking Chain-of-Thought in Large Multimodal Models for Reasoning Quality, Robustness, and Efficiency](https://arxiv.org/abs/2502.09621) | Yu Qi, Yanwei Li, Ziyu Guo, Renrui Zhang, CaraJ | - Introduces MME-CoT, a benchmark designed to evaluate Chain-of-Thought (CoT) reasoning in Large Multimodal Models (LMMs) across six diverse domains (math, science, OCR, logic, space-time, general scenes). - Proposes a novel evaluation suite encompassing three key aspects of CoT: quality (recall and precision of reasoning steps), robustness (impact of CoT on perception vs. reasoning tasks), and efficiency (relevance of generated content and effectiveness of reflection steps). - Leverages curated high-quality data with fine-grained annotations of key reasoning steps and image captions. - Through analysis of state-of-the-art LMMs, finds that reflection mechanisms enhance CoT quality, CoT can negatively impact performance on perception-heavy tasks, and existing LMMs exhibit inefficiencies in long CoT and reflection processes, like Kimi k1.5 outperforming GPT-4 in CoT quality. | ['Multimodal', 'Question Answering'] | N/A | N/A |
| [Typhoon T1: An Open Thai Reasoning Model](https://arxiv.org/abs/2502.09042) | Kunat Pipatanakul, Kasima Tharnpipitchai, Potsawee Manakul, pittawat | - This research introduces Typhoon T1, an open-source Thai reasoning model based on a supervised fine-tuning approach using synthetic data.  - The model outperforms standard fine-tuning and zero-shot prompting on several benchmarks including GSM8K, HumanEval+, and IFEval.  - The paper introduces a novel "structured thinking" format using XML tags to guide the model's reasoning process and shows that it improves performance.  - The authors release their datasets, data pipeline, training configurations, and model weights to support further research and development of reasoning models.  - Additional findings include the effects of data quantity and mixture on reasoning model performance. | ['Natural Language Processing', 'Question Answering', 'Text Generation'] | N/A | N/A |
| [CoT-Valve: Length-Compressible Chain-of-Thought Tuning](https://arxiv.org/abs/2502.09601) | Xinchao Wang, Gongfan Fang, Runpeng Yu, Guangnian Wan, Xinyin Ma | - This paper introduces CoT-Valve, a novel method for controlling the length of Chain-of-Thought (CoT) reasoning paths generated by Large Language Models (LLMs).  - CoT-Valve identifies a direction in the parameter space that allows for increasing or decreasing the length of generated CoT, using LoRA to implement this controllable direction, enabling flexible length manipulation during inference. - It introduces MixChain, a dataset with paired long and short reasoning chains, used to refine the direction for precise tuning and progressively compress reasoning paths. - Experiments on various LLMs show CoT-Valve achieves better control and compression of CoT compared to prompt-based methods and other baselines.  - The results also indicate that shorter reasoning paths can sometimes outperform longer ones on simpler tasks, highlighting the potential of CoT-Valve for enhancing model efficiency. | ['Natural Language Processing', 'Question Answering', 'Text Generation'] | [Link](https://github.com/horseee/CoT-Valve) | N/A |
| [SQuARE: Sequential Question Answering Reasoning Engine for Enhanced Chain-of-Thought in Large Language Models](https://arxiv.org/abs/2502.09390) | Moshe Wasserblat, Gad Markovits, Moshe Berchansky, danf | - This paper introduces SQuARE (Sequential Question Answering Reasoning Engine), a novel prompting technique designed to enhance chain-of-thought reasoning in Large Language Models (LLMs). - SQuARE prompts LLMs to generate and answer a series of sub-questions before addressing the main query, fostering a more thorough exploration of various aspects of a topic. - Evaluations were conducted with Llama 3 (3B and 8B) and GPT-4o on TriviaQA, HotpotQA, and ASQA datasets. - SQuARE consistently outperforms traditional Chain-of-Thought (CoT) prompting and existing rephrase-and-respond methods, especially with smaller LLMs. - The results suggest that systematically decomposing queries through self-interrogation improves reasoning capabilities in LLMs. | ['Question Answering'] | [Link](https://github.com/IntelLabs/RAG-FiT/tree/square) | N/A |
| [mmE5: Improving Multimodal Multilingual Embeddings via High-quality Synthetic Data](https://arxiv.org/abs/2502.08468) | Ziliang Zhao, Yutao Zhu, Nan Yang, Liang Wang, Haon-Chen | - This paper introduces mmE5, a multimodal multilingual embedding model trained on synthetic data generated using an MLLM (Multimodal Large Language Model). - The synthetic data generation framework focuses on three criteria: broad scope (covering diverse tasks, modalities, and languages), robust cross-modal alignment (achieved via a deep thinking process within the MLLM), and high fidelity (using real images and a refinement process). - mmE5 achieves state-of-the-art zero-shot performance on the MMEB benchmark with significantly less data than previous methods and shows superior multilingual performance on the XTD benchmark. - mmE5 demonstrates strong generalization capabilities across different tasks (classification, visual question answering, retrieval) and modalities. - The authors also analyzed the scaling effect of the synthetic data size and other hyperparameters, such as LORA rank, training batch size, and temperature. | ['Multimodal', 'Image-to-Text', 'Text-to-Image', 'Visual Question Answering', 'Zero-Shot Classification'] | [Link](https://github.com/haon-chen/mmE5) | N/A |
| [The Stochastic Parrot on LLM's Shoulder: A Summative Assessment of Physical Concept Understanding](https://arxiv.org/abs/2502.08946) | Shunchi Zhang, Tsz Ting Chung, Junjie Wu, Lemao Liu, Mo Yu | - This research paper introduces PHYSICO, a new benchmark designed to assess the depth of understanding in Large Language Models (LLMs), particularly in the realm of physical concepts. - PHYSICO employs a summative assessment approach, presenting tasks in both natural language and abstract grid formats to evaluate LLMs' comprehension beyond memorization. - Experimental results demonstrate that state-of-the-art LLMs, including GPT-40 and Gemini 2.0, significantly lag behind human performance on PHYSICO's high-level understanding subtasks. - This performance disparity between low-level (definition-based) and high-level (abstract reasoning) tasks provides quantitative evidence for the "stochastic parrot" phenomenon, where LLMs excel at mimicking patterns but struggle with genuine comprehension. - Further analysis reveals that the challenge stems from the intrinsic difficulty of understanding these concepts rather than unfamiliar format, as fine-tuning and in-context learning provide minimal benefit, indicating a need for deeper comprehension capabilities in LLMs. | ['Natural Language Processing', 'Question Answering', 'Multimodal'] | [Link](https://physico-benchmark.github.io) | N/A |
