

## Papers for 2025-02-17

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [ZeroBench: An Impossible Visual Benchmark for Contemporary Large Multimodal Models](https://arxiv.org/abs/2502.09696) | Samuel Roberts, Akash Gupta, Ansh Sharma, Mohammad Reza Taesiri, Jonathan Roberts | - Introduces ZeroBench, a challenging visual reasoning benchmark designed to be impossible for current large multimodal models (LMMs). - Contains 100 manually created questions and 334 subquestions, focusing on complex multi-step reasoning with diverse natural and synthetic images. - Evaluates 20 prominent LMMs, including those with test-time compute scaling, all achieving 0% accuracy on the primary questions. - Error analysis reveals that models struggle primarily with visual interpretation rather than logical reasoning. - Public release of ZeroBench aims to encourage progress in visual understanding by providing an extremely difficult benchmark with maximum headroom. | ['Multimodal', 'Visual Question Answering'] | N/A | N/A |
| [Large Language Diffusion Models](https://arxiv.org/abs/2502.09992) | Jingyang Ou, Xiaolu Zhang, Zebin You, Fengqi Zhu, Shen Nie | - This paper introduces LLaDA, a large language diffusion model trained from scratch using a masked diffusion approach, challenging the dominance of autoregressive models in natural language processing. - LLaDA uses a vanilla Transformer architecture to predict masked tokens, optimizing a likelihood bound for probabilistic inference, enabling bidirectional dependencies. - Across various benchmarks, LLaDA 8B demonstrates strong scalability and competes with LLaMA3 8B in in-context learning and instruction-following after supervised fine-tuning. - LLaDA addresses the reversal curse, outperforming GPT-4 in a reversal poem completion task, showing its ability for bidirectional context processing. - These findings establish diffusion models as a viable alternative to autoregressive models for LLMs, suggesting that key LLM capabilities aren't inherently tied to autoregression. | ['Natural Language Processing', 'Text Generation'] | N/A | N/A |
| [MM-RLHF: The Next Step Forward in Multimodal LLM Alignment](https://arxiv.org/abs/2502.10391) | Peiyan Li, Chaoyou Fu, Haochen Tian, Tao Yu, Yi-Fan Zhang | - Introduces MM-RLHF, a 120k human-annotated multimodal dataset designed for aligning large language models with human preferences, focusing on improved quality, diversity, granularity, and interpretability over existing datasets. - Proposes a Critique-Based Reward Model that generates critiques of model outputs before scoring, enabling fine-grained evaluation and outperforming other 7B-scale models on various reward model benchmarks. - Presents Dynamic Reward Scaling, which optimizes the Direct Preference Optimization (DPO) framework by adjusting sample loss weights according to reward signal strength. - Evaluates on 27 benchmarks across 10 dimensions, demonstrating substantial improvements – 19.5% increase in conversational abilities and 60% enhancement in safety for LLaVA-ov-7B when fine-tuned with MM-RLHF. - Argues that well-designed alignment using MM-RLHF and the proposed methods comprehensively boosts MLLM capabilities in various tasks, including visual perception, reasoning, dialogue, and trustworthiness. | ['Multimodal', 'Reinforcement Learning'] | N/A | [Link](https://huggingface.co/datasets/lmms-lab/LLaVA-OneVision-Data), [Link](https://huggingface.co/datasets/Yirany/UniMM-Chat), [Link](https://huggingface.co/openai/clip-vit-base-patch32) |
| [Precise Parameter Localization for Textual Generation in Diffusion Models](https://arxiv.org/abs/2502.09935) | Adam Dziedzic, Kamil Deja, Franziska Boenisch, Bartosz Cywiński, Łukasz Staniszewski | - This paper introduces a method for localizing a small subset of cross and joint attention layers within diffusion models that are responsible for generating text within images.  - The method involves "patching" the activations of these layers with the activations generated from a target prompt, which allows for precise modification of the generated text without affecting other visual attributes.  - Through experiments on Stable Diffusion XL, DeepFloyd IF, and Stable Diffusion 3, it demonstrates that less than 1% of the model parameters are responsible for text generation, and that the localized layers are highly specialized to textual content.  -  Fine-tuning only these localized layers with LoRA improves the quality of the generated text without affecting the overall generation capabilities and diversity.  - The localization method is also applied to text editing within synthetic images and prevention of toxic text generation, outperforming prior techniques. | ['Text-to-Image', 'Image-to-Image', 'Multimodal'] | N/A | N/A |
| [Diverse Inference and Verification for Advanced Reasoning](https://arxiv.org/abs/2502.09955) | Yuke Zhang, Seunghwan Hyun, Mao Mao, Gaston Longhitano, Iddo Drori | - This research introduces a diverse inference approach that combines multiple models and methods during test time to tackle advanced reasoning tasks such as International Mathematical Olympiad (IMO) combinatorics problems, Abstraction and Reasoning Corpus (ARC) puzzles, and Humanity's Last Exam (HLE) questions. - The approach utilizes perfect verifiers (Lean for IMO and code execution for ARC) and imperfect verifiers (best-of-N for HLE) to increase accuracy and validate solutions. - Test-time simulations and reinforcement learning generate problem-specific information, improving generalization by adapting agent graph representations and varying prompts, code, and datasets. - Meta-learning is employed to trace pipeline runs, generate A/B tests, and adaptively modify the agent graph structure. - The proposed approach increases accuracy on IMO combinatorics problems to 77.8%, HLE question accuracy to 37%, solves 80% of human-failed ARC puzzles, and 26.5% of puzzles unsolved by high-compute OpenAI models. | ['Reinforcement Learning', 'Natural Language Processing', 'Question Answering'] | N/A | N/A |
| [We Can't Understand AI Using our Existing Vocabulary](https://arxiv.org/abs/2502.07586) | Been Kim, Robert Geirhos, John Hewitt | - This paper introduces a new framework for understanding and controlling AI systems, arguing that progress in interpretability can be improved by defining and using neologisms (new words) corresponding to human concepts that we want to teach machines or machine concepts that we need to learn. - The paper posits that humans and machines conceptualize the world differently, leading to mismatches and a communication problem where bridging these differences is best achieved by forming new words. - It proposes "neologism embedding learning" as a proof of concept, where new word embeddings are learned via preference-based losses to understand and control model behavior; experiments include a length neologism to control LLM response length, and a diversity neologism to control the variability of responses. - Results show that using a "length neologism" enables controlling LLM response length to within a specified range more effectively than baseline prompting techniques. - Another experiment demonstrates that utilizing a "diversity neologism" promotes response diversity, aiding in tasks requiring exploration of variations, such as guessing a hidden number. | ['Natural Language Processing'] | N/A | N/A |
| [FoNE: Precise Single-Token Number Embeddings via Fourier Features](https://arxiv.org/abs/2502.09741) | Vatsal Sharan, Robin Jia, Mahdi Soltanolkotabi, Deqing Fu, Tianyi Zhou | - This research proposes **Fourier Number Embedding (FoNE)**, a novel method designed to enhance the representation and processing of numerical data within Large Language Models (LLMs). - FoNE directly maps numbers to their Fourier representations, encoding each digit using sine and cosine functions with different periods. This approach facilitates precise representation and efficient handling of numbers within LLMs. - On a 6-digit decimal addition task, FoNE achieves 99% accuracy with 64 times less training data than standard tokenization methods, while using significantly fewer tokens. Moreover, it reaches perfect accuracy with a larger training set. - FoNE not only accelerates training and inference but also facilitates perfect accuracy on various numerical tasks, including subtraction and multiplication, outperforming existing methods. - The method's efficiency and precision address a fundamental limitation in current LLMs, paving the way for improved performance on number-related tasks and broader applications in fields involving numerical reasoning. | ['Natural Language Processing'] | N/A | N/A |
| [Jailbreaking to Jailbreak](https://arxiv.org/abs/2502.09638) | Bijan Varjavand, Robert Vacareanu, Vaughn Robinson, Jeremy Kritz, ZifanScale | - This paper introduces a novel approach to red teaming Large Language Models (LLMs) called "jailbreaking-to-jailbreak" (J2), where a human jailbreaks an LLM (J2 attacker) to make it willing to jailbreak itself or other LLMs. - J2 attackers can systematically evaluate target models using various red teaming strategies and improve their performance via in-context learning from previous failures. - Experiments demonstrate that Sonnet-3.5 and Gemini-1.5-pro outperform other LLMs as J2 attackers, achieving high attack success rates against GPT-40 and other capable LLMs on Harmbench. - This approach not only offers a scalable way for strategic red teaming but also highlights an overlooked failure mode of LLM safeguards: LLMs can bypass their own safeguards by employing a jailbroken version of themselves. - The methodology is publicly shared, while specific prompting details are kept private to prevent misuse. | ['Natural Language Processing'] | N/A | N/A |
| [STMA: A Spatio-Temporal Memory Agent for Long-Horizon Embodied Task Planning](https://arxiv.org/abs/2502.10177) | Shuguang Cui, Zhixin Mai, Ge Wang, Yiming Zhao, Mingcong Lei | - Introduces Spatio-Temporal Memory Agent (STMA), a novel framework enhancing embodied task planning and decision-making through integrated spatio-temporal memory, dynamic knowledge graph, and planner-critic mechanism. - STMA leverages a dynamic Knowledge Graph (KG) for spatial memory, updating in real-time to reflect environmental changes for improved spatial reasoning and adaptability in complex scenarios.  - Employs a planner-critic closed-loop architecture combining proactive multi-step planning with real-time feedback for robust decision-making in dynamic environments. - Achieves 31.25% higher success rate and 24.7% higher average score compared to state-of-the-art models in the TextWorld environment, demonstrating effectiveness in long-horizon tasks.  - Demonstrates competitive performance using open-source models without fine-tuning, emphasizing the efficacy of the spatio-temporal memory design in conjunction with a planner-critic framework. | ['Reinforcement Learning', 'Robotics', 'Natural Language Processing'] | N/A | N/A |
| [V2V-LLM: Vehicle-to-Vehicle Cooperative Autonomous Driving with Multi-Modal Large Language Models](https://arxiv.org/abs/2502.09980) | Yu-Chiang Frank Wang, Stephen F. Smith, Chien-Yi Wang, Ryo Hachiuma, Hsu-kuang Chiu | - This paper introduces V2V-LLM, a new multimodal large language model (MLLM) for cooperative autonomous driving that fuses perception information from multiple connected autonomous vehicles (CAVs) to improve driving safety. - V2V-LLM uses a centralized LLM computing node that receives individual perception features (scene-level feature maps and object-level feature vectors) from each CAV, answers driving related questions in natural language based on fused information. -  A new dataset and benchmark called Vehicle-to-Vehicle Question-Answering (V2V-QA) is created based on V2V4Real dataset to support the development and evaluation of LLM-based cooperative autonomous driving. - V2V-QA includes question-answer pairs about grounding, notable object identification, and planning. - Experimental results show that V2V-LLM outperforms other baseline fusion methods, especially in the notable object identification and planning tasks, important for overall driving safety. | ['Multimodal', 'Visual Question Answering', 'Object Detection', 'Robotics'] | N/A | N/A |
| [Agentic End-to-End De Novo Protein Design for Tailored Dynamics Using a Language Diffusion Model](https://arxiv.org/abs/2502.10173) | Markus J. Buehler, Bo Ni | - This paper introduces VibeGen, a generative AI framework for end-to-end de novo protein design conditioned on normal mode vibrations, enabling the design of proteins with tailored dynamic properties. - VibeGen employs a dual-model architecture with a protein designer (PD) generating sequence candidates based on specified vibrational modes and a protein predictor (PP) evaluating their dynamic accuracy. - The designed proteins accurately reproduce prescribed normal mode amplitudes while adopting diverse stable, functionally relevant structures, often de novo, thereby expanding the protein space beyond evolutionary constraints. - The framework establishes a bidirectional link between sequence and vibrational behavior, which holds implications for designing flexible enzymes, dynamic scaffolds, and biomaterials. - The two-player framework outperforms single-model approaches by collaboratively boosting the strength of end-to-end models, improving accuracy and diversity of protein designs. | ['Natural Language Processing', 'Text Generation'] | [Link](https://github.com/lamm-mit/ModeShapeDiffusionDesign) | [Link](https://huggingface.co/lamm-mit/VibeGen) |
