

## Papers for 2025-03-04

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [Visual-RFT: Visual Reinforcement Fine-Tuning](https://arxiv.org/abs/2503.01785) | yhcao, sweetFruit, yuhangzang, Zery, ziyuliu | - Introduces Visual Reinforcement Fine-Tuning (Visual-RFT), a novel approach for enhancing the visual perception and reasoning capabilities of Large Vision-Language Models (LVLMs) using reinforcement learning with verifiable rewards. - Visual-RFT employs a policy optimization algorithm, such as Group Relative Policy Optimization (GRPO), guided by task-specific, rule-based verifiable reward functions (e.g., Intersection over Union (IoU) for object detection). - Demonstrates superior performance compared to Supervised Fine-tuning (SFT) across diverse visual tasks, including few-shot image classification, open-vocabulary object detection, and reasoning grounding, especially in data-scarce scenarios. - Achieves significant improvements in few-shot learning, boosting accuracy by 24.3% in one-shot fine-grained image classification with limited samples, and exceeding SFT baselines in few-shot object detection on COCO and LVIS datasets. - Showcases advanced generalization ability by successfully transferring knowledge to novel and rare categories in open-vocabulary object detection, improving mAP by substantial margins on both COCO and LVIS benchmarks. | ['Multimodal', 'Computer Vision', 'Reinforcement Learning', 'Image Classification', 'Object Detection', 'Zero-Shot Object Detection'] | [Link](https://github.com/Liuziyu77/Visual-RFT) | N/A |
| [Phi-4-Mini Technical Report: Compact yet Powerful Multimodal Language Models via Mixture-of-LoRAs](https://arxiv.org/abs/2503.01743) | vishravmsft, martincai, alonbenhaim, jianmin-ustc, atabakashfaqMSFT | - Phi-4-Mini and Phi-4-Multimodal are compact language and multimodal models, respectively, trained on curated web and synthetic data. - Phi-4-Mini, a 3.8B parameter model, outperforms similarly sized open-source models and matches larger models on complex reasoning tasks, utilizing a 200K token vocabulary and group query attention. - Phi-4-Multimodal integrates text, vision, and speech/audio using LoRA adapters and modality-specific routers, achieving state-of-the-art performance in multiple inference modes. - This "Mixture of LoRAs" approach allows flexible modality combinations without interference, exemplified by its top ranking on the OpenASR leaderboard with a compact speech/audio LoRA. - A reasoning-enhanced version of Phi-4-Mini rivals larger models like DeepSeek-R1-Distill-Qwen-7B and DeepSeek-R1-Distill-Llama-8B in reasoning tasks. | ['Multimodal', 'Image-to-Text', 'Visual Question Answering', 'Automatic Speech Recognition', 'Translation', 'Summarization', 'Question Answering', 'Text2Text Generation', 'Text Generation', 'Natural Language Processing'] | N/A | N/A |
| [OneRec: Unifying Retrieve and Rank with Generative Recommender and Iterative Preference Alignment](https://arxiv.org/abs/2502.18965) | GuoruiZhou, DingWF, caikuo, oneself, OrpheusBetter | - OneRec, a unified end-to-end generative framework, is proposed for single-stage recommendation, surpassing traditional cascaded ranking systems. - OneRec uses an encoder-decoder structure with sparse Mixture-of-Experts (MoE) to handle user behavior sequences and generate videos of interest efficiently. - It employs a session-wise list generation approach, considering context and order within a session, unlike point-by-point next-item prediction. - An Iterative Preference Alignment (IPA) module with Direct Preference Optimization (DPO) enhances generated results by learning from self-hard rejected samples ranked by a reward model. - Deployed in Kuaishou, a short-video platform, OneRec achieved a 1.6% increase in watch-time, demonstrating substantial improvement. | ['Natural Language Processing', 'Text Generation', 'Reinforcement Learning'] | N/A | N/A |
| [Liger: Linearizing Large Language Models to Gated Recurrent Structures](https://arxiv.org/abs/2503.01496) | Yu Cheng, JusenK, Jiaxihu2, weigao266, landisen | - Liger is a novel method for linearizing large language models (LLMs), converting pre-trained Transformer-based LLMs into gated linear recurrent models without introducing additional parameters, enabling efficient deployment. - It repurposes the pre-trained key matrix weights to construct diverse gating mechanisms, facilitating various gated recurrent structures. - Using Low-Rank Adaptation (LoRA), Liger restores the linearized model's performance to match the original LLMs with minimal linearization cost. - Liger introduces a hybrid attention mechanism, combining sliding window softmax attention and linear recurrent modeling, accelerating linearization and maintaining LLM capabilities with linear-time inference. - Experimental results on models ranging from 1B to 8B parameters show that Liger outperforms existing linearization methods, achieving competitive results across benchmarks with limited training tokens. | ['Natural Language Processing', 'Text Generation'] | [Link](https://github.com/OpenSparseLLMs/Linearization) | N/A |
| [When an LLM is apprehensive about its answers -- and when its uncertainty is justified](https://arxiv.org/abs/2503.01688) | Alexey Zaytsev, Edvard Khalafyan, DanielVyazhev, aigoncharov, sspetya | - This paper investigates the effectiveness of different uncertainty estimation methods for multiple-choice question-answering tasks using Large Language Models (LLMs). - The study focuses on token-wise entropy and model-as-judge (MASJ) estimates across various question topics and LLM sizes (Phi-4, Mistral, and Qwen). - Results indicate that response entropy effectively predicts model errors in knowledge-dependent domains and correlates with question difficulty (e.g., 0.73 ROC AUC for biology). - However, this correlation weakens in reasoning-dependent domains (e.g., 0.55 ROC AUC for math), suggesting the need to integrate data-related uncertainty within entropy frameworks. - The study also reveals biases in the MMLU-Pro dataset regarding reasoning requirements across different topics, calling for more balanced datasets for fair LLM evaluation. | ['Question Answering', 'Natural Language Processing'] | [Link](https://github.com/LabARSS/question-complextiy-estimation) | N/A |
| [DiffRhythm: Blazingly Fast and Embarrassingly Simple End-to-End Full-Length Song Generation with Latent Diffusion](https://arxiv.org/abs/2503.01183) | Guobin Ma, Chunbo Hao, Yuepeng Jiang, Huakang Chen, Ziqian Ning | - DiffRhythm is a novel diffusion-based model for generating full-length songs (up to 4m45s) with both vocals and accompaniment, conditioned on lyrics and a style prompt. - It utilizes a Variational Autoencoder (VAE) trained on a large music dataset (60,000 hours) for high-fidelity music reconstruction, demonstrating robustness against MP3 compression artifacts and sharing the same latent space with Stable Audio VAE. - A Diffusion Transformer (DiT) operates in the VAE's latent space, generating songs through iterative denoising, guided by style prompts, timesteps, and lyrics processed through a sentence-level alignment mechanism for improved vocal intelligibility. - Evaluations show DiffRhythm outperforms SongLM in quality and intelligibility while achieving a ~50x speedup in generation time, with an RTF below 0.04. - It addresses the limitations of existing autoregressive models by enabling faster generation, improving scalability, and maintaining consistency over longer sequences. | ['Text-to-Audio', 'Audio'] | N/A | [Link](https://huggingface.co/spaces/stabilityai/stable-audio-tools), [Link](https://huggingface.co/transformers) |
| [Cognitive Behaviors that Enable Self-Improving Reasoners, or, Four Habits of Highly Effective STaRs](https://arxiv.org/abs/2503.01307) | ngoodman, nlile, Asap7772, ayushchakravarthy, obiwan96 | - This paper investigates why some large language models (LLMs) improve significantly with reinforcement learning (RL) while others plateau, focusing on the presence of key cognitive behaviors in base LLMs. - It introduces a framework analyzing four cognitive behaviors: verification, backtracking, subgoal setting, and backward chaining, finding Qwen exhibits these more than Llama. - Priming Llama with examples demonstrating these behaviors, even incorrect solutions with correct reasoning patterns, substantially improved its RL performance, matching Qwen. - The study suggests the presence of these cognitive behaviors in the initial policy is crucial for effectively utilizing increased test-time compute through extended reasoning sequences. - Modifying pre-training data to emphasize these behaviors enabled Llama to achieve comparable self-improvement to Qwen, highlighting the importance of initial reasoning behaviors in enabling self-improvement through RL. | ['Natural Language Processing', 'Reinforcement Learning', 'Question Answering'] | [Link](https://github.com/kanishkg/cognitive-behaviors) | N/A |
| [Speculative Ad-hoc Querying](https://arxiv.org/abs/2503.00714) | Venkat Arun, Aditya Akella, Maria Angels de Luis Balaguer, Srikanth Kandula, Haoyu0529 | - SpeQL, a system for speculative ad-hoc querying, is introduced to reduce query latency by predicting and pre-executing queries while the user is still typing. - It leverages LLMs to predict query structure and precompute temporary tables containing the likely needed information and continuously displays results for speculated queries. - A user study shows SpeQL improved task completion time and aided in discovering data patterns more quickly. - Using TPC-DS queries and Amazon Redshift, SpeQL reduced planning, compilation, and execution latency by 94.42%, 99.99%, and 87.23%, respectively, with a P90 overhead of 7.72 seconds. - Open-sourced as a VS Code plugin and demonstrates potential for integration into database management systems. | ['Natural Language Processing', 'Question Answering', 'Table Question Answering'] | [Link](https://github.com/lihy0529/SpeQL) | N/A |
| [DuoDecoding: Hardware-aware Heterogeneous Speculative Decoding with Dynamic Multi-Sequence Drafting](https://arxiv.org/abs/2503.00784) | xpqiu, QipengGuo, KYLN24, KaiLv | - DuoDecoding is a novel hardware-aware heterogeneous speculative decoding method with dynamic multi-sequence drafting designed to accelerate large language model (LLM) text generation. - It strategically deploys the draft model on CPU and the target model on GPU, enabling parallel decoding and reducing draft model overhead. - A hardware-aware optimal draft budget minimizes idle times on both CPU and GPU. - Dynamic multi-sequence drafting enhances the quality of draft outputs based on uncertainty. - Experiments show up to a 2.61x speedup in generation latency compared to conventional autoregressive decoding and 17% reduction in time to first token compared to traditional speculative decoding. | ['Natural Language Processing', 'Text Generation'] | [Link](https://github.com/KaiLv69/DuoDecoding) | N/A |
| [Qilin: A Multimodal Information Retrieval Dataset with APP-level User Sessions](https://arxiv.org/abs/2503.00501) | Xiaohui He, Jia Chen, aiqy, haitaoli, qian | - This paper introduces Qilin, a multimodal information retrieval dataset collected from Xiaohongshu, a popular social platform with diverse content including image-text notes, video notes, commercial notes, and direct answers. - Qilin includes comprehensive user sessions with heterogeneous results, along with APP-level contextual signals and genuine user feedback, which facilitates advanced multimodal neural retrieval model development. - It contains user-favored answers and their referred results for search requests triggering the Deep Query Answering (DQA) module, which supports training and evaluation of Retrieval-augmented Generation (RAG) pipelines and analysis of module influence on user search behavior. - Preliminary experiments on search, recommendation and DQA tasks using baselines like BM25, BERT, DCN-V2, and VLM demonstrate the value of incorporating multimodal features and contextual signals. - DCN-V2 excels in search ranking by leveraging user history, features, and embeddings, while VLM demonstrates the effectiveness of visual information in both user modeling and note representation. | ['Multimodal', 'Question Answering', 'Natural Language Processing'] | [Link](https://github.com/RED-Search/Qilin) | N/A |
| [Word Form Matters: LLMs' Semantic Reconstruction under Typoglycemia](https://arxiv.org/abs/2503.01714) | Lang Gao, Zhongyu Wei, Ziruibest, Carol0110, Aurora-cx | - This paper investigates how Large Language Models (LLMs) reconstruct the semantics of words with scrambled internal characters (Typoglycemia) by introducing a novel metric, SemRecScore. - SemRecScore quantifies semantic reconstruction by comparing the representation of the original word token with the final subword token of the scrambled word at each layer of the LLM.  - Through experiments on LLaMA models, the study reveals that word form is the primary factor in semantic reconstruction, with contextual information having minimal impact. - LLMs rely on specialized attention heads to process word form information, with this mechanism remaining stable across varying scrambling levels. -  The study identifies a divergence between LLMs' fixed attention on word form and humans' adaptive strategy of balancing word form and context. | ['Natural Language Processing'] | [Link](https://github.com/Aurora-cx/TypoLLM) | N/A |
| [SampleMix: A Sample-wise Pre-training Data Mixing Strategey by Coordinating Data Quality and Diversity](https://arxiv.org/abs/2503.01506) | bitwjg, WeiWang, WQYC, DeyangKong, xixy | - This paper introduces SampleMix, a novel sample-wise pre-training data mixing strategy for Large Language Models (LLMs) that prioritizes both data quality and diversity. - Unlike traditional domain-wise methods, SampleMix employs a bottom-up approach, performing global sampling based on individual sample evaluations, dynamically determining optimal domain proportions, and adapting to varying token budgets. - SampleMix leverages a quality evaluator trained on GPT-40 annotations to assess data based on seven criteria and employs clustering analysis to gauge sample diversity, combining these metrics to create sample weights for dataset construction. - Experimental results on various downstream tasks and perplexity evaluations demonstrate SampleMix's superior performance compared to existing domain-based methods. - Notably, SampleMix achieves comparable accuracy with significantly fewer training steps, showcasing its training efficiency and its potential for optimizing pre-training data utilization. | ['Natural Language Processing'] | N/A | N/A |
| [From Hours to Minutes: Lossless Acceleration of Ultra Long Sequence Generation up to 100K Tokens](https://arxiv.org/abs/2502.18890) | Yuxuan Wang, zlzheng, vickyandkekey, JunzheS, TongWu | - TOKENSWIFT, a novel framework, accelerates ultra-long sequence generation (up to 100K tokens) with Large Language Models (LLMs) while maintaining the target model's quality. - It addresses three key challenges: frequent model reloading, dynamic key-value (KV) cache management, and repetitive generation, using techniques like multi-token generation, dynamic KV cache updates, and contextual penalties. - Experimental results demonstrate a 3x speedup across various model scales (1.5B, 7B, 8B, 14B) and architectures (MHA, GQA), translating to hours of time savings. - The acceleration becomes more pronounced with longer sequence lengths and larger model sizes, showing up to 5.54 hours saved for a 14B model generating 100K tokens. - TOKENSWIFT exhibits robust performance across varying prefix lengths and sampling methods, showcasing its versatility and applicability to diverse generation tasks. | ['Natural Language Processing', 'Text Generation'] | [Link](https://github.com/bigai-nlco/TokenSwift) | N/A |
| [CodeArena: A Collective Evaluation Platform for LLM Code Generation](https://arxiv.org/abs/2503.01295) | terryyz, DongHuang-ebay, bobxwu, anhtuanluu36, Elfsong | - CodeArena, an online evaluation framework for Large Language Model (LLM) code generation is introduced to address limitations like benchmark leakage, data dissipation, and limited accessibility in existing evaluation methods. - The framework features a dynamic evaluation system that recalibrates individual model scores based on the holistic performance of all participating models, mitigating score biases caused by benchmark leakage. - An open repository of solutions and test cases promotes transparency and facilitates research in LLM code generation, and automation-friendly APIs streamline the evaluation process. - Initial benchmarks using APPS and Mercury datasets demonstrate the platform's capability to assess LLM code generation performance. - CodeArena actively encourages community contribution to diversify the problem set and aims to establish a collaborative platform for evaluating and advancing code generation LLMs. | ['Natural Language Processing', 'Text Generation', 'Text2Text Generation'] | N/A | [Link](https://huggingface.co/) |
| [Large-Scale Data Selection for Instruction Tuning](https://arxiv.org/abs/2503.01807) | pradeepd, pangwei, faezeb, nanami, hamishivi | - This paper investigates the effectiveness of automated data selection methods for large-scale instruction tuning of language models. - The authors find that a variant of Representation-based Data Selection (RDS+), which uses weighted mean pooling of pre-trained LM hidden states, consistently outperforms other methods. - RDS+ improves performance with larger data pools, unlike other methods that decline or match random selection. - In multi-task settings, RDS+ outperforms baselines and human-curated mixtures like the TULU 2 dataset. - The study emphasizes the importance of evaluating data selection methods at scale to reveal their true potential for improving instruction-tuned language models. | ['Natural Language Processing', 'Text2Text Generation'] | [Link](https://github.com/hamishivi/automated-instruction-selection) | N/A |
| [AI-Invented Tonal Languages: Preventing a Machine Lingua Franca Beyond Human Understanding](https://arxiv.org/abs/2503.01063) | dnoever | - This paper proposes a tonal language system for machine-to-machine (M2M) communication, inspired by human cryptophasia and tonal languages like Mandarin. - The system maps ASCII characters to unique frequencies using a logarithmic scale based on musical semitones, spanning a range that includes ultrasonic frequencies beyond human hearing. - A software prototype demonstrates the encoding through visualization, auditory playback, and ABC musical notation, showing potential for information density exceeding human speech. - The work explores the potential for AI systems to develop private languages and provides a technical foundation for understanding and governing such communication. - By encoding messages in both audible and ultrasonic frequencies, the system offers a potential model for both human-interpretable and machine-private M2M communication. | ['Audio', 'Natural Language Processing', 'Multimodal'] | [Link](https://github.com/reveondivad/cryptophasia) | N/A |
| [CLEA: Closed-Loop Embodied Agent for Enhancing Task Execution in Dynamic Environments](https://arxiv.org/abs/2503.00729) | Qing Zhao, Zhixin Mai, Yiming Zhao, Ge Wang, SP4595 | - CLEA, a closed-loop embodied agent framework, is proposed for enhancing task execution in dynamic environments by incorporating four specialized open-source LLMs with functional decoupling for closed-loop task management. - The framework features two core innovations: an interactive task planner that generates executable subtasks dynamically based on environmental memory, and a multimodal execution critic employing an evaluation framework for probabilistic assessment of action feasibility, which triggers hierarchical re-planning when environmental perturbations exceed predefined thresholds. - Experimental results in a real environment with two heterogeneous robots for object search, object manipulation, and search-manipulation integration tasks demonstrate CLEA's effectiveness. - Across 12 task trials, CLEA outperforms the baseline model, achieving a 67.3% improvement in success rate and a 52.8% increase in task completion rate. - CLEA enhances the robustness of task planning and execution in dynamic environments by enabling adaptive decision-making through real-time environmental feedback and closed-loop perception-reasoning-execution. | ['Robotics', 'Multimodal'] | [Link](https://sp4595.github.io/CLEA/) | N/A |
