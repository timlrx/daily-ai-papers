

## Papers for 2025-03-05

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [MPO: Boosting LLM Agents with Meta Plan Optimization](https://arxiv.org/abs/2503.02682) | sujianli, songff, Adagio, Rsy24, xwm | - This paper introduces Meta Plan Optimization (MPO), a framework designed to enhance the planning abilities of Large Language Model (LLM) agents by incorporating explicit high-level guidance through meta plans. - MPO utilizes a meta planner to generate these abstract strategy plans, which are then optimized based on feedback from the agent's performance in the task environment, addressing common issues like planning hallucinations. - The framework employs Monte Carlo sampling to assess the effectiveness of the meta plans by measuring task completion rates, and uses Direct Preference Optimization (DPO) to refine the meta planner based on comparisons between high- and low-performing plans.  - Experimental results on ALFWorld and ScienceWorld benchmarks show MPO significantly improves agent performance, with gains up to 100%, outperforming existing baselines and explicit guidance methods.  - MPO provides a plug-and-play solution compatible with existing agent training frameworks, enabling efficient integration and performance boosts without retraining. | ['Natural Language Processing', 'Reinforcement Learning'] | [Link](https://github.com/WeiminXiong/MPO) | N/A |
| [Mask-DPO: Generalizable Fine-grained Factuality Alignment of LLMs](https://arxiv.org/abs/2503.02846) | Kai Chen, Chengqi Lyu, lindahua, ZwwWayne, vanilla1116 | - Mask-DPO, a novel fine-grained factuality alignment method for Large Language Models (LLMs), leverages sentence-level factuality as mask signals to resolve ambiguity in preference learning. - Unlike traditional Direct Preference Optimization (DPO), Mask-DPO learns exclusively from factually accurate sentences in preferred samples, avoiding penalties on factual content in non-preferred samples. - Experimental results show Mask-DPO significantly improves LLM factuality on in-domain and out-of-domain datasets, even with unseen topics during training.  - For instance, Mask-DPO boosts Llama3.1-8B-Instruct's score on the ANAH test set from 49.19% to 77.53%, exceeding Llama3.1-70B-Instruct (53.44%) and vanilla DPO (68.44%). - Further analysis suggests scaling the number of training topics is more impactful than increasing question diversity for factuality alignment. | ['Natural Language Processing', 'Question Answering'] | [Link](https://github.com/open-compass/ANAH) | N/A |
| [LADDER: Self-Improving LLMs Through Recursive Problem Decomposition](https://arxiv.org/abs/2503.00735) | akiray1, TamasSimonds | - This paper introduces LADDER (Learning through Autonomous Difficulty-Driven Example Recursion), a framework that enables Large Language Models (LLMs) to improve their problem-solving abilities by recursively generating and solving easier versions of complex problems. - Unlike prior approaches requiring curated datasets or human feedback, LADDER leverages the model's existing capabilities to generate easier question variants and uses reinforcement learning with a verifiable reward system to guide learning. - LADDER improved Llama 3.2 3B's accuracy on undergraduate-level integration problems from 1% to 82% and enabled Qwen2.5 7B to achieve 73% on the MIT Integration Bee qualifying exam. - The paper also introduces Test-Time Reinforcement Learning (TTRL), which further improves the model's performance to 90% on the MIT Integration Bee by dynamically generating and learning from problem variants during inference. - The results demonstrate self-directed learning can achieve significant capability improvements without relying on architectural scaling or human supervision. | ['Reinforcement Learning', 'Natural Language Processing', 'Question Answering'] | N/A | N/A |
| [Wikipedia in the Era of LLMs: Evolution and Risks](https://arxiv.org/abs/2503.02879) | Yao Wan, fjchendp, mgeng, sdzzxyl, hsm316 | - This paper analyzes the impact of Large Language Models (LLMs) on Wikipedia content and downstream NLP tasks. - It quantifies LLM influence on Wikipedia pages across categories, analyzes word usage changes, and examines LLM-generated content's effects on machine translation and Retrieval-Augmented Generation (RAG). - Findings reveal a potential decline in page views for certain Wikipedia categories, limited but increasing LLM influence on article content, potential inflation of machine translation benchmark scores, and decreased RAG effectiveness with LLM-generated content. - Simulations estimate a 1-2% LLM impact in some Wikipedia categories, suggesting a growing influence over time. - The study highlights the need for careful assessment of potential risks associated with LLMs' growing impact on Wikipedia and NLP research. | ['Natural Language Processing', 'Question Answering'] | [Link](https://github.com/HSM316/LLM_Wikipedia) | N/A |
| [MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents](https://arxiv.org/abs/2503.01935) | mikewang, ShuyiGuo, Thomas-X-Yang, zhaochenhong, Leozkl | - MultiAgentBench, a comprehensive benchmark designed to evaluate LLM-based multi-agent systems across diverse interactive scenarios, capturing both collaborative and competitive dynamics, is introduced. - The benchmark employs novel milestone-based key performance indicators (KPIs) to measure not only task completion but also the quality of collaboration and competition. - Various coordination protocols, including star, chain, tree, and graph topologies, as well as innovative strategies like group discussion and cognitive planning, are evaluated within the framework. - Notably, gpt-4o-mini achieves the highest average task score, the graph structure performs best among coordination protocols in research scenarios, and cognitive planning improves milestone achievement rates by 3%. - Agents exhibit emergent social behaviors, including strategic information sharing and trust-polarized collaboration, providing insights into AGI-level collaboration. | ['Natural Language Processing', 'Reinforcement Learning'] | [Link](https://github.com/MultiagentBench/MARBLE) | N/A |
| [PipeOffload: Improving Scalability of Pipeline Parallelism with Memory Optimization](https://arxiv.org/abs/2503.01328) | Min Lin, Xinyi Wan, JialinLi, huanggx-sea, QPHutu | - PipeOffload is a novel pipeline schedule designed to optimize memory and throughput for training large language models (LLMs). - It leverages memory offloading to the host, capitalizing on the natural gap between the forward and backward passes in pipeline parallelism, to reduce peak activation memory by up to 4x with minimal throughput loss, compared to interleaved 1F1B. - It introduces a selective offload strategy which prioritizes activations with longer lifespans, allowing for further peak memory optimization. - In settings with limited memory constraints, it extends the interleaving strategy into a more generalized form to manage the trade-off between memory and throughput, enabling flexible performance adjustments. - By significantly decreasing the memory footprint, PipeOffload enables the exclusive utilization of pipeline parallelism for training large models, surpassing the performance of existing hybrid parallelism approaches that combine pipeline and tensor parallelism by 12%-19%. | ['Natural Language Processing'] | [Link](https://github.com/sail-sg/zero-bubble-pipeline-parallelism) | N/A |
| [Iterative Value Function Optimization for Guided Decoding](https://arxiv.org/abs/2503.02368) | Ruizhe Chen, jokephp, ab3223323, lljhbxt, zhliu | - This paper proposes Iterative Value Function Optimization (IVO), a novel framework for enhancing guided decoding in large language models (LLMs). - IVO combines Monte Carlo Value Estimation with Iterative On-Policy Optimization, improving the accuracy and exploration capabilities of the value function, which guides text generation. - Experimental results across summarization, multi-turn dialogue, and instruction-following tasks demonstrate IVO's superior performance compared to existing baselines like FUDGE, VAS, ARGS, DPO, and IPO. - IVO achieves 77.52% win-rate against the base policy in multi-turn dialogue as judged by GPT-4, showcasing improved alignment. - IVO enhances safety against adversarial jailbreak attacks and demonstrates strong value function transferability across different model sizes. | ['Natural Language Processing', 'Text Generation'] | N/A | N/A |
| [FR-Spec: Accelerating Large-Vocabulary Language Models via Frequency-Ranked Speculative Sampling](https://arxiv.org/abs/2502.14856) | yuxuanli, zwl96, hyx21, ThonyPan, Achazwl | - FR-Spec, a frequency-ranked speculative sampling framework, is introduced to accelerate large-vocabulary language model (LLM) generation by optimizing draft candidate selection. - FR-Spec compresses the vocabulary space by constraining the draft search to a frequency-prioritized token subset, thereby reducing the computational overhead of the language modeling (LM) head. - This method reduces LM Head computation by 75% while maintaining the equivalence of the final output distribution to the original sampling method. - Experiments demonstrate an average of 1.12x speedup over EAGLE-2, the state-of-the-art speculative sampling method, and a 1.08x speedup over Medusa when integrated with FR-Spec. - The paper shows that FR-Spec supports both greedy decoding and random sampling and provides analysis of the tradeoff between drafting accuracy and time. | ['Natural Language Processing', 'Text Generation'] | N/A | N/A |
| [SemViQA: A Semantic Question Answering System for Vietnamese Information Fact-Checking](https://arxiv.org/abs/2503.00955) | Thanh T. Tran, ThanhDi, TienAnh, xuandin, DavidNguyen | - SemViQA, a novel Vietnamese fact-checking framework, combines Semantic-based Evidence Retrieval (SER) and Two-step Verdict Classification (TVC) to enhance accuracy and efficiency in misinformation detection. - SER integrates TF-IDF for fast keyword matching and a Question Answering Token Classifier (QATC) for deeper semantic analysis, balancing speed and precision in evidence retrieval. - TVC employs a hierarchical classification approach, first categorizing claims into Supported, Refuted, or Not Enough Information (NEI), then refining hard cases with a binary classifier using Focal Loss. - Data processing optimizes long-token sequence handling, addressing limitations of Transformer-based models, crucial for capturing context in complex claims. - Evaluation on ISE-DSC01 and ViWikiFC datasets shows state-of-the-art performance with 78.97% and 80.82% strict accuracy, respectively, outperforming existing baselines and demonstrating its effectiveness in Vietnamese fact verification. | ['Question Answering', 'Natural Language Processing'] | [Link](https://github.com/DAVID-NGUYEN-S16/SemViQA) | N/A |
| [UFO: A Unified Approach to Fine-grained Visual Perception via Open-ended Language Interface](https://arxiv.org/abs/2503.01342) | windmillknight, Shawnee-bxy, Haiyang-W, chenweix7, kanashi6 | - UFO, a unified framework, integrates fine-grained visual perception tasks, such as object detection and image segmentation, with open-ended language interfaces, eliminating the need for task-specific decoders. - The framework leverages a novel embedding retrieval approach for segmentation, treating the text embedding of a mask token as a query to retrieve corresponding visual features, thereby generating masks. - For tasks requiring multiple predictions, like object detection, UFO employs a parallel decoding strategy with local visual features acting as prompts, enhancing efficiency and scalability. - Evaluated on a multi-task benchmark, UFO surpasses the previous state-of-the-art generalist model, GiT, by significant margins, specifically 12.3 mAP on COCO instance segmentation and 3.3 mIoU on ADE20K semantic segmentation. - This unified approach streamlines the integration of fine-grained visual perception within multimodal large language models (MLLMs), enabling broader applications and more complex tasks, such as reasoning segmentation. | ['Multimodal', 'Object Detection', 'Image Segmentation', 'Computer Vision'] | [Link](https://github.com/nnnth/UFO) | N/A |
| [Language Models can Self-Improve at State-Value Estimation for Better Search](https://arxiv.org/abs/2503.02878) | rittera, emendes3 | - This paper introduces self-taught lookahead (STL), a self-supervised method that leverages state-transition dynamics to train a value model for language model-controlled search, eliminating the need for ground truth rewards or human demonstrations. - STL improves value estimation by fine-tuning an LLM value model on examples generated through single-step lookahead during tree search, incorporating the next best action, resulting state, rationale, and value. - Experiments on WebShop and Game-of-24 demonstrate that STL significantly improves performance compared to base LLM value models, matching or exceeding the performance of larger models like GPT-40. - STL achieves Pareto optimality in terms of cost and environment usage, showing a 37x cost reduction and significant state reduction compared to MCTS methods while outperforming previous LLM tree search approaches. - Analysis of scaling trends reveals that STL effectively improves value estimation even with smaller language models (<3 billion parameters). | ['Natural Language Processing', 'Reinforcement Learning'] | [Link](https://github.com/ethanm88/self-taught-lookahead) | N/A |
| [SPIDER: A Comprehensive Multi-Organ Supervised Pathology Dataset and Baseline Models](https://arxiv.org/abs/2503.02876) | Ekaterina Ivanova, alpchel, mgvz | - SPIDER (Supervised Pathology Image-DEscription Repository) is introduced as the largest publicly available patch-level dataset for multi-organ histopathology, including Skin, Colorectal, and Thorax, with comprehensive class coverage and expert-verified annotations. - The dataset includes context patches surrounding each central 224x224px patch at 20x magnification, enhancing classification performance by providing spatial context and mitigating challenges in distinguishing features like fat from background solely from the central patch. - Baseline models trained on SPIDER utilize the Hibou-L foundation model as a feature extractor and an attention-based classification head, achieving state-of-the-art performance across the included tissue categories. - These models serve as benchmarks and enable rapid identification of significant areas, quantitative tissue metric calculation, and act as a foundation for multimodal approaches. - Both SPIDER and the trained models are open-sourced to foster collaboration, reproducibility, and advancement in digital pathology. | ['Image Classification', 'Image Segmentation', 'Multimodal', 'Image Feature Extraction'] | [Link](https://github.com/HistAI/SPIDER) | N/A |
| [Q-Eval-100K: Evaluating Visual Quality and Alignment Level for Text-to-Vision Content](https://arxiv.org/abs/2503.02357) | Zicheng Zhang, GTZhai, a9108, sl2782087, wcain | - This paper introduces Q-Eval-100K, the largest text-to-vision evaluation dataset with mean opinion scores (MOS), containing 100K instances (60K images and 40K videos) and 960K human annotations focused on visual quality and alignment. - The authors propose Q-Eval-Score, a unified model that leverages large multimodal models (LMMs) and a context prompt learning approach for decoupled evaluation of visual quality and alignment. - For enhanced alignment evaluation with long prompts, a Vague-to-Specific strategy is introduced, where prompts are separated into core and detailed variants for more accurate scoring via weighted averaging. - Experimental results show Q-Eval-Score outperforms existing methods on Q-Eval-100K, achieving high correlation with human evaluations. - Cross-dataset validation demonstrates strong generalization capabilities of the model and the value of the Q-Eval-100K dataset. | ['Text-to-Image', 'Text-to-Video', 'Multimodal'] | [Link](https://github.com/zzc-1998/Q-Eval) | N/A |
| [IterPref: Focal Preference Learning for Code Generation via Iterative Debugging](https://arxiv.org/abs/2503.02783) | Ruihang, yangyu90, Jianwen2003, CharonBony, Ringo1110 | - IterPref, a novel framework for preference learning in Code LLMs, leverages iterative debugging insights to refine code generation. - Unlike existing methods that rely solely on pass rates for preference pairs, IterPref contrasts critical tokens between corrected and previous versions to pinpoint specific errors. - A new iterative debugging dataset, CodeFlow, is introduced, where samples are refined until tests pass, capturing error corrections for informative preference pair generation. - IterPref incorporates a tailored DPO algorithm that masks non-critical tokens in the dispreferred sample, improving fine-grained alignment. - Experimental results demonstrate that IterPref achieves significant performance gains on coding benchmarks, including BigCodeBench, and generates code with fewer errors. | ['Natural Language Processing', 'Text Generation', 'Text2Text Generation'] | N/A | N/A |
| [AppAgentX: Evolving GUI Agents as Proficient Smartphone Users](https://arxiv.org/abs/2503.02268) | Chi Zhang, Wenjia Jiang, xuyang, ChenxiSong, yyzhuang2 | - AppAgentX, a novel evolutionary framework for GUI agents, enhances operational efficiency while retaining intelligence and flexibility in interacting with graphical user interfaces (GUIs). - It incorporates a memory mechanism to record task execution history and identify repetitive action sequences, which are then replaced with higher-level actions to create shortcuts and improve performance.  - This approach allows the agent to focus on complex reasoning tasks while streamlining routine actions. - Experimental results demonstrate AppAgentX's significant outperformance over existing methods in both efficiency and accuracy on multiple benchmark tasks such as AppAgent, DroidTask, and MobileBench. - The framework utilizes visual information, eliminating the need for backend access or APIs, and leverages GPT-4, LangGraph, Neo4j, Pinecone, and ResNet-50 for its core components. | ['Multimodal'] | N/A | N/A |
