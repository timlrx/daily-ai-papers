

## Papers for 2025-03-21

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [Stop Overthinking: A Survey on Efficient Reasoning for Large Language
  Models](https://arxiv.org/abs/2503.16419) | andrewwen, HongyiLiuAI, jy-yuan, JiamuZhang, yangsui | - This paper surveys efficient reasoning methods for Large Language Models (LLMs), categorizing them into model-based, reasoning output-based, and input prompts-based approaches. - Model-based methods optimize or train LLMs for conciseness, while output-based methods dynamically reduce reasoning steps during inference, and prompt-based methods leverage prompt properties for efficiency. - The paper also discusses efficient data utilization, reasoning in smaller models, and evaluation methods. - It introduces Sys2Bench for evaluating LLMs across various reasoning tasks and frameworks to assess "overthinking."  - The survey highlights the practical benefits of efficient reasoning across diverse domains like healthcare, autonomous driving, and embodied AI, emphasizing the importance of balancing reasoning quality with computational efficiency. | ['Natural Language Processing', 'Question Answering'] | [Link](https://github.com/Eclipsess/Awesome-Efficient-Reasoning-LLMs) | N/A |
| [Survey on Evaluation of LLM-based Agents](https://arxiv.org/abs/2503.16416) | Yilun Zhao, Guy Uziel, Lilach Eden, lihaoxin2020, Asaf-Yehudai | - This paper presents the first comprehensive survey of evaluation methodologies for Large Language Model (LLM)-based agents. - The survey analyzes evaluation benchmarks and frameworks across four dimensions: fundamental agent capabilities, application-specific benchmarks, generalist agent benchmarks, and agent evaluation frameworks. - The paper identifies emerging trends in agent evaluation, including a shift towards more realistic and challenging evaluations using continuously updated benchmarks. - It also highlights critical gaps in current evaluation methods, particularly in assessing cost-efficiency, safety, and robustness, and in developing fine-grained and scalable methods. - The survey aims to provide a comprehensive overview of the current state of agent evaluation and guide future research by suggesting several promising directions. | ['Natural Language Processing', 'Question Answering'] | N/A | [Link](https://huggingface.co/spaces/galileo-ai/agent-leaderboard) |
| [Cosmos-Reason1: From Physical Common Sense To Embodied Reasoning](https://arxiv.org/abs/2503.15558) | Hannah Brandon, Alisson Azzolini, NVIDIA, zhuoliny, fferroni | - NVIDIA introduces Cosmos-Reason1, a multimodal large language model family (8B and 56B parameter versions) specializing in physical reasoning, trained to perceive, understand, and generate embodied decisions based on video input using a long chain-of-thought process. - The model architecture employs a decoder-only multimodal approach, where video input is processed by a vision encoder and aligned with text embeddings before being fed into a hybrid Mamba-MLP-Transformer LLM. - Training occurs in four stages: vision pre-training, general supervised fine-tuning (SFT), Physical AI SFT, and Physical AI reinforcement learning (RL), using curated datasets focusing on physical common sense and embodied reasoning, including specialized intuitive physics datasets.  - Evaluation on new benchmarks tailored for physical common sense and embodied reasoning shows significant performance improvements over existing models, especially after Physical AI SFT and RL, with the 56B model outperforming OpenAI 01 on the common sense benchmark. - The authors plan to open-source the code and open-weight the models. | ['Video-Text-to-Text', 'Multimodal', 'Reinforcement Learning', 'Robotics', 'Visual Question Answering'] | [Link](https://github.com/nvidia-cosmos/cosmos-reason1) | N/A |
| [MathFusion: Enhancing Mathematic Problem-solving of LLM through
  Instruction Fusion](https://arxiv.org/abs/2503.16212) | Honglin Lin, Yu Li, Zhuoshi Pan, Lijun Wu, Qizhi Pei | - MathFusion, a novel framework, enhances mathematical reasoning in Large Language Models (LLMs) by fusing different mathematical problems through instruction synthesis, focusing on leveraging the relationships between problems rather than simply modifying individual instances. - Three fusion strategies are introduced: sequential fusion (chaining related problems), parallel fusion (combining analogous problems), and conditional fusion (creating context-aware selective problems). - MathFusionQA, a new dataset, is created by applying these strategies and fine-tuning various LLMs (DeepSeekMath-7B, Mistral-7B, Llama3-8B). - Experimental results demonstrate substantial performance gains, boosting accuracy by 18.0 points across benchmarks using only 45K additional synthetic instructions compared to traditional single-instruction approaches. - MathFusion's high data efficiency is further highlighted by its superior performance when combined with the state-of-the-art DART-Math, exceeding its accuracy by 1.4 points with less data. | ['Natural Language Processing', 'Question Answering'] | [Link](https://github.com/QizhiPei/mathfusion) | N/A |
| [Plug-and-Play 1.x-Bit KV Cache Quantization for Video Large Language
  Models](https://arxiv.org/abs/2503.16257) | Huan Wang, Can Qin, Yang Sui, Haoxuan You, KD-TAO | - VidKV, a plug-and-play quantization method, compresses the key-value (KV) cache in Video Large Language Models (VideoLLMs) to lower than 2-bit precision without fine-tuning. - It employs a mixed-precision quantization strategy for the key cache, using 2-bit quantization for anomalous channels and 1-bit quantization combined with Fast Fourier Transform (FFT) for normal channels. - For the value cache, VidKV implements 1.58-bit quantization with an optional semantic token protection mechanism to preserve critical visual tokens at 2-bit precision. - Extensive experiments on six video benchmarks with LLaVA-OV-7B and Qwen2.5-VL-7B demonstrate that VidKV compresses KV cache to 1.5-bit and 1.58-bit with negligible performance drop compared to FP16. - The results show that per-channel quantization is more effective for the value cache in VideoLLMs, contrary to previous findings in LLMs that favor per-token quantization. | ['Multimodal', 'Video-Text-to-Text'] | [Link](https://github.com/KD-TAO/VidKV) | N/A |
| [JARVIS-VLA: Post-Training Large-Scale Vision Language Models to Play
  Visual Games with Keyboards and Mouse](https://arxiv.org/abs/2503.16365) | Yitao Liang, Xiaojian Ma, Kaichen He, Zihao Wang, Muyao Li | - Introduces JARVIS-VLA, a Vision-Language-Action (VLA) model trained with a novel Act from Visual Language Post-Training (ActVLP) paradigm.  - JARVIS-VLA is a non-Markovian model that uses a history of observations in its prompts, and employs an action decoder to output discrete and continuous actions. - ActVLP enhances VLMs with visual and linguistic guidance in a self-supervised manner before imitation learning, significantly improving performance on a variety of tasks. - Achieves state-of-the-art performance in Minecraft, surpassing traditional imitation learning-based policies and showing a 40% improvement over baseline agents on atomic tasks like crafting, smelting, and mining. - Open-sourced code, models, and datasets to facilitate further research.  | ['Reinforcement Learning', 'Robotics', 'Multimodal'] | N/A | N/A |
| [CaKE: Circuit-aware Editing Enables Generalizable Knowledge Learners](https://arxiv.org/abs/2503.16356) | Shumin Deng, Jia-Chen Gu, Jizhan Fang, Yunzhi Yao, Ningyu | - CaKE (Circuit-aware Knowledge Editing) is introduced, a novel method designed to improve the generalization of knowledge edits in Large Language Models (LLMs) for multi-hop reasoning tasks. - CaKE leverages circuit-aware training data, which explicitly requires the LLM to reason with the updated knowledge, guiding the model to construct robust reasoning circuits. - This approach addresses the limitations of existing KE methods that often struggle to integrate updates into the multi-hop reasoning process. - Experimental results on the MQUAKE dataset demonstrate that CaKE significantly improves multi-hop reasoning accuracy, achieving an average of 20% improvement compared to existing KE methods. - CaKE's effectiveness is shown across various LLMs, including LLAMA3-8B-Instruct, Qwen2.5-7B-Instruct, and LLAMA3-70B-Instruct, showcasing its adaptability to different model sizes. | ['Natural Language Processing', 'Question Answering'] | [Link](https://github.com/zjunlp/CaKE) | N/A |
| [Why Do Multi-Agent LLM Systems Fail?](https://arxiv.org/abs/2503.13657) | Bhavya Chopra, Lakshya A. Agrawal, Shuyi Yang, Melissa Z. Pan, Mert Cemri | - This paper presents MASFT, the first comprehensive taxonomy of failure modes in Multi-Agent Large Language Model (LLM) systems. - The study analyzes five popular MAS frameworks across 150 tasks, using human annotations to identify 14 distinct failure modes categorized into specification and system design, inter-agent misalignment, and task verification. - An LLM-as-a-judge pipeline is introduced for scalable automated failure mode detection and achieves 94% accuracy and 0.77 Cohen's Kappa score against human annotations. - Interventions, including improved role specifications and enhanced orchestration, show a 14% improvement in one framework but don't resolve all failures, highlighting the need for more complex solutions. - The research emphasizes the importance of organizational understanding in MAS design and releases the dataset and LLM annotator as open-source resources. | ['Natural Language Processing'] | [Link](https://github.com/multi-agent-systems-failure-taxonomy/MASFT) | N/A |
| [M3: 3D-Spatial MultiModal Memory](https://arxiv.org/abs/2503.16413) | Jianglong Ye, Xuanbin Peng, Ri-Zhao Qiu, Yuchen Song, Xueyan Zou | - M3, a 3D spatial multimodal memory system, is introduced, integrating 3D Gaussian Splatting with foundation models to store multimodal memories efficiently. - It addresses two key limitations of previous feature splatting approaches: the computational constraints of storing high-dimensional features and misalignment or information loss between distilled and original features. - M3 introduces principal scene components and Gaussian memory attention, enabling efficient processing and high fidelity rendering. - Comprehensive quantitative evaluations of feature similarity, downstream tasks, and qualitative visualizations confirm M3's superiority in memorization and downstream tasks. - M3 has been successfully deployed on a real-world quadruped robot for grasping tasks, showcasing its potential for real-world applications. | ['Multimodal', 'Computer Vision', 'Image Feature Extraction'] | [Link](https://github.com/MaureenZOU/m3-spatial) | N/A |
| [XAttention: Block Sparse Attention with Antidiagonal Scoring](https://arxiv.org/abs/2503.16428) | Song Han, Junxian Guo, Guangxuan Xiao, Ruyi Xu, songhan | - XAttention is a plug-and-play framework that accelerates long-context inference in Transformer models using sparse attention by summing antidiagonal values in the attention matrix to determine block importance. - Unlike existing methods relying on computationally intensive solutions, XAttention uses this simple, efficient scoring method to identify and prune non-essential blocks, leading to high sparsity and accelerated inference without sacrificing accuracy. - Across benchmarks like RULER, LongBench, VideoMME, and VBench, XAttention achieves accuracy comparable to full attention while significantly reducing computational costs, demonstrating up to 13.5x acceleration in attention computation. - This method effectively balances accuracy and efficiency and unlocks the practical potential of block sparse attention. - XAttention paves the way for scalable and efficient deployment of Long-Context Transformer Models (LCTMs) in real-world applications. | ['Natural Language Processing', 'Video Classification', 'Video-Text-to-Text', 'Multimodal', 'Question Answering', 'Text Generation', 'Text-to-Video'] | [Link](https://github.com/mit-han-lab/x-attention) | N/A |
| [CLS-RL: Image Classification with Rule-Based Reinforcement Learning](https://arxiv.org/abs/2503.16188) | Kaipeng Zhang, Jike Zhong, Ming Li, yuxianglai117, stzhao | - CLS-RL, a novel rule-based reinforcement learning framework, is proposed for few-shot image classification fine-tuning of Multimodal Large Language Models (MLLMs), addressing the catastrophic forgetting issues encountered in supervised fine-tuning. - CLS-RL utilizes verifiable signals (class names) as rewards and formats rewards to encourage models to think before answering, demonstrating superior performance compared to supervised fine-tuning in most datasets across both base-to-new generalization and few-shot learning settings. - A "free-lunch" phenomenon is observed with CLS-RL, where fine-tuning on one dataset enhances performance on other distinct datasets, suggesting that RL effectively teaches models the fundamentals of image classification. - No-Thinking-CLS-RL, a variant minimizing the thinking process during training through an equality accuracy reward, achieves better in-domain performance and generalization capabilities than CLS-RL with less fine-tuning time. - The paper explores the role of the thinking process during RL fine-tuning for visual classification, finding it potentially less critical than previously assumed, and suggests that for simple visual tasks extensive thinking might be detrimental. | ['Image Classification', 'Reinforcement Learning', 'Multimodal', 'Zero-Shot Image Classification'] | N/A | N/A |
| [Fin-R1: A Large Language Model for Financial Reasoning through
  Reinforcement Learning](https://arxiv.org/abs/2503.16252) | Jinyi Niu, Lingfeng Zeng, Fangqi Lou, Xin Guo, Zhaowei Liu | - This paper introduces Fin-R1, a 7-billion parameter large language model designed for financial reasoning, addressing the challenges of fragmented data, opaque reasoning, and weak generalization in financial AI. - Fin-R1 leverages a two-stage training process: Supervised Fine-Tuning (SFT) on a new dataset, Fin-R1-Data, followed by Reinforcement Learning (RL) using Group Relative Policy Optimization (GRPO). - Fin-R1-Data consists of 60,091 Chain-of-Thought (CoT) examples derived and filtered from a combination of public and proprietary financial datasets. - In evaluations, Fin-R1 achieves state-of-the-art results on ConvFinQA (85.0) and FinQA (76.0), and strong performance across other financial benchmarks, outperforming larger models like DeepSeek-R1-Distill-Llama-70B. - The model shows promising real-world applications in financial compliance and robo-advisory. | ['Natural Language Processing', 'Question Answering', 'Reinforcement Learning'] | [Link](https://github.com/SUFE-AIFLM-Lab/Fin-R1) | N/A |
| [Make Your Training Flexible: Towards Deployment-Efficient Video Models](https://arxiv.org/abs/2503.14237) | Yi Wang, Xiangyu Zeng, Tianxiang Jiang, Kunchang Li, Chenting Wang | - This paper introduces Flux, a new data augmentation tool and training approach for video models that optimizes performance across various computational budgets and spatiotemporal resolutions. - Flux employs flexible sampling and token selection to maximize input information, enabling training of flexible models. - FluxViT, trained using Flux, achieves state-of-the-art results on standard video classification benchmarks like K400 and Something-Something V2. - Notably, FluxViT matches or exceeds prior state-of-the-art performance while using significantly fewer tokens (1/4 to 1/2), leading to substantial computational savings (70% to 95%). - It also shows robust performance on multi-modal tasks, especially in chat-centric applications including video captioning and question answering. | ['Computer Vision', 'Video Classification', 'Multimodal', 'Video-Text-to-Text'] | [Link](https://github.com/OpenGVLab/FluxViT) | N/A |
| [Reinforcement Learning for Reasoning in Small LLMs: What Works and What
  Doesn't](https://arxiv.org/abs/2503.16219) | Chris Ngo, quyanh | - This paper explores Reinforcement Learning (RL) for improving reasoning in small Large Language Models (LLMs), specifically a 1.5B parameter model (DeepSeek-R1-Distill-Qwen-1.5B), under limited resources (4 NVIDIA A40 GPUs for 24 hours). - The study uses a curated dataset of mathematical problems and adapts the Group Relative Policy Optimization (GRPO) algorithm for resource efficiency. - Results show significant improvement in reasoning performance with minimal resources: accuracy on AMC23 rose from 63% to 80%, and AIME24 reached 46.7%, outperforming larger models like o1-preview. - Key challenges include optimization instability, length constraints, and language drift with prolonged training, suggesting a need for more robust training strategies and potentially longer sequence lengths. - Code and data are released to foster further research into computationally efficient enhancement of small LLMs, promoting wider accessibility to advanced reasoning capabilities. | ['Reinforcement Learning', 'Natural Language Processing', 'Question Answering'] | [Link](https://github.com/knoveleng/open-rs) | [Link](https://huggingface.co/datasets/AI-MO/aimo-validation-aime), [Link](https://huggingface.co/datasets/AI-MO/aimo-validation-amc) |
| [Deceptive Humor: A Synthetic Multilingual Benchmark Dataset for Bridging
  Fabricated Claims with Humorous Content](https://arxiv.org/abs/2503.16031) | Sunil Saumya, Shankar Biradar, UVSKKR | - This paper introduces the Deceptive Humor Dataset (DHD), a synthetic multilingual benchmark dataset designed for studying humor derived from fabricated claims and misinformation. - DHD consists of humor-infused comments generated from false narratives using ChatGPT-40, labeled with satire levels and categorized into distinct humor types. - The dataset spans multiple languages, including English and several Indian languages, along with their code-mixed variations, addressing the gap in regional language resources for humor detection. - The authors established baseline results using various transformer-based models and large language models for both satire level and humor attribute classification tasks, providing a benchmark for future research. - Results suggest that while existing models perform well on standard humor detection or misinformation classification individually, they struggle with the combined challenge of deceptive humor, highlighting the need for new research in this direction. | ['Natural Language Processing', 'Text Classification'] | N/A | N/A |
| [BigO(Bench) -- Can LLMs Generate Code with Controlled Time and Space
  Complexity?](https://arxiv.org/abs/2503.15242) | Gabriel Synnaeve, Benoit Sagot, Baptiste Roziere, pierrechambon | - This paper introduces BigO(Bench), a novel coding benchmark designed to evaluate the ability of Large Language Models (LLMs) to generate code that adheres to specific time and space complexity constraints. - The benchmark includes tooling to infer the time and space complexity of Python code, a dataset of 3,105 coding problems with inferred complexity labels and 1.2M solutions, and an evaluation framework. - Results from evaluating several state-of-the-art LLMs reveal that, despite their impressive performance in generating functional code, most struggle to meet specified time and space complexity constraints, hinting that they may not generalize well to tasks without specific reward at training. - Token-space reasoning models, while superior in code generation tasks, show limitations in complexity understanding. - DeepSeek R1 Llama 70B achieves the highest scores on most aspects of the benchmark (41.4% and 4.8% All@1 on complexity prediction and generation respectively), with Llama 3.1 405B excelling at space complexity prediction (10.3%). | ['Natural Language Processing', 'Text Generation', 'Text2Text Generation'] | [Link](https://github.com/facebookresearch/bigobench) | [Link](https://huggingface.co/datasets/facebook/BigOBench) |
| [See-Saw Modality Balance: See Gradient, and Sew Impaired Vision-Language
  Balance to Mitigate Dominant Modality Bias](https://arxiv.org/abs/2503.13834) | YoungBin Kim, Juhwan Choi, Eunju Lee, MiHyeon Kim, JuneHyoung Kwon | - This paper introduces BALGRAD, a novel framework designed to mitigate dominant modality bias in vision-language (VL) models by balancing gradients between modalities and ensuring stable convergence and balanced learning. - BALGRAD employs two key components: inter-modality gradient reweighting, which adjusts the gradient magnitude of the KL divergence term based on each modality's contribution, and inter-task gradient projection, which prevents conflicts between gradients that can hinder balanced learning.   - The authors theoretically demonstrate that unbalanced loss reduction can result from conflicting directions or significantly different magnitudes of the gradients between modalities.   - Experimental results on UPMC Food-101, Hateful Memes, and MM-IMDb datasets show that BALGRAD effectively reduces the performance gap between modalities under different impaired conditions (missing/noisy data) and avoids negative transfer.  - BALGRAD achieves superior performance by balancing modality contributions and improving robustness, as demonstrated by achieving the highest Avg. performance and the smallest gap in experiments with impaired modalities across the datasets. | ['Multimodal'] | N/A | N/A |
