

## Papers for 2025-03-25

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [I Have Covered All the Bases Here: Interpreting Reasoning Features in
  Large Language Models via Sparse Autoencoders](https://arxiv.org/abs/2503.18878) | Polina Druzhinina, Andrey Galichin, tlenusik, razzant, therem | - This paper introduces a methodology for identifying reasoning-specific features within Large Language Models (LLMs) using Sparse Autoencoders (SAEs). - The authors propose ReasonScore, a metric designed to pinpoint SAE features associated with reasoning by analyzing their activation patterns on a curated vocabulary of introspective terms. - Through empirical analysis, an automatic interpretability pipeline, and controlled feature steering experiments, they demonstrate a direct correlation between the identified features and the model's reasoning capabilities. - Notably, amplifying these features leads to enhanced reasoning performance on benchmarks like AIME 2024, MATH-500, and GPQA Diamond, providing mechanistic evidence for the role of specific LLM components in complex cognitive behaviors. - The results show that steering certain features systematically enhances structured reasoning in model outputs, offering an initial mechanistic explanation of reasoning in LLMs. | ['Natural Language Processing', 'Question Answering', 'Feature Extraction'] | [Link](https://github.com/AIRI-Institute/SAE-Reasoning) | N/A |
| [LEMMA: Learning from Errors for MatheMatical Advancement in LLMs](https://arxiv.org/abs/2503.17439) | mingchenlin2025, Word2Li, QizhiPei, LHL3341, panzs | - LEMMA, a novel method to enhance LLMs' reflective reasoning by constructing and learning from error-corrective trajectories, is proposed. - LEMMA systematically analyzes model-generated error types and introduces an error-type grounded mistake augmentation method to collect diverse and representative errors. - The model is fine-tuned on error-corrective trajectories, enabling it to self-correct errors within the generation process without relying on external critique models. - Experimental results on mathematical reasoning benchmarks show LEMMA achieves state-of-the-art performance, outperforming standard SFT baselines and prior error-aware methods. - LEMMA-trained models also exhibit strong generalization ability on out-of-distribution benchmarks and can consistently reduce the occurrence of representative error types. | ['Natural Language Processing', 'Question Answering'] | [Link](https://github.com/pzs19/LEMMA) | N/A |
| [Judge Anything: MLLM as a Judge Across Any Modality](https://arxiv.org/abs/2503.17489) | shuang72, Frywind, NiuniuWang, yuhangchen, fjchendp | - This paper introduces two benchmarks, TASKANYTHING and JUDGEANYTHING, for evaluating and assessing the capabilities of Multimodal Large Language Models (MLLMs) as judges across various modalities (image, text, audio, video) in understanding and generation tasks. - TASKANYTHING is a benchmark consisting of 1,500 open-ended queries across 15 any-to-any modality categories, accompanied by human annotations and model-generated responses. - JUDGEANYTHING evaluates MLLMs' judging ability across the same modalities using pair comparison and score evaluation settings against human judgments and detailed checklists. - Experiments with advanced MLLMs like GPT-40 and Gemini show promising results in assessing multimodal understanding tasks but significant challenges in assessing generation tasks, revealing cross-modality biases and hallucination issues. - The authors also present OMNIARENA, an automated evaluation platform for omni-models and multimodal reward models based on these benchmarks to further improve any-to-any multimodal models. | ['Any-to-Any', 'Multimodal'] | [Link](https://urrealhero.github.io/judgeanythingweb/) | N/A |
| [FFN Fusion: Rethinking Sequential Computation in Large Language Models](https://arxiv.org/abs/2503.18908) | geifmany, AmnonGeifman, omripuny, mdabbah-nvidia, abercovich | - This paper introduces FFN Fusion, a novel architectural optimization designed to reduce sequential computation in large language models (LLMs) by parallelizing Feed-Forward Network (FFN) layers. - The key insight is that consecutive FFN layers, especially those prevalent after attention pruning, can be fused into a single, wider layer, facilitating parallel execution and minimizing synchronization overhead. - This method is evaluated on Llama-3.1-405B-Instruct, resulting in a new model called Llama-Nemotron-Ultra-253B-Base, which achieves a 1.71x speedup and 35x lower per-token cost while maintaining comparable performance. - Experiments across various model sizes (49B to 253B parameters) demonstrate that FFN Fusion's effectiveness increases with scale and complements existing techniques like quantization and pruning. - The paper also presents preliminary findings suggesting that full transformer blocks (including both attention and FFN layers) can sometimes be parallelized, which opens new avenues for LLM architecture design. | ['Natural Language Processing', 'Text Generation'] | N/A | N/A |
| [Video SimpleQA: Towards Factuality Evaluation in Large Video Language
  Models](https://arxiv.org/abs/2503.18923) | Pengfei Hu, zhangysk, Drexubery, grejioh, mengcao | - This paper introduces Video SimpleQA, a novel benchmark designed to evaluate the factual grounding capabilities of Large Video Language Models (LVLMs). - Video SimpleQA consists of short, fact-seeking questions paired with definitive short-form answers and corresponding video clips, focusing on knowledge integration. - Unlike existing video benchmarks, Video SimpleQA necessitates external knowledge integration, promoting factual grounding rather than mere video content analysis.  - Experimental results on 41 state-of-the-art LVLMs reveal significant performance gaps, with top models reaching an F-score of only 54.4%, highlighting substantial room for improvement in video-grounded factual understanding. - The benchmark further explores test-time compute strategies and retrieval-augmented generation, revealing limitations and trade-offs in enhancing LVLMs factuality. | ['Multimodal', 'Visual Question Answering', 'Video-Text-to-Text'] | N/A | N/A |
| [AgentRxiv: Towards Collaborative Autonomous Research](https://arxiv.org/abs/2503.18102) | Samuel Schmidgall, mdmoor | - Introduces AgentRxiv, a framework for collaborative autonomous research among Large Language Model (LLM) agents, enabling them to iteratively build upon prior research findings via a shared preprint server. - Demonstrates that agents with access to past research through AgentRxiv achieve higher performance improvements (11.4% relative improvement over baseline on MATH-500) compared to isolated agents, and the best performing strategies generalize to other benchmark domains (average 3.3% improvement). - Shows that multiple agent laboratories using AgentRxiv collaborate effectively and achieve faster progress, reaching higher overall accuracy (13.7% relative improvement over baseline on MATH-500) compared to isolated labs. - Presents a parallelized mode for AgentRxiv, allowing concurrent research and faster discovery (+6.0% improvement on MATH-500 with 3 labs) but with a trade-off between speed and computational cost. - Discusses the discovered reasoning technique, Simultaneous Divergence Averaging (SDA), which yields the highest accuracy on MATH-500 (78.2%) and shows generalization across diverse benchmarks and language models. | ['Natural Language Processing'] | N/A | N/A |
| [Vision-R1: Evolving Human-Free Alignment in Large Vision-Language Models
  via Vision-Guided Reinforcement Learning](https://arxiv.org/abs/2503.18013) | Fan Yang, Hongyin Zhao, Shurong Zheng, Yousong Zhu, Yufei Zhan | - This paper introduces Vision-R1, a novel vision-guided reinforcement learning algorithm designed to improve the object localization capabilities of Large Vision-Language Models (LVLMs). - Vision-R1 uses a criterion-driven reward function based on visual feedback, eliminating the need for human-annotated preference data and specialized reward models. - It incorporates a progressive rule refinement strategy, dynamically adjusting reward criteria during training to ensure continuous model improvement and mitigate reward hacking. - Experiments on various object localization benchmarks, including in-domain and out-of-domain datasets, show that Vision-R1 significantly enhances performance, even surpassing the state-of-the-art Qwen2.5-VL-72B model on ODINW-13 by 2.5 mAP with a 10x smaller model size. - Furthermore, Vision-R1 maintains strong generalized question answering capabilities, unlike supervised fine-tuning which shows a decline in performance. | ['Multimodal', 'Object Detection', 'Reinforcement Learning'] | [Link](https://github.com/jefferyZhan/Griffon/tree/master/Vision-R1) | N/A |
| [Reasoning to Learn from Latent Thoughts](https://arxiv.org/abs/2503.18866) | Tatsunori Hashimoto, cmaddis, nband, ryoungj | - This paper proposes "reasoning to learn," a novel approach to improve data efficiency in language model (LM) pretraining by explicitly modeling and inferring latent thoughts underlying text generation. - This approach treats web text as the outcome of a compressed thought process and posits that latent thoughts have contextual knowledge important for data-efficient learning. - The authors demonstrate the effectiveness of their approach by continually pretraining a 1.1B TinyLlama model on a limited amount of data from FineMath, a reasoning-intensive web corpus, augmented with latent thoughts generated by GPT-40-mini. - Results show substantial improvements in downstream task performance compared to baselines trained on raw data and synthetic Chain-of-Thought paraphrases. - The introduced BoLT algorithm enables iterative improvement of the latent thought generator, showing gains for at least three iterations without task-specific data. | ['Natural Language Processing'] | [Link](https://github.com/ryoungj/BOLT) | N/A |
| [Defeating Prompt Injections by Design](https://arxiv.org/abs/2503.18813) | Tianqi Fan, ftramer, carlini, iliashum, dedeswim | - This paper introduces CaMeL, a new defense against prompt injection attacks in Large Language Model (LLM) agents. - CaMeL creates a protective system layer around the LLM that extracts control and data flows from trusted queries, ensuring that retrieved untrusted data does not influence program flow. - The system utilizes a custom Python interpreter to track data provenance and enforce security policies based on capabilities (metadata) attached to individual data values, enabling granular control over data and control flows. - CaMeL's effectiveness is demonstrated in AgentDojo, where it successfully completes 67% of tasks with provable security guarantees, mitigating prompt injection risks and preventing unintended data exfiltration without modifying the underlying LLM. - This approach mirrors established software security practices and offers a more robust solution compared to relying solely on LLM training or prompting for security. | ['Natural Language Processing', 'Question Answering'] | N/A | N/A |
| [Typed-RAG: Type-aware Multi-Aspect Decomposition for Non-Factoid
  Question Answering](https://arxiv.org/abs/2503.15879) | Yunho Maeng, Hyeonseo Nam, Ahjeong Park, keirahrlee, oneonlee | - Typed-RAG, a novel type-aware multi-aspect decomposition framework within the RAG paradigm, is introduced to enhance Non-Factoid Question Answering (NFQA). - Typed-RAG refines retrieval and generation strategies for different NFQ types by incorporating a pre-trained question type classifier and decomposing questions into single-aspect sub-queries. - It addresses the diverse intent and answer perspective limitations in current RAG systems by classifying NFQs into distinct types such as debate, experience, and comparison. - Experimental results on Wiki-NFQA, a new benchmark dataset for NFQA, show that Typed-RAG surpasses baseline models. - Typed-RAG demonstrates the significance of type-aware decomposition for effective retrieval and generation in NFQA by outperforming LLMs and standard RAG in capturing NFQ complexity. | ['Question Answering'] | [Link](https://github.com/TeamNLP/Typed-RAG) | N/A |
| [AlphaSpace: Enabling Robotic Actions through Semantic Tokenization and
  Symbolic Reasoning](https://arxiv.org/abs/2503.18769) | Bui Quang Huy, Dinh Bach Vu, alandao | - AlphaSpace is a novel methodology designed to improve the spatial reasoning capabilities of Large Language Models (LLMs) for robotic manipulation in 3D space. - The methodology utilizes a hierarchical, semantics-based tokenization strategy that encodes both coarse and fine-grained spatial data, including height information represented by z-coordinates. - It incorporates symbolic reasoning and synthetic data to train a decoder-only LLM architecture to understand spatial relationships and perform actions like picking, placing, and stacking objects within a simulated tabletop environment. - On the EmbodiedBench Manipulation Subtask, AlphaSpace achieves 66.67% accuracy, surpassing GPT-40 (37.5%) and Claude 3.5 Sonnet (29.17%). - The enhanced spatial tokenization method expands upon previous 2D approaches by incorporating z-axis height information, leading to more effective 3D object manipulation. | ['Robotics', 'Multimodal'] | N/A | N/A |
| [Lost in Cultural Translation: Do LLMs Struggle with Math Across Cultural
  Contexts?](https://arxiv.org/abs/2503.18018) | Jaswinder Singh, Bhoomika Lohana, Aabid Karim, 55mv, Abdul084 | - This research explores the impact of cultural context on the mathematical reasoning abilities of Large Language Models (LLMs). - Six culturally adapted versions of the GSM8K dataset were created, maintaining the original mathematical logic while changing cultural elements like names and food. - Evaluation across 14 LLMs revealed a performance drop on culturally adapted problems compared to the original GSM8K, with smaller models showing larger drops. - Interestingly, models familiar with specific cultures sometimes outperformed larger, mathematically proficient models on culturally relevant problems. - This highlights the need for more diverse training data to improve LLM robustness in real-world applications. | ['Natural Language Processing', 'Question Answering'] | [Link](https://github.com/akarim23131/Lost_in_Cultural_Translation) | N/A |
| [V-Seek: Accelerating LLM Reasoning on Open-hardware Server-class RISC-V
  Platforms](https://arxiv.org/abs/2503.17422) | Luca Benini, Daniele Jahier Pagliari, Alessio Burrello, Mohamed Amine Ahmdi, Javier J. Poveda Rodrigo | - This paper presents V-Seek, a method for optimizing Large Language Model (LLM) inference on the Sophon SG2042, a RISC-V CPU with vector processing capabilities. - The authors develop optimized and quantized kernels for key LLM layers, targeting the specific hardware features of the SG2042, including vectorization and memory infrastructure. - The work explores different compiler options (GCC and Clang) and NUMA optimization strategies to maximize performance. - Results on DeepSeek R1 Distill Llama 8B/QWEN 14B and vanilla Llama 7B demonstrate speedups of up to 3.0x and 2.8x in token generation and prompt processing, respectively, compared to baseline llama.cpp. - The optimized system achieves throughputs up to 13.07/6.54/3.68 token/s for the evaluated LLMs, showing competitive performance against incumbent x86 architecture and improvements over previous work on the SG2042. | ['Natural Language Processing', 'Question Answering'] | N/A | N/A |
| [MetaSpatial: Reinforcing 3D Spatial Reasoning in VLMs for the Metaverse](https://arxiv.org/abs/2503.18470) | Han Liu, zhenyupan | - MetaSpatial, a novel reinforcement learning (RL)-based framework, enhances 3D spatial reasoning in vision-language models (VLMs) for generating coherent and realistic 3D scenes. - It addresses the limitations of supervised fine-tuning by employing a multi-turn refinement strategy with a hybrid reward system combining format, physics, and rendering-based evaluations. - This approach uses Group Relative Policy Optimization (GRPO) to optimize the model across multiple refinement trajectories, promoting adaptable and generalizable spatial understanding. - Experimental results demonstrate that MetaSpatial significantly improves scene quality, increasing format accuracy, reducing physical violations, and enhancing perceptual realism as judged by GPT-4o. - The qualitative analysis shows more structured and realistic object placements after training, validating RL's effectiveness in 3D spatial reasoning for applications like AR/VR and metaverse design. | ['Text-to-3D', 'Reinforcement Learning', 'Multimodal'] | [Link](https://github.com/PzySeere/MetaSpatial) | N/A |
| [Verbal Process Supervision Elicits Better Coding Agents](https://arxiv.org/abs/2503.18494) | Jui-Ming Yao, Cheng-Pong Huang, MarkChenX | - This paper introduces CURA (Code Understanding and Reasoning Agent), a novel code generation framework enhanced with Verbal Process Supervision (VPS). - VPS guides language models to generate step-level reward signals for improved code generation outcomes.  - CURA with VPS improves performance by 3.65% over baseline models on BigCodeBench.  - Paired with o3-mini and VPS, CURA achieves state-of-the-art performance, indicating the effectiveness of iterative verbal process supervision in enhancing agentic reasoning.  - Deterministic decoding (temperature 0) leads to better results in code generation compared to stochastic decoding (temperature 1), as shown by Mistral Large Latest and GPT-40-mini on BigCodeBench. | ['Natural Language Processing', 'Text Generation', 'Text2Text Generation'] | N/A | N/A |
