

## Papers for 2025-04-01

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [TextCrafter: Accurately Rendering Multiple Texts in Complex Visual
  Scenes](https://arxiv.org/abs/2503.23461) | Nikai Du, yingtai, jzzzzk, Chenzzzzzz, zhen-nan | - TextCrafter is a novel training-free framework for rendering multiple texts in complex visual scenes, addressing challenges like text distortion, omission, and blurriness common in current text-to-image models. - It employs a progressive strategy with three stages: Instance Fusion strengthens the link between visual text and its carrier; Region Insulation separates and denoises text prompts in different regions, leveraging positional priors of a pre-trained DiT model; and Text Focus enhances attention maps of visual text, refining fidelity. - A new benchmark dataset, CVTG-2K, is introduced with 2,000 prompts containing complex visual texts, varying in position, quantity, length, and attributes, to rigorously evaluate models on CVTG tasks. - Quantitative experiments on CVTG-2K show TextCrafter significantly outperforms state-of-the-art models in OCR accuracy (Word Accuracy and NED) and prompt adherence (CLIPScore), improving OCR accuracy by over 45% compared to the baseline FLUX model. - Qualitative results further demonstrate TextCrafter's ability to generate harmonious images with accurate and clear multiple visual texts, even in complex scenarios, while other models struggle with omissions, confusion, and background information loss. | ['Text-to-Image', 'Multimodal'] | N/A | N/A |
| [MoCha: Towards Movie-Grade Talking Character Synthesis](https://arxiv.org/abs/2503.23307) | Luczzz, daixl1992, FelixXu, haoyum1997, lim142857 | - MoCha is a novel diffusion transformer (DiT) model for generating talking character animations from speech and text input, focusing on full-body motions and expressions beyond just the face. - It introduces a speech-video window attention mechanism for aligning video and speech, a joint training strategy that leverages both speech and text data to improve data efficiency, - and supports multi-character conversations by using character tags in prompts. - Human evaluations and automatic metrics on MoCha-Bench, a new benchmark tailored for this task, demonstrate MoCha's superior performance over existing methods on lip-sync quality, facial expressions, action naturalness, text alignment, and visual quality. - MoCha represents a significant advancement in AI-driven cinematic storytelling, setting a new standard for talking character video generation. | ['Text-to-Video', 'Multimodal'] | N/A | N/A |
| [What, How, Where, and How Well? A Survey on Test-Time Scaling in Large
  Language Models](https://arxiv.org/abs/2503.24235) | nancy-zwx, demolei, RubinSun, silentspring2, DonJoey | - This paper surveys Test-Time Scaling (TTS), a technique to improve Large Language Model (LLM) performance by allocating additional computation during inference. - It introduces a four-dimensional framework for analyzing TTS methods: what to scale (e.g., CoT length, samples), how to scale (e.g., SFT, RL, search), where to scale (tasks and datasets), and how well to scale (evaluation metrics). - It systematically reviews existing TTS methods, mapping them to the framework's dimensions and providing hands-on guidelines for practical implementation. - The paper identifies key trends, open challenges, and promising research directions in TTS, including improving scalability, clarifying the essence of techniques, and broadening generalization across domains. - It highlights the shift towards AI systems that dynamically scale their intelligence at inference, adapting to complex and evolving tasks. | ['Natural Language Processing', 'Question Answering'] | N/A | N/A |
| [RIG: Synergizing Reasoning and Imagination in End-to-End Generalist
  Policy](https://arxiv.org/abs/2503.24388) | Haian Huang, Zhonghan Zhao, GaoangWang, pppppM, ZwwWayne | - This paper introduces RIG, an end-to-end generalist Transformer-based policy that synergizes reasoning and imagination for embodied agents in open-world environments. - RIG integrates textual reasoning, low-level action control, and image generation within a unified sequence-to-sequence model, enabling it to reason about actions, predict their consequences, and review imagined outcomes before execution. - Trained with a progressive data collection strategy, RIG achieves state-of-the-art results on embodied tasks, image generation, and reasoning benchmarks, showing significant improvements over existing methods. - RIG demonstrates higher sample efficiency, requiring only 111 hours of training data compared to thousands of hours used by other methods, while also achieving 3.29x, 2.42x, and 1.33Ã— improvements on embodied tasks, image generation, and reasoning benchmarks respectively. - The model also supports test-time scaling, allowing for dynamic lookahead reasoning to improve action robustness and reduce trial-and-error during inference. | ['Reinforcement Learning', 'Robotics', 'Multimodal'] | N/A | N/A |
| [Effectively Controlling Reasoning Models through Thinking Intervention](https://arxiv.org/abs/2503.24370) | Prateek Mittal, Jiachen T. Wang, cxiang, tongwu2020 | - This paper introduces "Thinking Intervention," a novel method for controlling reasoning-enhanced large language models (LLMs) by strategically inserting or modifying specific thinking tokens within the LLM's reasoning process. - This method requires no model training and can be integrated with existing techniques like prompt engineering.  - The authors demonstrate that Thinking Intervention improves performance across tasks including instruction following, handling instruction hierarchies, and safety alignment.  - Evaluating on IFEval, SEP, XSTEST, and SORRY-BENCH datasets using DeepSeek R1 and QwQ models, Thinking Intervention shows significant improvements over baseline prompting methods.  - Results demonstrate gains up to 6.7% in instruction following accuracy, 15.4% for hierarchy tasks and 40% higher refusal rates for unsafe prompts, enhancing LLM control without extra training. | ['Natural Language Processing', 'Question Answering'] | N/A | N/A |
| [Query and Conquer: Execution-Guided SQL Generation](https://arxiv.org/abs/2503.24364) | sfc-mwydmuch, Borchmann | - This paper introduces a novel approach called "execution-guided SQL generation" for enhancing the accuracy of text-to-SQL tasks. - The method leverages execution results to select the most semantically consistent query from multiple generated candidates, enabling smaller, cost-effective models to outperform computationally intensive reasoning methods like OpenAI's o1, o3-mini, and DeepSeek R1. - By comparing query outputs based on exact and approximate execution similarity, the proposed approach overcomes limitations of traditional self-consistency methods that rely on structural comparisons, which are ineffective when queries are structurally different yet semantically equivalent. - Empirical results on the BIRD-SQL dataset demonstrate significant accuracy improvements across various model sizes, notably matching the performance of larger models with a 30-fold reduction in inference cost. - Further enhancements include leveraging partial executability in SQL dialects like PipeSQL to incrementally apply self-consistency during intermediate generation stages, leading to more robust refinement of complex queries. | ['Natural Language Processing', 'Text2Text Generation'] | N/A | N/A |
| [TeleAntiFraud-28k: A Audio-Text Slow-Thinking Dataset for Telecom Fraud
  Detection](https://arxiv.org/abs/2503.24115) | Kai Wu, Jingpeng Wang, HuangMinhua, WDong, JimmyMa99 | - This paper introduces TeleAntiFraud-28k, the first open-source audio-text slow-thinking dataset for automated telecom fraud analysis, integrating audio signals with reasoning-oriented textual analysis. - The dataset was constructed using three strategies: privacy-preserved text-truth sample generation with ASR and TTS, semantic enhancement via LLM-based self-instruction sampling, and multi-agent adversarial synthesis to simulate diverse fraud tactics. - TeleAntiFraud-28k contains 28,511 speech-text pairs with detailed annotations for fraud reasoning, divided into tasks for scenario classification, fraud detection, and fraud type classification. - A standardized evaluation benchmark, TeleAntiFraud-Bench, and a production-optimized SFT model trained on hybrid real/synthetic data are also provided. - Evaluations show that fine-tuning a large audio language model (LALM) like Qwen2Audio with this dataset significantly improves performance on telecom fraud detection tasks, outperforming other models and highlighting the importance of data synthesis, modality fusion, and slow-thinking training. | ['Audio', 'Automatic Speech Recognition', 'Natural Language Processing'] | [Link](https://github.com/JimmyMa99/TeleAntiFraud) | N/A |
| [Efficient Inference for Large Reasoning Models: A Survey](https://arxiv.org/abs/2503.23077) | jiaheng233, Bibaolong, HongyuChen, HongchengGao, yueliu1999 | - This paper surveys efficient inference methods for Large Reasoning Models (LRMs), focusing on mitigating token inefficiency while preserving reasoning quality. - The paper introduces a taxonomy categorizing methods into explicit compact Chain-of-Thought (CoT) and implicit latent CoT. - Empirical analyses are conducted on existing methods, comparing performance and efficiency. - Open challenges are presented, including human-centric controllable reasoning and ensuring safety. - The paper suggests key insights for enhancing LRMs' inference efficiency via model merging, new architectures, and agent routers. | ['Natural Language Processing', 'Question Answering'] | [Link](https://github.com/yueliu1999/Awesome-Efficient-Inference-for-LRMs) | N/A |
| [Classical Planning with LLM-Generated Heuristics: Challenging the State
  of the Art with Python Code](https://arxiv.org/abs/2503.18809) | jendrikseipp, andregrahl, abcorrea | - This paper introduces a novel approach to classical planning using Large Language Models (LLMs) to automatically generate domain-dependent heuristic functions, written in Python code, for greedy best-first search. - The pipeline prompts an LLM multiple times with domain descriptions, training tasks, and examples of heuristics to obtain a pool of candidate heuristic functions. - The best-performing heuristic is selected based on its performance on a training set and then used to solve unseen test tasks. -  Experimental results on the International Planning Competition (IPC) 2023 domains show that these LLM-generated heuristics outperform state-of-the-art domain-independent heuristics and are competitive with leading learning algorithms for domain-dependent heuristics, even when implemented within an unoptimized Python planner (Pyperplan) competing against highly optimized C++ planners. | ['Natural Language Processing'] | N/A | N/A |
| [UPME: An Unsupervised Peer Review Framework for Multimodal Large
  Language Model Evaluation](https://arxiv.org/abs/2503.14941) | Zheyuan Liu, Yibing, yuehuang, MunanNing, 77Hui | - This paper introduces UPME, an unsupervised peer review framework for evaluating multimodal large language models (MLLMs). - UPME uses only image data, allowing models to automatically generate questions and conduct peer reviews of answers from other models, reducing reliance on human annotations. - A vision-language scoring system is introduced to mitigate biases, focusing on response correctness, visual understanding and reasoning, and image-text correlation. - Experimental results on the MMStar and ScienceQA datasets demonstrate that UPME achieves high Pearson and Spearman correlations with human evaluations, showing strong alignment with human preferences. - The framework addresses limitations of existing MLLM evaluation methods by reducing human workload and mitigating biases such as self-preference and verbosity. | ['Multimodal', 'Visual Question Answering'] | N/A | N/A |
| [Decoupling Angles and Strength in Low-rank Adaptation](https://arxiv.org/abs/2503.18225) | Zeynep Akata, Leander Girrbach, Massimo Bini | - This paper introduces DeLoRA, a novel parameter-efficient fine-tuning method that enhances the robustness of low-rank adaptation by decoupling angular learning from adaptation strength. - DeLoRA achieves this by normalizing and scaling learnable low-rank matrices, effectively controlling the magnitude of weight updates while maintaining expressiveness. - The method is derived from and improves upon both LoRA and ETHER, combining their respective strengths and mitigating their limitations. - Evaluations on image generation, natural language understanding, and instruction tuning tasks demonstrate that DeLoRA matches or surpasses the performance of competing methods while exhibiting improved robustness. - Ablation studies validate the design choices of DeLoRA and highlight its advantages in terms of hyperparameter sensitivity and resistance to performance degradation during extended training. | ['Image-to-Image', 'Text-to-Image', 'Natural Language Processing'] | [Link](https://github.com/ExplainableML/DeLoRA) | N/A |
| [Entropy-Based Adaptive Weighting for Self-Training](https://arxiv.org/abs/2503.23913) | Wei Wang, Mingyu Derek Ma, Yihe Deng, Xiaoxuan Wang | - This paper introduces Entropy-Based Adaptive Weighting for Self-Training (EAST), a novel method for improving the mathematical reasoning capabilities of large language models (LLMs). - EAST employs an adaptive weighting strategy that prioritizes uncertain data during self-training by assigning higher weights to data points where the model exhibits higher uncertainty, as measured by the entropy of the model's sample distribution. - This approach encourages the model to focus on more informative and challenging examples, thereby enhancing its reasoning ability. - Experimental results on GSM8K and MATH benchmarks demonstrate that EAST consistently outperforms baseline methods, achieving a 1% gain over the backbone model on MATH and a further 1-2% performance boost on GSM8K compared to the vanilla self-training method. - EAST effectively addresses the limitation of existing self-training methodologies that treat all generated training data uniformly, regardless of the model's confidence level. | ['Natural Language Processing', 'Question Answering', 'Text2Text Generation'] | [Link](https://github.com/mandyyyyii/east) | N/A |
