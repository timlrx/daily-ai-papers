

## Papers for 2025-04-16

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [Genius: A Generalizable and Purely Unsupervised Self-Training Framework
  For Advanced Reasoning](https://arxiv.org/abs/2504.08672) | Haiteng Zhao, Chang Ma, Hang Yan, QiushiSun, xufangzhi | - Genius, a generalizable and purely unsupervised self-training framework, is proposed to enhance the reasoning capabilities of Large Language Models (LLMs) without external supervision or reward models. - It uses a stepwise foresight re-sampling strategy, which involves simulating future outcomes to estimate step values and create high-quality preference pairs for training. - To ensure robust optimization, Genius introduces an advantage-calibrated optimization (ACO) loss function which mitigates inconsistencies between foresight scores and step advantages. - Experimental results on seven reasoning benchmarks demonstrate that Genius significantly improves the reasoning performance of LLaMA 3.1 by >7% with only 25K unsupervised general queries. - Further analysis reveals that Genius holds potential for scalability, as indicated by the consistent improvement observed with increasing training steps. | ['Natural Language Processing', 'Question Answering', 'Text Generation', 'Text2Text Generation'] | [Link](https://github.com/xufangzhi/Genius) | N/A |
| [xVerify: Efficient Answer Verifier for Reasoning Model Evaluations](https://arxiv.org/abs/2504.10481) | Bo Tang, Wentao Zhang, Pengyuan Wang, Duguce, Hush-cd | - This paper introduces xVerify, an efficient answer verifier designed for evaluating responses from reasoning models on objective questions, addressing the limitations of existing methods in handling complex reasoning traces and equivalence checking. - It supports robust equivalence checking, including symbol conversion, mathematical expression matching, and semantic alignment, and is tolerant of formatting errors, making it applicable to a wide range of question types. - A new dataset, Verify Answer for Reasoning (VAR), is constructed, containing responses from 19 LLMs across 24 reasoning benchmarks, with labels verified through GPT-40 and human review. - xVerify models of different sizes are trained on VAR and achieve state-of-the-art performance, outperforming existing evaluation methods and judge models on both test and generalization sets. - Notably, even the smallest variant, xVerify-0.5B-I, surpasses most existing methods, while larger variants achieve F1 scores and accuracy exceeding 95%. | ['Question Answering', 'Natural Language Processing'] | [Link](https://github.com/IAAR-Shanghai/xVerify) | [Link](https://huggingface.co/collections/IAAR-Shanghai/xverify) |
| [Pixel-SAIL: Single Transformer For Pixel-Grounded Understanding](https://arxiv.org/abs/2504.10465) | Weixian Lei, Yanwei Li, Zilong Huang, Tao Zhang, LXT | - Pixel-SAIL, a simplified Multimodal Large Language Model (MLLM) designed for pixel-level understanding tasks like referring segmentation and visual prompt understanding, uses a single transformer, eliminating the need for extra components like vision encoders or segmentation experts. - Pixel-SAIL incorporates a learnable upsampling module to refine low-resolution visual tokens, a novel visual prompt injection method for better visual prompt understanding, and a dense feature distillation strategy from pre-trained segmentation experts to enhance fine-grained feature extraction. - Evaluated on RefCOCO, RefCOCOg, RefCOCO+, and gRefCOCO, Pixel-SAIL-0.5B outperforms similarly sized models and even some larger 7B models with vision experts.  Pixel-SAIL-3B achieves state-of-the-art results on these datasets, outperforming larger models like Sa2VA-4B.  - On the new PerBench, which includes detailed object captions, visual prompt multiple-choice questions, and visual-text referring segmentation, Pixel-SAIL-3B achieves an overall score of 42.2, surpassing Sa2VA-4B's 39.0 and GLaMM-7B's 15.3. | ['Image Segmentation', 'Visual Question Answering', 'Multimodal'] | [Link](https://github.com/magic-research/Sa2VA) | N/A |
| [Heimdall: test-time scaling on the generative verification](https://arxiv.org/abs/2504.10337) | Xing Jin, WesleyShi | - Heimdall, a long chain-of-thought (CoT) verification large language model (LLM), is proposed, which accurately judges the correctness of solutions, boosting verification accuracy on competitive math problems from 62.5% to 97.5% using reinforcement learning and repeated sampling. - Heimdall demonstrates strong generalization capabilities by successfully detecting issues in challenging math proofs not seen during training and is extended to improve problem-solving through Pessimistic Verification, which selects the most likely correct solution by judging multiple solutions from a solver model. - Using DeepSeek-R1-Distill-Qwen-32B as the solver, Pessimistic Verification with Heimdall improves solution accuracy on AIME2025 from 54.2% to 83.3% and reaches 93% with Gemini 2.5 Pro, matching state-of-the-art performance. - An automatic knowledge discovery system is prototyped using NuminaMath for data synthesis, with Heimdall verifying solutions, effectively identifying nearly half of the synthetic data as flawed, consistent with findings from NuminaMath's own study. - The work highlights the importance of verification in AI systems for knowledge creation and maintenance, showing the potential of long CoT LLMs for accurate verification and improved problem-solving. | ['Natural Language Processing', 'Question Answering', 'Reinforcement Learning'] | N/A | N/A |
| [How Instruction and Reasoning Data shape Post-Training: Data Quality
  through the Lens of Layer-wise Gradients](https://arxiv.org/abs/2504.10766) | Ziyue Li, Yanhong Li, Ming Li, zhoutianyi | - This paper presents a spectral analysis of layer-wise gradients in Large Language Models (LLMs) during post-training with instruction/reasoning data of varying quality. - The analysis reveals that established data quality metrics can be unified and explained by the spectral properties of gradients obtained through singular value decomposition (SVD). - Higher-quality data correlates with lower nuclear norms and higher effective ranks of gradients, with effective rank demonstrating finer-grained resolution in discerning data quality compared to nuclear norms. - The study shows that reasoning data elicits richer gradient structures (higher effective ranks) than instruction-following data, indicating greater complexity in parameter updates for reasoning tasks. - Models within the same family exhibit similar gradient dynamics irrespective of model size, but variations are significant across different model families. | ['Natural Language Processing'] | [Link](https://github.com/MingLiiii/Gradient_Unified) | N/A |
| [The Scalability of Simplicity: Empirical Analysis of Vision-Language
  Learning with a Single Transformer](https://arxiv.org/abs/2504.10462) | Jun Hao Liew, Haochen Wang, Jiacong Wang, Weixian Lei, LXT | - This paper introduces SAIL, a Single Transformer unified Multimodal Large Language Model (MLLM) that integrates raw pixel encoding and language decoding within a single architecture, eliminating the need for a separate vision encoder. - SAIL leverages mixed attention mechanisms (bidirectional for image patches, causal for text) and multimodal positional encodings to align visual and textual modalities. - Through model and data scaling, SAIL achieves performance comparable to modular MLLMs on vision-language benchmarks and functions as a high-performing vision backbone. - Notably, SAIL demonstrates superior data scaling properties compared to modular MLLMs, achieving near-comparable performance with significantly less pretraining data when scaled to 512M image-text pairs. - SAIL also exhibits strong visual representation capabilities, achieving results on par with ViT-22B in vision tasks such as semantic segmentation. | ['Multimodal', 'Image Classification', 'Image Segmentation', 'Visual Question Answering', 'Image Feature Extraction'] | [Link](https://github.com/bytedance/SAIL) | N/A |
| [Efficient Process Reward Model Training via Active Learning](https://arxiv.org/abs/2504.10559) | Tianyu Pang, Xin Mao, Zichen Liu, Keyu Duan, dreamerdeo | - This paper introduces ACTPRM, an active learning approach for training Process Reward Models (PRMs) that significantly reduces annotation costs by proactively selecting uncertain samples for labeling. - ACTPRM uses an ensemble of PRMs to estimate uncertainty during training, which is used in the pool-based setting to retain only highly uncertain data that subsequently gets labelled by a reasoning model. - The paper demonstrates that ACTPRM achieves comparable or better performance to full-data tuning while using only 50% of the annotation budget. - It also presents a one-shot active learning setting where ACTPRM filters over 1M math reasoning trajectories, reaching a new state-of-the-art performance of 75.0% on ProcessBench and 65.5% on PRMBench with significantly reduced costs compared to previous SOTA methods. - The code and models are open-sourced to facilitate community adoption and further research. | ['Natural Language Processing', 'Question Answering'] | [Link](https://github.com/sail-sg/ActivePRM) | N/A |
| [DeepMath-103K: A Large-Scale, Challenging, Decontaminated, and
  Verifiable Mathematical Dataset for Advancing Reasoning](https://arxiv.org/abs/2504.11456) | Xingyu Chen, Qiuzhi Liu, Jiahao Xu, Tian Liang, Zhiwei He | - This paper introduces DeepMath-103K, a large-scale dataset of 103K challenging mathematical problems designed for training advanced reasoning models via reinforcement learning. - DeepMath-103K is more challenging and diverse than existing datasets, with problems spanning difficulty levels 3-10 and covering a wide range of mathematical topics.  - Each problem includes a verifiable final answer and three distinct AI-generated solutions, supporting various training paradigms like supervised fine-tuning, model distillation, and reinforcement learning. - Models trained on DeepMath-103K demonstrate significant performance improvements on multiple challenging mathematical reasoning benchmarks, especially using RL-Zero techniques. - The dataset's rigorous decontamination process ensures the integrity of evaluations, facilitating the development of robust AI reasoning systems by removing overlap with common evaluation benchmarks. | ['Natural Language Processing', 'Question Answering', 'Reinforcement Learning'] | [Link](https://github.com/zwhe99/DeepMath) | N/A |
| [ReZero: Enhancing LLM search ability by trying one-more-time](https://arxiv.org/abs/2504.11001) | Thinh Le, alandao | - ReZero, a novel Reinforcement Learning (RL) framework, is introduced to enhance the search capabilities of Large Language Models (LLMs) in Retrieval-Augmented Generation (RAG) by explicitly rewarding the act of retrying a search query after an initial unsuccessful attempt. - It uses a modified reward function within a standard RL loop (state, action, reward, policy) to incentivize the model to explore different querying strategies and persist in information seeking rather than prematurely halting. - ReZero was evaluated on the Apollo 3 mission dataset using Llama2-3B-Instruct and achieved a peak accuracy of 46.88%, nearly double the 25% accuracy of a baseline model trained without the retry incentive. - The reward_retry component encourages more effective utilization of the search tool to arrive at correct answers, particularly in challenging scenarios where initial queries may be insufficient. - The results demonstrate that explicitly rewarding retry attempts in a RAG system significantly improves LLM robustness in information retrieval, suggesting the model learns effective search strategies faster. Further research focusing on the training dynamics, generalizing ReZero's performance, using other datasets and integrating it with related methods are suggested as future directions. | ['Natural Language Processing', 'Question Answering', 'Reinforcement Learning'] | N/A | N/A |
| [AI-University: An LLM-based platform for instructional alignment to
  scientific classrooms](https://arxiv.org/abs/2504.08846) | Rahul Gulati, Mostafa Faghih Shojaei, garikipati, Dinzhenzhenzhu, simocimolato | - AI-University (AI-U) is an LLM-based platform for instructional alignment to scientific classrooms by using retrieval-augmented generation (RAG) to fine-tune LLMs with course materials such as lecture videos, notes, and textbooks. - The AI-U framework fine-tunes a large language model (LLM) with retrieval-augmented generation (RAG) to create instructor-aligned responses, mirroring the instructor's style and approach. - A prototype web application allows users to input queries and receive AI-generated responses with links to relevant course materials and timestamps in corresponding video lectures. - Evaluation results showed that the fine-tuned LLM, LLaMA-TOMMI-1.0, achieves a higher cosine similarity with reference answers and outperforms the base Llama 3.2 model in alignment with course style. - The framework offers a scalable approach to AI-assisted education with a focus on adaptability and personalized learning, and can be extended to broader research content in science. | ['Question Answering'] | [Link](https://github.com/my-ai-university/finite-element-method) | [Link](https://huggingface.co/my-ai-university) |
| [Adaptive Computation Pruning for the Forgetting Transformer](https://arxiv.org/abs/2504.06949) | Aaron Courville, Johan Obando-Ceron, Zhixuan Lin, littleowen | - This paper introduces Adaptive Computation Pruning (ACP) for the Forgetting Transformer (FoX), a method to dynamically prune computations in attention based on a forget gate and a threshold. - ACP identifies and skips computations related to input-output dependencies significantly weakened by the forget gate, reducing FLOPs without impacting performance. - Applied to language model pretraining with FoX, ACP reduces FLOPs in softmax attention by ~70% and improves training throughput by 10-35% across various model sizes and context lengths, with longer contexts yielding greater savings. - Analysis reveals a bimodal distribution of attention heads, categorized into "local" heads (primarily focused on local context) and "global" heads, with the majority being local, aligning with the observed FLOP reduction. - The paper also explores the impact of a hyperparameter controlling pruning aggressiveness and demonstrates its robustness, showing minimal performance impact even with a less conservative setting. | ['Natural Language Processing', 'Text Generation'] | [Link](https://github.com/zhixuan-lin/arctic-fox), [Link](https://github.com/zhixuan-lin/forgetting-transformer) | N/A |
| [Multimodal Long Video Modeling Based on Temporal Dynamic Context](https://arxiv.org/abs/2504.10443) | Xiangyu Yue, Yiyuan Zhang, Jiaming Han, Hoar012 | - This paper introduces Temporal Dynamic Context (TDC), a novel multimodal long-video modeling framework that leverages both static visual features and dynamic multimodal context within each scene. - TDC employs a query-based Transformer to compress video, audio, and instruction text tokens into a limited set of temporal context tokens, enabling effective token compression while preserving crucial information. - To handle extremely long videos, the paper proposes a training-free Long Video Chain-of-Thought (LVCoT) strategy, which processes the video segment by segment and then integrates the segment information for a final answer. - Extensive experiments on various video and audio-video understanding benchmarks demonstrate that TDC achieves state-of-the-art performance, outperforming existing methods such as VideoLLaMA2 and LongVU on MLVU by 15.6% and 7.4%, respectively. - Results on VideoMME, with and without subtitles, further validates TDC's effectiveness in long video understanding. | ['Multimodal', 'Video-Text-to-Text', 'Visual Question Answering', 'Audio'] | [Link](https://github.com/Hoar012/TDC-Video) | N/A |
| [Summarization of Multimodal Presentations with Vision-Language Models:
  Study of the Effect of Modalities and Structure](https://arxiv.org/abs/2504.10049) | Frédéric Dufaux, Camille Guinaudeau, gigant | - This paper benchmarks open-weight Vision-Language Models (VLMs) for summarizing multimodal presentations, specifically focusing on the impact of input representation. - It introduces a structured, interleaved representation of slides and transcripts, demonstrating superior performance compared to unstructured or single-modality inputs. - With Qwen2-VL, the study conducts a fine-grained analysis across various visual token budgets and input structures, revealing that visual information becomes crucial with higher budgets while structure is key at lower budgets.  - The paper further examines the scaling of model size and its interaction with visual token budget.  - Through a qualitative evaluation, the paper illustrates how multimodal input leads to more comprehensive summaries with improved accuracy and contextual information, while also observing an unintended "bullet point" generation tendency. | ['Multimodal', 'Summarization', 'Video-Text-to-Text'] | N/A | [Link](https://huggingface.co/datasets/gigant/tib-bench), [Link](https://huggingface.co/spaces/gigant/slide-presentation-viz) |
| [LazyReview A Dataset for Uncovering Lazy Thinking in NLP Peer Reviews](https://arxiv.org/abs/2504.11042) | Iryna Gurevych, Lizhen Qu, Anne Lauscher, Zhuang Li, sukannya | - Introduces LAZYREVIEW, a dataset of peer review sentences annotated with fine-grained lazy thinking categories. - Reveals that Large Language Models (LLMs) struggle to detect lazy thinking instances in a zero-shot setting but improve significantly with instruction-based fine-tuning. - Demonstrates through a controlled experiment that reviews revised with lazy thinking feedback are more comprehensive and actionable. - Releases the dataset and enhanced guidelines to aid in training junior reviewers. - Presents analysis and experimental results on effectiveness of instruction tuning and positive examples in identifying lazy thinking. | ['Natural Language Processing'] | [Link](https://github.com/UKPLab/arxiv2025-lazy-review) | N/A |
