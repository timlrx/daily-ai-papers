

## Papers for 2025-04-21

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [Does Reinforcement Learning Really Incentivize Reasoning Capacity in
  LLMs Beyond the Base Model?](https://arxiv.org/abs/2504.13837) | Zhaokai Wang, Andrew Zhao, Rui Lu, Zhiqi Chen, Yang Yue | - This paper challenges the assumption that Reinforcement Learning with Verifiable Rewards (RLVR) enables Large Language Models (LLMs) to develop novel reasoning abilities beyond the capabilities of the base model. - Through experiments across math, code, and visual reasoning tasks, using various model families and RL algorithms, the study reveals that RLVR primarily improves the sampling efficiency of existing reasoning paths present in the base model, rather than introducing new ones. - By measuring the pass@k metric, where k represents the number of samples, the authors found that base models can often outperform RL-trained models when k is large, indicating a broader reasoning coverage in base models. -  Perplexity analysis revealed that RL model's reasoning paths are already present in base model's output distribution. - The study concludes that RLVR, in its current form, has limitations in expanding the reasoning boundary of LLMs and suggests the need for new paradigms to advance LLM reasoning abilities. | ['Reinforcement Learning', 'Natural Language Processing'] | [Link](https://limit-of-RLVR.github.io) | N/A |
| [MIG: Automatic Data Selection for Instruction Tuning by Maximizing
  Information Gain in Semantic Space](https://arxiv.org/abs/2504.13835) | Haochen Ye, Zerun Ma, Kai Hu, Yining Li, Yicheng Chen | - This paper introduces MIG (Maximize Information Gain), a novel data selection method for instruction tuning of Large Language Models (LLMs). - MIG quantifies dataset quality and diversity by modeling the semantic space as a label graph, where nodes represent labels and edges capture semantic relationships. - Information gain is maximized during data selection by iteratively selecting samples that contribute the most to the overall information content of the dataset as measured by the label graph. - Experiments on diverse datasets (Tulu3, OpenHermes 2.5, X sota) and LLMs (Llama 3.1-8b, Mistral-7B, Qwen2.5-7B) demonstrate that MIG consistently outperforms state-of-the-art data selection methods. - Notably, a model fine-tuned with only 5% of the Tulu3 data selected by MIG achieved comparable performance to the model trained on the full dataset, showcasing significant efficiency gains. | ['Natural Language Processing', 'Text2Text Generation'] | N/A | N/A |
| [Could Thinking Multilingually Empower LLM Reasoning?](https://arxiv.org/abs/2504.11833) | Lei Li, Shujian Huang, Wenhao Zhu, Xu Huang, Changjiang Gao | - This paper explores the potential of multilingualism in enhancing reasoning capabilities of Large Language Models (LLMs). - The study quantifies the potential gain from multilingual thinking by aggregating model responses to translated parallel inputs on reasoning-specific tasks like GPQA and MGSM. - Results demonstrate that multilingual thinking can significantly improve accuracy compared to English-only reasoning or paraphrased inputs, and a combination of just a few (≥4) languages is sufficient for substantial improvement. - The study finds that common answer selection methods, like majority voting, prompt-based selection, and LLM-as-a-judge selection, struggle to fully realize the potential of multilingualism due to issues like bias toward specific languages and sensitivity to answer selection criteria. - The paper suggests that different languages may be better suited for different difficulty levels of questions, and the presence of "key advantageous languages" can compensate for errors in other languages, yet a robust solution is not fully realized yet. | ['Natural Language Processing', 'Question Answering'] | [Link](https://github.com/CONE-MT/multilingual_reasoning) | [Link](https://huggingface.co/meta-llama/Llama-3.1-70B-Instruct), [Link](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B), [Link](https://huggingface.co/Qwen/Qwen-2.5-72B-Chat) |
| [NodeRAG: Structuring Graph-based RAG with Heterogeneous Nodes](https://arxiv.org/abs/2504.11544) | Yixin Liu, Haoxiang Chen, Chengze Li, Haojie Zheng, Tianyang Xu | - NodeRAG, a novel graph-based Retrieval-Augmented Generation (RAG) framework, is introduced, which enhances RAG performance through optimized graph structure indexing for more effective and fine-grained retrieval. - NodeRAG constructs a heterogenous graph with functionally distinct nodes, balancing fine-grained understanding with a global perspective of the knowledge corpus, addressing limitations of previous graph-based RAG methods. - The heterograph integrates various node types, including entities, relationships, text chunks, events, and summaries, enabling precise hierarchical retrieval while minimizing irrelevant information. - Experimental results show that NodeRAG outperforms current methods (GraphRAG, LightRAG) in multi-hop benchmarks and open-ended evaluations with fewer retrieval tokens, demonstrating enhanced efficiency. - The framework offers system-level efficiency advantages with improvements in indexing time, query time, and storage efficiency due to the fine-grained graph structure and retrieval process. | ['Question Answering', 'Natural Language Processing', 'Graph Machine Learning'] | [Link](https://github.com/Terry-Xu-666/NodeRAG) | N/A |
| [Thought Manipulation: External Thought Can Be Efficient for Large
  Reasoning Models](https://arxiv.org/abs/2504.13626) | Wenhan Dong, Zifan Peng, Zhen Sun, Jingyi Zheng, Yule Liu | - This paper introduces ThoughtMani, a training-free method to enhance the efficiency of Large Reasoning Models (LRMs) by mitigating the "overthinking" problem, where models generate redundant reasoning steps. - ThoughtMani leverages smaller CoT generator models to provide external thoughts inserted into the reasoning process of the LRM, reducing internal thought generation and computational cost. - Experimental results on various datasets like GSM-8k, MATH-500, AIME-2024, and LiveBench/Code demonstrate that ThoughtMani reduces output token counts while maintaining or even improving reasoning accuracy and safety alignment. - For instance, using ThoughtMani with a smaller Qwen-2.5-7B-Instruct CoT generator for QwQ-32B on LiveBench/Code decreases output tokens by approximately 30% without performance degradation. - The method also reveals a distinct behavior in RL-based and distillation-based LRMs in handling external CoTs, offering insights into their reasoning processes. | ['Natural Language Processing', 'Question Answering'] | N/A | N/A |
| [It's All Connected: A Journey Through Test-Time Memorization,
  Attentional Bias, Retention, and Online Optimization](https://arxiv.org/abs/2504.13173) | Vahab Mirrokni, Peilin Zhong, Meisam Razaviyayn, Ali Behrouz | - This paper introduces MIRAS, a novel framework for designing sequence models based on associative memory principles, inspired by the cognitive phenomenon of attentional bias. - MIRAS framework considers four design choices: memory architecture, attentional bias objective, retention gate, and memory learning algorithm, offering flexibility in model design. - Three new sequence models—MONETA, YAAD, and MEMORA—are presented as variants of MIRAS, employing distinct attentional biases and retention mechanisms. - Experimental results demonstrate that these MIRAS variants outperform Transformer++ and other linear RNNs across language modeling, commonsense reasoning, and needle-in-haystack tasks. - The authors attribute the superior performance of MIRAS models to their expressive memory architectures and robust learning mechanisms, especially in long-context scenarios. | ['Natural Language Processing', 'Text Generation'] | N/A | N/A |
