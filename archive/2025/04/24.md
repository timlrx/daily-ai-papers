

## Papers for 2025-04-24

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [VisuLogic: A Benchmark for Evaluating Visual Reasoning in Multi-modal
  Large Language Models](https://arxiv.org/abs/2504.15279) | Einsiedler, luotto, Weiyun1025, GenuineWWD, wilye | - This research introduces VisuLogic, a new benchmark designed for evaluating visual reasoning abilities in multimodal large language models (MLLMs). - VisuLogic contains 1,000 human-verified visual reasoning problems across six categories, focusing on pure visual reasoning, unlike existing benchmarks that permit shortcuts through text descriptions.  - Evaluations revealed that SOTA MLLMs performed poorly, scoring below 30% accuracy, significantly lower than human performance (51.4%). - A supplementary training dataset and reinforcement learning baseline were developed and showed improved performance compared to open-source and closed-source MLLMs, showcasing RL's potential in enhancing visual reasoning.  - All code and data are publicly available to support further research. | ['Multimodal', 'Visual Question Answering', 'Computer Vision'] | [Link](https://visulogic-benchmark.github.io/VisuLogic) | N/A |
| [Trillion 7B Technical Report](https://arxiv.org/abs/2504.15431) | Suyeong An, hist0613, kyudolski, scottsuk0306, sungjunhan-trl | - Introduces Trillion-7B, a Korean-centric multilingual large language model (LLM) that uses a novel Cross-lingual Document Attention (XLDA) mechanism for efficient knowledge transfer from English to other languages. - The model architecture is based on a Transformer decoder with ROPE, SwiGLU, and RMSNorm, consisting of 32 layers with a hidden size of 4096 and a feedforward dimension of 11008. - Achieves competitive multilingual performance using only 10% of its 2 trillion training tokens for multilingual data, trained with a cost of $148K. - Evaluations across 27 benchmarks in four languages demonstrate the model's robust multilingual performance and cross-lingual consistency, particularly in Korean and instruction following. - Demonstrates zero-shot cross-lingual transfer to vision modalities with Trillion-LLaVA, which outperforms other vision-language models on Korean benchmarks despite being trained only on English vision-language data. | ['Natural Language Processing', 'Text Generation', 'Text2Text Generation', 'Question Answering', 'Translation'] | N/A | N/A |
| [Pre-DPO: Improving Data Utilization in Direct Preference Optimization
  Using a Guiding Reference Model](https://arxiv.org/abs/2504.15843) | Yue Zhang, Qiji Zhou, Shulin Huang, Junshu Pan, Swtheking | - This paper introduces Pre-DPO, a novel training paradigm for Direct Preference Optimization (DPO) that leverages a "guiding reference model" to enhance data utilization and improve performance in aligning large language models (LLMs). - Pre-DPO initializes training with a standard preference optimization method like DPO or SimPO, then re-optimizes the policy using the initial optimized model as a guiding reference, leading to adaptive data reweighting. - The guiding reference model assigns higher weights to more suitable training samples and lower weights to less suitable or conflicting samples, effectively transforming the role of the reference model from a static constraint to a dynamic guide. - Experiments on the Llama3.2, Qwen2.5 models, and AlpacaEval 2 and Arena-Hard benchmarks show that Pre-DPO consistently improves performance of both DPO and SimPO without external models or additional data. - Pre-DPO addresses the limitations of conventional reference models by utilizing the optimized policy as the reference, providing foresight and improving data reweighting during training. | ['Natural Language Processing', 'Reinforcement Learning'] | [Link](https://github.com/DtYXs/Pre-DPO) | [Link](https://huggingface.co/datasets/HuggingFaceH4/ultrachat_200k), [Link](https://huggingface.co/datasets/HuggingFaceH4/ultrafeedback_binarized) |
| [Decoupled Global-Local Alignment for Improving Compositional
  Understanding](https://arxiv.org/abs/2504.16801) | Ziyong Feng, Jun Wang, haoranxu, Kaichengalex, xiaoxing2001 | - This paper introduces Decoupled Global-Local Alignment (DeGLA), a framework designed to enhance the compositional understanding of Contrastive Language-Image Pre-training (CLIP) models while mitigating the loss of general capabilities often observed in existing methods. - DeGLA incorporates a self-distillation mechanism during global alignment, using a frozen teacher model derived from an exponential moving average to guide the learning of a student model, thus preserving pre-trained knowledge. - For local alignment, the framework leverages in-context learning capabilities of Large Language Models (LLMs) to construct a dataset of approximately 2 million high-quality negative captions. - It then introduces Image-Grounded Contrast (IGC) and Text-Grounded Contrast (TGC) losses to further refine compositional understanding by attracting and repelling image and text embeddings based on their alignment. - Experimental results show that DeGLA achieves state-of-the-art performance on compositional reasoning benchmarks (VALSE, SugarCrepe, and ARO) while improving zero-shot classification accuracy by an average of 13% across 11 datasets compared to previous state-of-the-art methods. | ['Multimodal', 'Zero-Shot Classification', 'Zero-Shot Image Classification', 'Computer Vision'] | [Link](https://github.com/xiaoxing2001/DeGLA) | N/A |
| [Tina: Tiny Reasoning Models via LoRA](https://arxiv.org/abs/2504.15777) | Ollie Liu, Enes Burak Bilgin, Ömer Faruk Akgül, Julian Asilis, upup-ashton-wang | - Tina, a family of tiny reasoning models, demonstrates substantial reasoning performance can be achieved with minimal resources by applying parameter-efficient updates during reinforcement learning (RL) using low-rank adaptation (LoRA) to a small 1.5B parameter base model. - The best Tina model achieves a >20% reasoning performance increase and 43.33% Pass@1 accuracy on AIME24 at only $9 USD post-training and evaluation cost, an estimated 260x cost reduction compared to existing SOTA models. - The authors hypothesize LoRA's effectiveness stems from rapidly adapting the model to the structural format of reasoning rewarded by RL, while preserving the base model's underlying knowledge. - This "rapid reasoning format adaptation" hypothesis is supported by observations of a training phase transition where format-related metrics peak or destabilize just before optimal performance is reached, while accuracy rewards show more gradual trends. - All code, training logs, model weights, and checkpoints are open-sourced to promote accessibility and reproducibility. | ['Natural Language Processing', 'Question Answering', 'Reinforcement Learning'] | [Link](https://github.com/shangshang-wang/Tina) | [Link](https://huggingface.co/Tina-Yi) |
| [A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training
  and Deployment](https://arxiv.org/abs/2504.15585) | Guibin Zhang, Kun Wang, Ningyu, Atarogic, Fred456 | - This paper presents a comprehensive survey of Large Language Model (LLM) safety, introducing the concept of "full-stack" safety, encompassing the entire LLM lifecycle from data preparation to commercialization and usage. - The survey analyzes safety and security risks across different stages, including data poisoning, privacy leakage, misalignment, jailbreak attacks, and vulnerabilities in LLM-based agent systems. - The research is based on an extensive review of 800+ papers and offers insights into mitigation strategies, defense mechanisms, and evaluation metrics. - The paper identifies promising research directions like data generation safety, alignment techniques, and robust prompt engineering. - It also provides roadmaps and perspectives for each LLM lifecycle stage, aiming to offer a holistic understanding and guide future research in LLM safety. | ['Natural Language Processing', 'Question Answering'] | [Link](https://github.com/bingreeky/full-stack-llm-safety) | N/A |
| [RePOPE: Impact of Annotation Errors on the POPE Benchmark](https://arxiv.org/abs/2504.15707) | Matthias Hein, YanNeu | - This paper assesses the impact of label errors in the MSCOCO dataset on the POPE benchmark, a standard for evaluating object hallucinations in vision-language models (VLMs). - The authors re-annotate the POPE benchmark images and create RePOPE, a corrected version of the dataset, finding an imbalance in annotation errors across different subsets. - Evaluating multiple VLM models on RePOPE reveals notable shifts in model rankings compared to the original POPE, highlighting the significant impact of label quality. - The paper observes a much higher error rate in the original POPE labels for questions with "yes" answers (9.3%) compared to "no" answers (1.7%). - This biased error distribution significantly affects the F1 scores and rankings of models on the benchmark, calling into question the reliability of some POPE subsets for measuring object hallucination. | ['Multimodal', 'Visual Question Answering'] | [Link](https://github.com/YanNeu/REPOPE) | N/A |
| [Rethinking the Generation of High-Quality CoT Data from the Perspective
  of LLM-Adaptive Question Difficulty Grading](https://arxiv.org/abs/2504.11919) | Keyu Wu, Kunlinliu2, MeiManlin, zcs1234, USTCYu | - This paper introduces a method for generating high-quality Chain-of-Thought (CoT) data by adapting question difficulty to the capabilities of Large Language Models (LLMs). - The approach involves grading question difficulty based on LLM performance and constructing an adaptive question database. - Questions are sampled from this database based on a difficulty distribution and DeepSeek-R1 (671B) is used to generate corresponding CoT data. - This LLM-adaptive CoT data is then used for fine-tuning smaller LLMs, improving their reasoning abilities. - Experiments demonstrate the effectiveness of this method, with models trained on 2k LLM-adaptive CoT data outperforming larger baseline models on mathematical and code generation tasks. | ['Question Answering', 'Text2Text Generation', 'Natural Language Processing'] | N/A | [Link](https://huggingface.co/datasets/open-r1/codeforces), [Link](https://huggingface.co/AI-MO/NuminaMath-CoT) |
| [CRUST-Bench: A Comprehensive Benchmark for C-to-safe-Rust Transpilation](https://arxiv.org/abs/2504.15254) | Ziteng Wang, Jia Pan, Robert Zhang, gregdurrett, anirudhkhatry | - This paper introduces CRUST-Bench, a new benchmark for evaluating C-to-safe-Rust transpilation, comprising 100 C repositories with manually-written Rust interfaces and test cases. - CRUST-Bench focuses on evaluating the ability of systems to transpile entire C repositories into safe and idiomatic Rust code, addressing the limitations of previous benchmarks that primarily focus on isolated functions. - The authors evaluate several state-of-the-art large language models (LLMs) on CRUST-Bench and find that safe and idiomatic Rust generation remains challenging, with the best model (OpenAI o1) solving only 15% of tasks in a single-shot setting. - Applying iterative self-repair techniques, such as incorporating compiler error messages and failing test cases, improves performance, achieving up to 37% success rate. - The benchmark and analysis highlight the need for further research in automated code migration and the importance of considering realistic, multi-file scenarios. | ['Text2Text Generation', 'Translation', 'Natural Language Processing'] | [Link](https://github.com/anirudhkhatry/CRUST-bench) | N/A |
| [Unchecked and Overlooked: Addressing the Checkbox Blind Spot in Large
  Language Models with CheckboxQA](https://arxiv.org/abs/2504.10419) | Borchmann, sf-mchilinski, mturski | - This paper introduces CheckboxQA, a new dataset designed to evaluate and improve large language models' (LLMs) ability to interpret checkboxes in visually rich documents. - CheckboxQA contains diverse documents with annotated question-answer pairs related to checkbox interpretation, addressing a gap in existing benchmarks that often overlook this critical element. - Current LLMs struggle with checkbox interpretation due to challenges such as the small size and visual subtlety of checkboxes, their context-dependent significance, and limited training data capturing checked vs. unchecked states. - Experiments demonstrate that models trained on data that includes checkbox annotations gain a distinct advantage in this task, highlighting the importance of dedicated resources like CheckboxQA.  - Although improvements are observed, all models still fall short of human performance, highlighting the need for further research in accurately identifying and interpreting checkmarks. | ['Document Question Answering', 'Multimodal'] | [Link](https://github.com/Snowflake-Labs/CheckboxQA) | N/A |
| [Progressive Language-guided Visual Learning for Multi-Task Visual
  Grounding](https://arxiv.org/abs/2504.16145) | Dingjiang Huang, Kunhua Ji, Wenlong Zhang, Hong Wang, jcwang0602 | - This paper introduces PLVL, a Progressive Language-guided Visual Learning framework for Multi-Task Visual Grounding (MTVG) which includes Referring Expression Comprehension (REC) and Referring Expression Segmentation (RES). - PLVL progressively injects language information into the visual backbone using a cross-attention mechanism within a local-global group architecture, eliminating the need for an extra cross-modal fusion module. - A collaborative multi-task head based on convolutional layers is used to jointly predict outputs for REC and RES, leveraging the shared central position of identified objects. - The model outperforms state-of-the-art methods on RefCOCO, RefCOCO+, and RefCOCOg benchmarks in both REC and RES tasks under traditional and pre-trained settings. - Experimental results demonstrate improvements, such as 8% reduced time overhead per image compared to EEVG. | ['Multimodal', 'Object Detection', 'Image Segmentation', 'Computer Vision'] | [Link](https://github.com/jcwang0602/PLVL) | N/A |
