

## Papers for 2025-05-14

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [MiniMax-Speech: Intrinsic Zero-Shot Text-to-Speech with a Learnable
  Speaker Encoder](https://arxiv.org/abs/2505.07916) | Congchao Guo, Bowen Zhang, ymzhang0519, mqyang1s, JunjieYan | - This paper introduces MiniMax-Speech, a novel autoregressive Transformer-based Text-to-Speech (TTS) model featuring a learnable speaker encoder.  - The model architecture includes a tokenizer, autoregressive Transformer, and a latent flow matching model with Flow-VAE.  - MiniMax-Speech achieves state-of-the-art (SOTA) results on objective voice cloning metrics (Word Error Rate and Speaker Similarity) and secured top position on the public TTS Arena leaderboard.  - The model supports zero-shot and one-shot voice cloning and demonstrates strong performance across 32 languages.  - Ablation studies show the effectiveness of the learnable speaker encoder and Flow-VAE in improving audio quality and speaker similarity. | ['Text-to-Speech'] | [Link](https://minimax-ai.github.io/tts_tech_report) | [Link](https://huggingface.co/datasets/MiniMaxAI/TTS-Multilingual-Test-Set) |
| [A Multi-Dimensional Constraint Framework for Evaluating and Improving
  Instruction Following in Large Language Models](https://arxiv.org/abs/2505.07591) | xjhuang, sean-xl-y, wuyilong, avonfwj, Junjie-Ye | This paper introduces a novel multi-dimensional constraint framework for evaluating and enhancing instruction following in large language models.  The framework is utilized to construct a benchmark dataset of 1200 instruction-following test samples with code-verifiable constraints.  Experiments on 19 LLMs across seven model families reveal substantial performance variations across diverse constraint forms.  Finally, the authors demonstrate that reinforcement learning utilizing their generated dataset significantly improves instruction following, primarily by modifying attention module parameters. | ['Natural Language Processing', 'Text Generation'] | [Link](https://github.com/Junjie-Ye/MulDimIF) | N/A |
| [ViMRHP: A Vietnamese Benchmark Dataset for Multimodal Review Helpfulness
  Prediction via Human-AI Collaborative Annotation](https://arxiv.org/abs/2505.07416) | Kiet Van Nguyen, Dat Minh Nguyen, sonlam1102, trucnguyen28 | - This paper introduces ViMRHP, a new Vietnamese benchmark dataset for multimodal review helpfulness prediction (MRHP). - ViMRHP contains 46K reviews across four domains, with AI assistance significantly reducing annotation time and cost. - A human-AI collaborative annotation framework was used, resulting in a high-quality dataset. - Baseline models were evaluated on both AI-generated and human-verified annotations; human verification improved performance. - The dataset is publicly available and contributes to the advancement of MRHP research in low-resource languages. | ['Multimodal'] | [Link](https://github.com/trng28/ViMRHP) | N/A |
