

## Papers for 2025-05-20

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [Chain-of-Model Learning for Language Model](https://arxiv.org/abs/2505.11820) | tricktreat, Chengruidong, iofu728, xutan, KaitaoSong |  * The paper introduces a novel learning paradigm called "Chain-of-Model" (CoM) which incorporates causal relationships into hidden states, improving scaling efficiency and inference flexibility.   * CoM formulates hidden states at each layer as a combination of sub-representations (chains) at the hidden dimension level, allowing progressive model scaling by increasing chains.   * The proposed Chain-of-Language-Model (CoLM) integrates CoM into each Transformer layer, offering multiple sub-models at varying sizes for elastic inference.   * CoLM-Air introduces a KV sharing mechanism, further enhancing extensibility with seamless LM switching and prefilling acceleration.  * Experimental results show that CoLM achieves comparable performance to standard Transformers while offering greater flexibility and efficiency. | ['Natural Language Processing', 'Text Generation'] | [Link](https://github.com/microsoft/CoLM) | N/A |
| [AdaptThink: Reasoning Models Can Learn When to Think](https://arxiv.org/abs/2505.13417) | Ling Feng, Lei Hou, juanli, linny2002, NeoZ123 | - This paper introduces AdaptThink, a novel reinforcement learning algorithm that enables reasoning models to adaptively choose between "Thinking" (lengthy reasoning process) and "NoThinking" (direct answer generation) modes based on problem difficulty. - AdaptThink consists of a constrained optimization objective that encourages NoThinking while maintaining performance and an importance sampling strategy to balance both modes during training. - Experimental results on three math datasets (GSM8K, MATH500, and AIME2024) show that AdaptThink significantly reduces average response length (by 53%) while improving accuracy (by 2.4%) compared to the baseline model. - The method also demonstrates effectiveness on out-of-distribution datasets, further highlighting its adaptability and efficiency. - AdaptThink offers a promising approach to optimize the balance between reasoning quality and efficiency by leveraging adaptive thinking-mode selection. | ['Question Answering'] | [Link](https://github.com/THU-KEG/AdaptThink) | N/A |
| [AdaCoT: Pareto-Optimal Adaptive Chain-of-Thought Triggering via
  Reinforcement Learning](https://arxiv.org/abs/2505.11896) | Shuangzhi, qingping95, Swtheking, sunzewei2715, louchenwei | AdaCoT is a novel framework that allows LLMs to adaptively decide when to use Chain-of-Thought (CoT) prompting, addressing the inefficiency of indiscriminately using CoT for all queries.  It formulates this as a Pareto optimization problem, balancing model performance and CoT costs using reinforcement learning.  AdaCoT achieves significant reductions in CoT usage (as low as 3.18%) and tokens (69.06%), while maintaining high performance on complex tasks.  A key technical contribution is Selective Loss Masking (SLM), which prevents decision boundary collapse during training.  Experimental results show AdaCoT successfully navigates the Pareto frontier. | ['Question Answering'] | N/A | N/A |
| [Delta Attention: Fast and Accurate Sparse Attention Inference by Delta
  Correction](https://arxiv.org/abs/2505.11254) | Sung Ju Hwang, gmlwns5176, jeffwillette | - This paper introduces Delta Attention, a novel method to improve the accuracy of sparse attention inference in transformer models. - Delta Attention addresses the performance degradation caused by distributional shifts in sparse attention outputs by applying a simple correction procedure. - Experimental results demonstrate that Delta Attention achieves an average 36 percentage point increase in accuracy across various benchmarks, recovering 88% of full quadratic attention accuracy. - The method maintains approximately 98.5% sparsity, resulting in a 32 times speedup compared to Flash Attention 2 on a 1 million token prefill task. - Delta Attention can be applied to any existing sparse attention method with minimal overhead. | ['Natural Language Processing'] | N/A | N/A |
| [Scaling Computer-Use Grounding via User Interface Decomposition and
  Synthesis](https://arxiv.org/abs/2505.13227) | Mayome, RadioBlue, lixiaochuan2020, MillanK, tianbaoxiexxx |  - This paper introduces OSWORLD-G, a comprehensive benchmark with 564 finely annotated samples for evaluating GUI grounding models, addressing limitations of previous benchmarks.  - It also presents JEDI, a large-scale (4 million examples) computer use grounding dataset synthesized via multi-perspective task decoupling.  - Multi-scale models trained on JEDI outperform existing approaches on ScreenSpot-v2, ScreenSpot-Pro, and OSWORLD-G.  - The authors demonstrate improved grounding with JEDI enhances agentic capabilities of foundation models, improving performance on complex computer tasks.  - Ablation studies identify key factors contributing to grounding performance and show combining specialized data for different interface elements enables compositional generalization. | ['Multimodal'] | [Link](https://osworld-grounding.github.io) | N/A |
| [Thinkless: LLM Learns When to Think](https://arxiv.org/abs/2505.13379) | wxcTest, horseee, Vinnnf | - This paper introduces Thinkless, a novel framework that enables LLMs to adaptively select between short-form and long-form reasoning based on task complexity and model capabilities. - Thinkless employs two control tokens, <short> and <think>, to direct the LLM's reasoning mode and is trained using a reinforcement learning paradigm with a decoupled optimization algorithm (DeGRPO). - DeGRPO decomposes the learning objective into two components: control token loss and response loss, enhancing training stability and preventing mode collapse observed in vanilla GRPO. - Experiments on several benchmarks show that Thinkless reduces long-chain reasoning usage by 50%-90%, significantly improving efficiency without sacrificing accuracy. - The code for Thinkless is publicly available on GitHub. | ['Reinforcement Learning', 'Natural Language Processing', 'Question Answering'] | [Link](https://github.com/VainF/Thinkless) | N/A |
| [Seek in the Dark: Reasoning via Test-Time Instance-Level Policy Gradient
  in Latent Space](https://arxiv.org/abs/2505.13308) | zlzheng, vickyandkekey, ColorfulAI, xuekai, henry12348 | The paper introduces LATENTSEEK, a novel framework that enhances Large Language Model (LLM) reasoning capabilities through Test-Time Instance-level Adaptation (TTIA) in the latent space.  LATENTSEEK leverages policy gradients to iteratively refine latent representations, guided by self-generated reward signals.  Experimental results on various reasoning benchmarks demonstrate that LATENTSEEK consistently outperforms strong baselines, such as Chain-of-Thought prompting and fine-tuning based methods.  The method is highly efficient, converging within a few iterations for problems of average complexity and showing scalability with additional iterations.  The findings suggest LATENTSEEK is a lightweight, scalable, and effective solution for enhancing LLM reasoning. | ['Natural Language Processing'] | [Link](https://github.com/bigai-nlco/LatentSeek) | N/A |
| [MM-PRM: Enhancing Multimodal Mathematical Reasoning with Scalable
  Step-Level Supervision](https://arxiv.org/abs/2505.13427) | wqshao126, Domingo12, SuperposedWave, FanqingM, Cierra0506 | - This paper introduces MM-PRM, a process reward model designed to enhance multimodal mathematical reasoning. - MM-PRM leverages a three-stage framework: policy model construction, process supervision data generation using Monte Carlo Tree Search (MCTS), and process reward model training. - The model achieves significant improvements across various benchmarks (MM-K12, OlympiadBench, MathVista, etc.), outperforming existing methods by a notable margin. - The effectiveness of soft labels, smaller learning rates, and path diversity in optimizing PRM performance is demonstrated. - The researchers release their code and data at https://github.com/ModalMinds/MM-PRM. | ['Multimodal'] | [Link](https://github.com/ModalMinds/MM-PRM) | N/A |
| [FedSVD: Adaptive Orthogonalization for Private Federated Learning with
  LoRA](https://arxiv.org/abs/2505.12805) | Sangwoo Park, hbseong, dwgnr, dongboklee, Seanie-lee | - This paper introduces FedSVD, a novel method for private federated learning with LoRA that addresses noise amplification issues. - FedSVD uses singular value decomposition (SVD) to reparameterize the LoRA update, improving stability and performance under differential privacy (DP-SGD). - The proposed method avoids quadratic noise amplification by optimizing only one matrix (B) while the other matrix (A) is reinitialized using SVD. - FedSVD consistently outperforms baselines under both private and non-private settings across various benchmarks and privacy levels. - Theoretical analysis shows that the orthonormal structure of matrix A improves the condition number of the Hessian, resulting in faster convergence. | ['Natural Language Processing'] | N/A | N/A |
| [Fractured Chain-of-Thought Reasoning](https://arxiv.org/abs/2505.12992) | JunnanLi, doyensahoo, yuhuixu, hendrydong, baohao | - This paper introduces Fractured Sampling, a novel inference-time scaling technique that improves the reasoning capabilities of large language models (LLMs) by generating rich intermediate reasoning trajectories while reducing token costs. - Fractured Sampling operates along three orthogonal axes: the number of reasoning trajectories, the number of final solutions per trajectory, and the depth at which reasoning traces are truncated. - Extensive experiments on five reasoning benchmarks show that Fractured Sampling consistently achieves superior accuracy-cost trade-offs compared to traditional methods like full chain-of-thought (CoT) prompting and solution-only sampling. - The analysis reveals how to allocate computation across the three dimensions of Fractured Sampling to maximize performance, leading to more efficient and scalable LLM reasoning. - The authors demonstrate that truncated CoT, which stops reasoning before completion, often matches full CoT sampling in accuracy while using significantly fewer tokens. | ['Natural Language Processing'] | N/A | N/A |
| [VisionReasoner: Unified Visual Perception and Reasoning via
  Reinforcement Learning](https://arxiv.org/abs/2505.12081) | Shu Liu, BoHao0326, zszhong, TainU, Ricky06662 | - VisionReasoner is a novel unified framework for visual perception tasks that leverages reinforcement learning to enhance reasoning capabilities and solve diverse perception tasks within a shared model. - It outperforms existing models like Qwen2.5VL by relative margins of 29.1% on COCO (detection), 22.1% on ReasonSeg (segmentation), and 15.3% on CountBench (counting). - The model employs a multi-object cognitive learning strategy and reformulates tasks into three fundamental types: detection, segmentation, and counting. - It incorporates a reasoning module which processes the image and locates targeted objects, and a segmentation module that produces segmentation masks if needed. - The reward mechanism includes format rewards (thinking rewards, answer format rewards, non-repeat rewards) and accuracy rewards (multi-object IoU rewards, L1 rewards for precise localization) to strengthen multi-object cognition. | ['Multimodal', 'Reinforcement Learning', 'Visual Question Answering', 'Object Detection', 'Image Segmentation', 'Zero-Shot Object Detection'] | [Link](https://github.com/dvlab-research/VisionReasoner) | N/A |
| [Neuro-Symbolic Query Compiler](https://arxiv.org/abs/2505.11932) | jrwen, wuyongkang, lixiaoxi45, douzc, KeriaZhang | - This paper introduces QCompiler, a neuro-symbolic framework designed to enhance Retrieval-Augmented Generation (RAG) systems' ability to handle complex queries. - QCompiler uses a Backus-Naur Form (BNF) grammar to formalize complex queries, minimizing redundancy and ensuring completeness. - The framework comprises a Query Expression Translator, a Lexical Syntax Parser, and a Recursive Descent Processor to compile queries into Abstract Syntax Trees (ASTs). - Experiments on multiple benchmarks demonstrate that QCompiler significantly improves the accuracy and efficiency of RAG systems in addressing complex queries compared to existing methods. - The atomicity of sub-queries in leaf nodes of the AST ensures precise document retrieval and response generation. | ['Question Answering'] | [Link](https://github.com/YuyaoZhangQAQ/Query_Compiler) | N/A |
| [Model Merging in Pre-training of Large Language Models](https://arxiv.org/abs/2505.12082) | Jing Liu, Chaoyi Zhang, Shen Yan, Yiyuan Ma, Yunshui Li | - This paper introduces Pre-trained Model Averaging (PMA), a novel technique for enhancing large language models (LLMs) during pre-training. - PMA merges checkpoints from the stable training phase, resulting in consistent performance improvements across various model sizes and architectures (dense and Mixture-of-Experts). - Experiments demonstrate that PMA achieves comparable or superior performance to traditional annealing methods, offering faster validation cycles and significant computational savings. - The optimal merging interval and number of checkpoints scale with model size, and incorporating more checkpoints generally improves performance. - PMA can also be used to stabilize training by initializing consecutive training (CT) and supervised fine-tuning (SFT) stages with PMA-applied checkpoints, leading to more reliable recovery from unstable trajectories. | ['Natural Language Processing'] | N/A | N/A |
| [When AI Co-Scientists Fail: SPOT-a Benchmark for Automated Verification
  of Scientific Research](https://arxiv.org/abs/2505.11855) | sngwon, Cartinoe5930, HazelNam, JW17, amphora | This paper introduces SPOT, a new benchmark dataset for evaluating the ability of Large Language Models (LLMs) to perform automated verification of scientific research. The dataset consists of 83 published papers paired with 91 manually-annotated errors, validated by authors and human annotators. The authors evaluate the performance of various state-of-the-art LLMs on SPOT, finding that none achieve satisfactory results, highlighting a significant gap between current LLM capabilities and the requirements for dependable AI-assisted academic verification.  The benchmark is multi-modal, containing both text and image data. The authors also present case studies and further analysis on the impact of context length and multi-modality on model performance. | ['Multimodal'] | [Link](https://github.com/guijinSON/ai4s_r2.git) | [Link](https://huggingface.co/datasets/amphora/SPOT-MetaData) |
| [SoftCoT++: Test-Time Scaling with Soft Chain-of-Thought Reasoning](https://arxiv.org/abs/2505.11484) | Chunyan Miao, Xu Guo, Aver3, xuyige | - SoftCoT++, a novel framework, extends SoftCoT for test-time scaling in the continuous latent space of the chain-of-thought reasoning process. - It introduces multiple specialized initial tokens and contrastive learning to generate diverse soft thought representations. - Experiments across five reasoning benchmarks and two LLMs demonstrate that SoftCoT++ significantly outperforms SoftCoT and other baselines. - SoftCoT++'s performance is consistent across different architectures and tasks, highlighting its versatility. - The method's effectiveness is shown by its ability to amplify the scaling effect when combined with self-consistency, indicating the orthogonality of scaling the thinking and reasoning stages. | ['Natural Language Processing', 'Text Generation', 'Text2Text Generation', 'Question Answering'] | [Link](https://github.com/xuyige/SoftCoT) | N/A |
| [Tiny QA Benchmark++: Ultra-Lightweight, Synthetic Multilingual Dataset
  Generation & Smoke-Tests for Continuous LLM Evaluation](https://arxiv.org/abs/2505.12058) | vincentkoc | - This paper introduces Tiny QA Benchmark++ (TQB++), an ultra-lightweight evaluation suite designed for rapid LLM evaluation. - TQB++ consists of a small, hand-crafted English QA dataset and a Python-based synthetic data generation toolkit which creates multilingual datasets for various languages. - The toolkit uses LiteLLM to allow users to generate datasets using different LLMs. - The authors demonstrate how TQB++ helps in exposing critical failures in LLMs and detecting regressions in LLMOps workflows by using various models and datasets. - The dataset, generator script, and related tools are open-sourced and hosted on the Hugging Face Hub and GitHub. | ['Question Answering'] | [Link](https://github.com/vincentkoc/tiny_qa_benchmark_pp) | [Link](https://huggingface.co/datasets/vincentkoc/tiny_qa_benchmark_pp) |
| [HelpSteer3-Preference: Open Human-Annotated Preference Data across
  Diverse Tasks and Languages](https://arxiv.org/abs/2505.11475) | Felipe Soares, Hoo-Chang Shin, Olivier Delalleau, Jiaqi Zeng, Zhilin Wang | This paper introduces HelpSteer3-Preference, a high-quality human-annotated preference dataset with over 40,000 samples covering diverse real-world LLM applications.  It improves upon existing datasets by offering enhanced quality and diversity, encompassing STEM, coding, and multilingual scenarios. Reward models trained on this dataset achieve state-of-the-art performance on RM-Bench (82.4%) and JudgeBench (73.7%). The dataset is available under a permissive CC-BY-4.0 license.  The authors further demonstrate the dataset's applicability to training generative reward models and aligning policy models with RLHF. | ['Natural Language Processing'] | N/A | [Link](https://huggingface.co/datasets/nvidia/HelpSteer3#preference) |
| [Fast, Not Fancy: Rethinking G2P with Rich Data and Rule-Based Models](https://arxiv.org/abs/2505.12973) | Hamid R. Rabiee, Zahra Dehghanian, Mahta Fetrat Qharabagh | This paper introduces HomoRich, a new large-scale Persian homograph dataset created using a semi-automated pipeline that leverages LLMs.  The authors propose two novel G2P tools: Homo-GE2PE, a fine-tuned neural model, and HomoFast eSpeak, an enhanced rule-based system.  Experiments show Homo-GE2PE improves homograph disambiguation accuracy by 29.72% and HomoFast eSpeak shows a 30.66% improvement.  The dataset and code are publicly available. | ['Text-to-Speech'] | [Link](https://github.com/MahtaFetrat/Homo-GE2PE-Persian), [Link](https://github.com/MahtaFetrat/HomoFast-eSpeak-Persian), [Link](https://github.com/MahtaFetrat/Persian-G2P-Tools-Benchmark) | [Link](https://huggingface.co/datasets/MahtaFetrat/HomoRich-G2P-Persian) |
| [LLM Context Conditioning and PWP Prompting for Multimodal Validation of
  Chemical Formulas](https://arxiv.org/abs/2505.12257) | PChemGuy | - This paper explores the use of Large Language Models (LLMs) for multimodal validation of chemical formulas in scientific documents. - It introduces a novel methodology that combines structured LLM context conditioning with Persistent Workflow Prompting (PWP) principles to improve the reliability of LLMs for such tasks. - The proposed approach is tested on a complex test paper with known textual and image-based errors, demonstrating improved accuracy in identifying errors compared to simpler prompting techniques. - Notably, the method enables the LLM to repeatedly identify a subtle image-based error overlooked during manual review. - The findings highlight the potential of PWP-informed context conditioning as a promising technique for developing more robust LLM-driven analytical workflows for scientific and technical documents. | ['Multimodal'] | N/A | N/A |
| [TechniqueRAG: Retrieval Augmented Generation for Adversarial Technique
  Annotation in Cyber Threat Intelligence Text](https://arxiv.org/abs/2505.11988) | mparvez, TahaSencar, utsavshukla, lekssays | - This paper introduces TECHNIQUERAG, a novel retrieval-augmented generation (RAG) framework for annotating adversarial techniques in cyber threat intelligence text. - TECHNIQUERAG mitigates data scarcity by fine-tuning only the generation component on limited in-domain examples, unlike resource-intensive methods. - It enhances retrieval quality and domain specificity through zero-shot LLM re-ranking, which aligns retrieved candidates with adversarial techniques. - Experiments on multiple security benchmarks show that TECHNIQUERAG achieves state-of-the-art performance without extensive task-specific optimizations or labeled data. - Comprehensive analysis further reveals insights into the framework's strengths and limitations. | ['Text Classification', 'Text Generation', 'Text2Text Generation'] | [Link](https://github.com/qcri/TechniqueRAG) | N/A |
| [AI-Driven Scholarly Peer Review via Persistent Workflow Prompting,
  Meta-Prompting, and Meta-Reasoning](https://arxiv.org/abs/2505.03332) | PChemGuy |  - This paper introduces Persistent Workflow Prompting (PWP), a novel prompt engineering methodology for guiding LLMs through complex analytical tasks such as scholarly peer review.  - PWP employs a hierarchical prompt structure to systematically codify expert workflows and mitigate LLM input bias.  - The authors demonstrate PWP's effectiveness through a proof-of-concept application to experimental chemistry manuscript reviews, showing that LLMs guided by PWP can reliably identify major methodological flaws.  - A key advantage of PWP is its ability to guide complex reasoning through standard LLM chat interfaces without requiring specialized APIs or coding.  - The paper further explores meta-prompting and meta-reasoning techniques for refining and formalizing complex prompts and workflows. | ['Natural Language Processing'] | N/A | N/A |
