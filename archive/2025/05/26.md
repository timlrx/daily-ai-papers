

## Papers for 2025-05-26

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [Reasoning Model is Stubborn: Diagnosing Instruction Overriding in
  Reasoning Models](https://arxiv.org/abs/2505.17225) | Eunho Yang, Hyun Ryu, Chanjae Park, yjyjyj98, jadohu | - This paper introduces ReasoningTrap, a new diagnostic dataset designed to identify and analyze reasoning rigidity in large language models (LLMs). - Reasoning rigidity is defined as the tendency of LLMs to override explicit instructions and default to familiar reasoning patterns, even when those patterns lead to incorrect conclusions. - The dataset contains modified versions of existing mathematical benchmarks and logic puzzles, designed to require deviations from typical reasoning strategies. - By analyzing model performance on ReasoningTrap, the authors identify three distinct modes of contamination caused by reasoning rigidity: Interpretation Overload, Input Distrust, and Partial Instruction Attention. - ReasoningTrap is publicly released to facilitate future research on mitigating reasoning rigidity in LLMs. | ['Natural Language Processing'] | N/A | N/A |
| [One RL to See Them All: Visual Triple Unified Reinforcement Learning](https://arxiv.org/abs/2505.18129) | Pengfei Li, Shaoxiang Chen, Linge Du, Yan Ma, Ryan1122 | - This paper introduces V-Triune, a Visual Triple Unified Reinforcement Learning system that enables Vision-Language Models to jointly learn visual reasoning and perception tasks within a single training pipeline.  - V-Triune comprises three complementary components: Sample-Level Data Formatting, Verifier-Level Reward Computation, and Source-Level Metric Monitoring.  - A novel Dynamic IoU reward is introduced, providing adaptive and progressive feedback for perception tasks.  - The resulting model, Orsta, demonstrates consistent improvements across both reasoning and perception tasks, achieving substantial gains on MEGA-Bench Core (+2.1% to +14.1%).  - V-Triune and Orsta models are publicly available on Github. | ['Reinforcement Learning', 'Multimodal', 'Visual Question Answering', 'Object Detection', 'Image Segmentation', 'Image-to-Text'] | [Link](https://github.com/MiniMax-AI) | N/A |
| [Quartet: Native FP4 Training Can Be Optimal for Large Language Models](https://arxiv.org/abs/2505.14669) | Jiale Chen, Oliver Sieberling, Soroush Tabesh, Andrei Panferov, Roberto L. Castro | - The paper introduces Quartet, a novel algorithm enabling accurate end-to-end FP4 training for large language models (LLMs). - Quartet achieves state-of-the-art accuracy for FP4 precision by maximizing both parameter and data efficiency. - The algorithm is implemented using optimized CUDA kernels tailored for NVIDIA Blackwell GPUs, demonstrating speedups of almost 2x relative to FP8. - Experiments on Llama-type models reveal a new low-precision scaling law that identifies Quartet as a near-optimal low-precision training technique. - The research demonstrates that fully FP4-based training is a competitive alternative to standard-precision and FP8 training. | ['Natural Language Processing'] | [Link](https://github.com/IST-DASLab/Quartet) | N/A |
| [Distilling LLM Agent into Small Models with Retrieval and Code Tools](https://arxiv.org/abs/2505.17612) | Sung Ju Hwang, Jaewoong Cho, Seanie Lee, Jongwon Jeong, Minki Kang | This paper introduces Agent Distillation, a novel framework for transferring the problem-solving capabilities of large language model (LLM)-based agents to smaller language models (SLMs).  The method improves agent distillation by introducing a prompting method called first-thought prefix to enhance teacher-generated trajectories and a self-consistent action generation method to improve small agents' test-time robustness.  Evaluated on eight reasoning tasks, the results demonstrate that SLMs as small as 0.5B parameters achieve performance competitive with next-tier larger models fine-tuned using chain-of-thought distillation. The proposed agent distillation method consistently improves performance across all model sizes, particularly on out-of-domain tasks. | ['Question Answering'] | [Link](https://github.com/Nardien/agent-distillation) | N/A |
| [PhyX: Does Your Model Have the "Wits" for Physical Reasoning?](https://arxiv.org/abs/2505.15929) | Yunta Hsieh, Qi Han, Hui Shen, John-ai-bee, taki555 |  - This paper introduces PHYX, a large-scale benchmark for evaluating multimodal models' capacity for physics-grounded reasoning.  - PHYX includes 3000 meticulously curated multimodal questions spanning 6 reasoning types across 25 sub-domains and 6 core physics domains.  - State-of-the-art models achieve only around 45% accuracy on PHYX, significantly underperforming human experts, revealing critical limitations in current models.  - The evaluation protocol uses widely used toolkits such as VLMEvalKit, enabling one-click evaluation and ensures reproducibility.  - The authors provide fine-grained statistics, detailed case studies, and multiple evaluation paradigms for comprehensive analysis of physical reasoning capabilities. | ['Multimodal', 'Visual Question Answering'] | [Link](https://phyx-bench.github.io/) | N/A |
| [QwenLong-CPRS: Towards infty-LLMs with Dynamic Context Optimization](https://arxiv.org/abs/2505.18092) | Shaopeng Lai, Shengyi Liao, Chenliang Li, Weizhou Shen, Wanfq | - QWENLONG-CPRS is a novel context compression framework designed for optimizing long-context processing in large language models (LLMs). - It introduces a dynamic context optimization mechanism that compresses input contexts into query-specific content at varying granularities. - The framework comprises four key innovations: natural language-guided dynamic optimization, bidirectional reasoning layers, token critic mechanisms, and window-parallel inference. - Evaluations across five benchmarks demonstrate QWENLONG-CPRS's threefold effectiveness: consistent superiority over existing methods, architecture-agnostic integration with various LLMs, and establishment of new state-of-the-art performance. - QWENLONG-CPRS achieves significant context compression (up to 290.5 times) and performance gains (up to 19.15 points) while maintaining high efficiency. | ['Natural Language Processing'] | [Link](https://github.com/Tongyi-Zhiwen/QwenLong-CPRS) | [Link](https://huggingface.co/Tongyi-Zhiwen/QwenLong-CPRS-7B) |
| [VeriThinker: Learning to Verify Makes Reasoning Model Efficient](https://arxiv.org/abs/2505.17941) | Xinchao Wang, Ruonan Yu, Gongfan Fang, Xinyin Ma, Zigeng |  - VeriThinker is a novel approach for Chain-of-Thought (CoT) compression in Large Reasoning Models (LRMs) that avoids the need for synthetic data.   - It uses Supervised Verification Fine-Tuning (SVFT), where the model is trained on an auxiliary verification task to distinguish correct from incorrect CoT solutions.   - This approach significantly reduces the length of reasoning chains while maintaining or improving accuracy across multiple mathematical reasoning benchmarks.   - VeriThinker also generalizes to solution-wise speculative reasoning, further enhancing efficiency.   - Experimental results demonstrate that VeriThinker achieves effective CoT compression without relying on synthetic concise CoT data, outperforming existing SFT or RL-based methods. | ['Natural Language Processing', 'Question Answering'] | [Link](https://github.com/czg1225/VeriThinker) | N/A |
| [MOOSE-Chem3: Toward Experiment-Guided Hypothesis Ranking via Simulated
  Experimental Feedback](https://arxiv.org/abs/2505.17873) | Lidong Bing, Jue Wang, di-zhang-fdu, ZonglinY, wanhaoliu | - This paper introduces the task of experiment-guided hypothesis ranking, aiming to prioritize hypotheses based on experimental feedback. - A novel simulator, CSX-Sim, is developed to address the challenge of limited access to real experimental data in chemistry, grounded on three foundational assumptions. - CSX-Rank, a pseudo experiment-guided ranking method, is proposed, which clusters hypotheses based on functional characteristics and utilizes simulated experimental feedback. - Experimental results demonstrate that CSX-Rank outperforms pre-experiment ranking baselines and strong ablation variants, with a reduction in trials required to identify optimal hypotheses by more than 50%. - The study contributes to automated scientific discovery, particularly in chemistry, by providing a more efficient hypothesis selection process. | ['Natural Language Processing'] | [Link](https://github.com/wanhaoliu/ChemsimX.git) | [Link](None) |
| [AudioTrust: Benchmarking the Multifaceted Trustworthiness of Audio Large
  Language Models](https://arxiv.org/abs/2505.16211) | Jirui Han, Yile Liu, Can Shen, Kai Li, jiaxiaojunQAQ | The paper introduces AudioTrust, a comprehensive benchmark for evaluating the trustworthiness of Audio Large Language Models (ALLMs).  It assesses ALLMs across six key dimensions: fairness, hallucination, safety, privacy, robustness, and authentication.  AudioTrust uses a meticulously constructed dataset of over 4,420 audio/text samples from real-world scenarios.  The benchmark employs 9 audio-specific evaluation metrics and uses a large-scale automated pipeline for objective and scalable scoring.  Results show trustworthiness boundaries and limitations of current ALLMs. | ['Audio'] | [Link](https://github.com/JusperLee/AudioTrust) | [Link](https://huggingface.co/datasets/JusperLee/AudioTrust) |
| [Scaling Image and Video Generation via Test-Time Evolutionary Search](https://arxiv.org/abs/2505.17618) | Di Zhang, Pengfei Wan, Xintao Wang, Jiajun Liang, haoranhe |  - This paper introduces EvoSearch, a novel test-time scaling framework that enhances the scalability of image and video generation models by allocating more compute at inference time. - EvoSearch reformulates test-time scaling as an evolutionary search problem, leveraging principles from biological evolution to iteratively generate higher-quality samples. - The method is applicable to both diffusion and flow models and does not require additional training or model expansion. - Extensive experiments demonstrate that EvoSearch significantly improves sample quality and diversity across various models and tasks, outperforming existing methods. - Notably, EvoSearch enables a 1.3B parameter model to surpass a 14B parameter model with 10x fewer parameters in video generation. | ['Text-to-Image', 'Text-to-Video', 'Multimodal'] | [Link](https://github.com/tinnerhrhe/evosearch) | N/A |
| [FullFront: Benchmarking MLLMs Across the Full Front-End Engineering
  Workflow](https://arxiv.org/abs/2505.17399) | Yu Cheng, Linjie Li, Huichen Will Wang, Haoyu Sun, Kuvvi | - FullFront, a novel benchmark, evaluates Multimodal Large Language Models (MLLMs) across the entire front-end engineering workflow, encompassing conceptualization, comprehension, and implementation. - Unlike existing benchmarks that focus on isolated tasks, FullFront assesses three crucial stages: Webpage Design, Webpage Perception QA, and Webpage Code Generation. - The benchmark employs a two-stage process to transform real-world webpages into clean, standardized HTML, resolving copyright concerns and data inconsistencies. - Evaluation reveals significant MLLM limitations in page perception, code generation (especially handling images and layouts), and interaction implementation, highlighting performance discrepancies between open-source and proprietary models. - FullFront offers a comprehensive, multi-faceted evaluation pipeline and code, advancing research in MLLM capabilities for front-end engineering. | ['Multimodal'] | [Link](https://github.com/Mikivishy/FullFront) | N/A |
| [Teaching with Lies: Curriculum DPO on Synthetic Negatives for
  Hallucination Detection](https://arxiv.org/abs/2505.17558) | Ying Ding, Liu Leqi, ashwinnv, SP2001 | - This paper introduces HaluCheck, a novel hallucination detection model that leverages a curriculum learning strategy with Direct Preference Optimization (DPO). - HaluCheck uses high-quality hallucinated samples as negative examples in the DPO alignment process, improving performance over using standard negative samples. - The model demonstrates significant improvements of up to 24% on benchmarks like MedHallu and HaluEval, outperforming larger state-of-the-art models. - HaluCheck also shows robustness in zero-shot settings across multiple benchmarks and domains. - The authors introduce a curriculum learning strategy that gradually transitions the training from easier to harder samples, ensuring stable and incremental learning. | ['Natural Language Processing', 'Text Classification', 'Question Answering'] | [Link](https://teachingwithlies.github.io/) | N/A |
| [Teaching Large Language Models to Maintain Contextual Faithfulness via
  Synthetic Tasks and Reinforcement Learning](https://arxiv.org/abs/2505.16483) | Zhitong Wang, Yuzhuo Bai, Cheng Gao, Shuzheng Si, BleachNick | This paper introduces CANOE, a novel framework designed to enhance the contextual faithfulness of large language models (LLMs).  CANOE leverages synthetic short-form question-answering (QA) data and a rule-based reinforcement learning method called Dual-GRPO to achieve this goal.  The Dual-GRPO method employs three tailored rewards and simultaneously optimizes both short-form and long-form response generation, eliminating the need for manual data labeling. Experimental results on 11 downstream tasks indicate that CANOE significantly improves LLM faithfulness and outperforms existing state-of-the-art models in multiple cases. | ['Natural Language Processing', 'Reinforcement Learning', 'Text Generation', 'Question Answering'] | [Link](https://github.com/S1s-Z/CANOE) | N/A |
| [Time-R1: Towards Comprehensive Temporal Reasoning in LLMs](https://arxiv.org/abs/2505.13508) | Jiaxuan You, Haoru Li, Haofei Yu, Peixuan Han, m-serious |  - Time-R1 is a novel framework that enhances a 3B-parameter LLM with comprehensive temporal reasoning abilities, encompassing understanding, prediction, and creative generation.  - It employs a three-stage reinforcement learning curriculum with a dynamic reward system, progressively building foundational understanding, future prediction skills, and creative scenario generation capabilities.  - Time-R1 surpasses models over 200 times larger, including the state-of-the-art 671B DeepSeek-R1, on challenging benchmarks involving future event prediction and creative scenario generation.  - The study provides strong evidence that smaller, efficient models can achieve superior temporal performance via thoughtfully engineered progressive reinforcement learning.  - Time-Bench, a large-scale multi-task temporal reasoning dataset derived from 10 years of news data, is released to facilitate further research. | ['Reinforcement Learning', 'Natural Language Processing', 'Time Series Forecasting'] | [Link](https://github.com/ulab-uiuc/Time-R1) | [Link](https://huggingface.co/collections/ulab-ai/time-r1-682626aea47cb2b876285a16) |
| [Speechless: Speech Instruction Training Without Speech for Low Resource
  Languages](https://arxiv.org/abs/2505.17417) | Shreyas Gopal, Tuan Le Duc Anh, Huy Hoang Ha, Dinh Bach Vu, alandao | - The paper introduces Speechless, a novel method for generating synthetic training data for early-fusion speech language models without using traditional text-to-speech (TTS) systems. - Speechless leverages a quantized Whisper encoder to generate semantic speech tokens, bypassing the need for waveform generation, making it particularly useful for low-resource languages. - The proposed method achieves competitive automatic speech recognition (ASR) performance on Vietnamese, a low-resource language, without speech-based fine-tuning, showcasing its effectiveness. - Speechless demonstrates comparable performance to Llama-Omni on VoiceBench, a benchmark for evaluating speech instruction tuning, but underperforms some more recent models. - A new pre-tokenized Vietnamese instruction dataset is released to facilitate further research and development in speech-language models for low-resource languages. | ['Automatic Speech Recognition', 'Text-to-Audio', 'Multimodal'] | [Link](https://github.com/menloresearch/ichigo/tree/legacy/main) | [Link](https://huggingface.co/Menlo/Speechless-llama3.2-v0.1), [Link](https://huggingface.co/datasets/Menlo/Ichigo-instruction-tokenized-v0.2), [Link](https://huggingface.co/Menlo/Ichigo-whisper-v0.1) |
| [RBench-V: A Primary Assessment for Visual Reasoning Models with
  Multi-modal Outputs](https://arxiv.org/abs/2505.16770) | Qianrui Yang, uyzhang, Mo-ZheHan, CXY07, MenghaoGuo | - This paper introduces RBench-V, a new benchmark designed to evaluate the visual reasoning capabilities of multimodal models, focusing specifically on their ability to generate multi-modal outputs (not just process them). - RBench-V contains 803 questions covering math, physics, counting, and games, requiring image manipulation and generation as part of the solution process. - Evaluation of numerous open- and closed-source models on RBench-V reveals a significant performance gap between models and human experts (25.8% accuracy vs. 82.3% human accuracy), highlighting the challenges of multimodal reasoning. - The benchmark highlights the fact that current models struggle to effectively leverage multi-modal reasoning, even the best performing models achieve low accuracy. - The authors suggest the need for new paradigms, such as incorporating multi-modal chain of thought (M-CoT) or agent-based reasoning frameworks, to improve the performance of multimodal reasoning models. | ['Multimodal', 'Visual Question Answering'] | [Link](https://evalmodels.github.io/rbenchv) | N/A |
| [s3: You Don't Need That Much Data to Train a Search Agent via RL](https://arxiv.org/abs/2505.14146) | Zifeng Wang, Jinfeng Xiao, Jiacheng Lin, Xueqiang Xu, Pengcheng Jiang | - This paper introduces s3, a lightweight, model-agnostic framework that trains a search agent using reinforcement learning to improve the accuracy of large language models (LLMs) in question answering. - s3 decouples the searcher from the generator, training only the searcher using a novel reward signal called Gain Beyond RAG (GBR), which measures the improvement in generation accuracy over naive RAG. - The results show that s3 outperforms other baselines on six general QA and five medical QA benchmarks, achieving stronger downstream performance with significantly less training data (2.4k samples compared to 70x more for other methods). - s3 is a modular framework, making it compatible with various frozen or proprietary LLMs and facilitating targeted optimization of retrieval quality. - The approach addresses the limitations of existing methods that either use search-only metrics or jointly optimize retrieval and generation, often limiting real search utility and entanglement with the LLM. | ['Reinforcement Learning', 'Question Answering'] | [Link](https://github.com/pat-jj/s3) | N/A |
| [Transformer Copilot: Learning from The Mistake Log in LLM Fine-tuning](https://arxiv.org/abs/2505.16270) | Ruizhong Qiu, Yunzhe Qi, Zihao Li, Yikun Ban, jiaruz2 |  - This paper introduces Transformer Copilot, a novel framework that enhances the inference performance of pre-trained LLMs by learning from their mistakes during fine-tuning. - The framework comprises three key components: a novel Copilot model design, a joint training paradigm, and a fused inference paradigm. - The Copilot model rectifies the Pilot model's logits using a Mistake Log that systematically tracks the model's learning behavior and recurring errors. - Experiments on 12 benchmarks demonstrate that Transformer Copilot improves performance by up to 34.5%, while introducing marginal computational overhead. - The method exhibits strong scalability and transferability, outperforming several strong baselines with fewer parameters. | ['Natural Language Processing', 'Text Generation', 'Text2Text Generation'] | [Link](https://github.com/jiaruzouu/TransformerCopilot) | [Link](https://huggingface.co/docs/transformers/main/en/index) |
| [Are Vision-Language Models Safe in the Wild? A Meme-Based Benchmark
  Study](https://arxiv.org/abs/2505.15389) | Hwanjo Yu, Jihae Jeong, Joonwon Jang, oneonlee |  - This paper introduces MEMESAFETYBENCH, a new benchmark dataset designed to evaluate the safety of vision-language models (VLMs) using real-world meme images. - The dataset contains 50,430 instances pairing meme images with harmful and benign instructions, enabling a more comprehensive evaluation of VLM safety in real-world contexts. - Results show that VLMs are more vulnerable to meme-based harmful prompts than to synthetic or typographic images, highlighting the need for stronger safety mechanisms. - The study also analyzes the mitigating effects of conversational context and the relationship between model scale and safety metrics. - Overall, the findings demonstrate that existing benchmarks that utilize artificial visual inputs fail to adequately capture real-world vulnerabilities. | ['Multimodal'] | N/A | N/A |
| [Large Language Models Implicitly Learn to See and Hear Just By Reading](https://arxiv.org/abs/2505.17091) | Mert Pilanci, Prateek Verma | - This paper introduces a novel approach that leverages pre-trained text LLMs to perform image and audio classification without using modality-specific encoders. - The method involves replacing the traditional Vision Transformer (ViT) or Audio Transformer with a text LLM, thereby enabling the model to implicitly learn to "see" and "hear" through textual training. - Experimental results demonstrate the effectiveness of this approach across multiple datasets (CIFAR-10, Fashion-MNIST, FSD-50K, GTZAN), showcasing competitive performance with architectures trained from scratch and even outperforming those with frozen weights. - The paper highlights the potential for transfer learning and efficient fine-tuning, particularly using Low-Rank Adaptation (LoRA), to adapt pretrained LLMs for various tasks and modalities. - The study contributes to understanding the emergent capabilities of large language models and their potential to solve tasks beyond their initial training scope. | ['Audio Classification', 'Image Classification', 'Multimodal'] | N/A | N/A |
| [Augmenting LLM Reasoning with Dynamic Notes Writing for Complex QA](https://arxiv.org/abs/2505.16293) | Sai Rajeswar, Shiva Krishna Reddy Malay, Khyati Mahajan, Masoud Hashemi, rmahesh | This paper introduces NotesWriting, a method for augmenting Large Language Model (LLM) reasoning in complex question answering by generating concise and relevant notes from retrieved documents at each step.  NotesWriting addresses context overload and information noise in iterative Retrieval Augmented Generation (RAG).  Experiments across three iterative RAG methods, two LLMs, and four evaluation datasets show an average improvement of 15.6 percentage points, with minimal increase in output tokens.  The method is framework-agnostic and can be easily integrated with different iterative RAG methods, improving both efficiency and scalability.  | ['Question Answering'] | N/A | N/A |
| [NOVER: Incentive Training for Language Models via Verifier-Free
  Reinforcement Learning](https://arxiv.org/abs/2505.16022) | Yali Du, Chen Qian, Xinyu Wang, Siya Qi, Wei Liu | - This paper introduces NOVER, a novel verifier-free reinforcement learning framework for incentive training in language models. - NOVER computes rewards solely based on the model's reasoning process, enabling incentive training across various text-to-text tasks without external verifiers. - Experimental results demonstrate that NOVER outperforms models of the same size distilled from large reasoning models by 7.7% on several benchmark datasets. - The framework's flexibility allows for optimizing large language models through techniques like inverse incentive training. - NOVER addresses the limitations of existing incentive training methods that rely on external verifiers, which are often expensive and limited in applicability. | ['Reinforcement Learning', 'Text2Text Generation'] | [Link](https://github.com/thinkwee/NOVER) | N/A |
| [Keep Security! Benchmarking Security Policy Preservation in Large
  Language Model Contexts Against Indirect Attacks in Question Answering](https://arxiv.org/abs/2505.15805) | Hwanhee Lee, Yonghyun Jun, Yumin Kim, HwanChang0106 | - This paper introduces CoPriva, a new large-scale benchmark dataset for evaluating the ability of Large Language Models (LLMs) to adhere to user-defined security policies in question answering, especially against indirect attacks. - CoPriva includes realistic contexts, explicit policies, and queries designed as direct and challenging indirect attacks seeking prohibited information. - The evaluation of 10 LLMs on CoPriva reveals a significant vulnerability: many models violate user-defined policies and leak sensitive information, particularly against indirect attacks. - The analysis reveals that while models can often identify the correct answer, they struggle to incorporate policy constraints during generation, highlighting a critical gap in current LLM safety alignment. - The findings underscore the urgent need for more robust methods to guarantee contextual security in sensitive applications. | ['Question Answering'] | N/A | N/A |
| [TIME: A Multi-level Benchmark for Temporal Reasoning of LLMs in
  Real-World Scenarios](https://arxiv.org/abs/2505.12891) | Tianyi Zhuang, Wen Luo, Wei Li, Shaohang Wei, songff |  - This paper introduces TIME, a multi-level benchmark for evaluating the temporal reasoning capabilities of Large Language Models (LLMs) in real-world scenarios. - TIME consists of 38,522 question-answer pairs covering three levels with eleven fine-grained sub-tasks, encompassing three sub-datasets (TIME-WIKI, TIME-NEWS, and TIME-DIAL). - The benchmark incorporates challenges such as intensive temporal information, fast-changing event dynamics, and complex temporal dependencies in social interactions. - Extensive experiments are conducted on various reasoning and non-reasoning models, providing insights into the impact of test-time scaling on temporal reasoning performance. - A human-annotated subset, TIME-LITE, is also released to facilitate future research and standardized evaluation in temporal reasoning. | ['Question Answering'] | [Link](https://github.com/sylvain-wei/TIME) | [Link](https://huggingface.co/datasets/SylvainWei/TIME) |
| [Not All Models Suit Expert Offloading: On Local Routing Consistency of
  Mixture-of-Expert Models](https://arxiv.org/abs/2505.16056) | Duyu Tang, Yitong Li, Miren Tian, Siyuan Wang, ljcleo | This paper introduces two metrics, SRP and SCH, to measure the local routing consistency of Mixture-of-Expert (MoE) models.  The study analyzes 20 MoE LLMs, revealing that models applying MoE on every layer without shared experts exhibit the highest consistency. Domain-specialized experts contribute more to routing consistency than vocabulary-specialized ones.  Finally, the research demonstrates that most models can effectively balance cache size and efficiency with cache sizes approximately twice the number of active experts.  The code for replicating experiments is publicly available. | ['Natural Language Processing'] | [Link](https://github.com/ljcleo/moe-lrc) | N/A |
