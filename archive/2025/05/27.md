

## Papers for 2025-05-27

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [Shifting AI Efficiency From Model-Centric to Data-Centric Compression](https://arxiv.org/abs/2505.19147) | Pppeach33, coderchen01, Steven-Shaobo, zichenwen, xuyang-liu16 |  - This paper advocates for a paradigm shift in AI efficiency research, moving from model-centric to data-centric compression, focusing on token compression. - The authors introduce a unified mathematical framework that encompasses existing model efficiency strategies, and argue that the quadratic cost of self-attention in LLMs is now a primary bottleneck.  - Token compression methods aim to improve AI efficiency by reducing the number of tokens during model training or inference. - The authors analyze current challenges and outline promising future directions for token compression research.  -  The study systematically reviews the research landscape of token compression, and presents compelling advantages and challenges. | ['Natural Language Processing', 'Computer Vision', 'Multimodal'] | [Link](https://github.com/xuyang-liu16/Awesome-Token-level-Model-Compression) | N/A |
| [BizFinBench: A Business-Driven Real-World Financial Benchmark for
  Evaluating LLMs](https://arxiv.org/abs/2505.19457) | Ji Liu, Qlisp, Tinker250, xuntao, guilong |  - BizFinBench, a new benchmark for evaluating LLMs in real-world financial applications, is introduced. It comprises 6,781 well-annotated queries in Chinese, covering five dimensions and nine fine-grained categories.  - IteraJudge, a novel LLM evaluation method, is presented to mitigate bias when LLMs serve as evaluators, enhancing the robustness and reliability of the benchmark.  - Experiments on 25 LLMs, including both proprietary and open-source models, reveal that while current LLMs handle routine financial queries proficiently, complex scenarios demand significant improvement.  - The benchmark highlights the capabilities of different LLMs across various financial tasks, uncovering distinct capability patterns, such as the stronger performance of proprietary models in reasoning.  - BizFinBench offers a rigorous, business-aligned benchmark for future research; the dataset and code are publicly available. | ['Natural Language Processing', 'Question Answering', 'Text Classification'] | [Link](https://github.com/HiThink-Research/BizFinBench) | N/A |
| [PATS: Process-Level Adaptive Thinking Mode Switching](https://arxiv.org/abs/2505.19250) | Shujian Huang, Jiajun Chen, Shimao Zhang, master-lan, Yi53 | - This paper introduces PATS (Process-Level Adaptive Thinking Mode Switching), a novel reasoning paradigm that dynamically adjusts the reasoning strategy of LLMs based on the difficulty of each reasoning step. - PATS integrates Process Reward Models (PRMs) with Beam Search, incorporating progressive mode switching and bad-step penalty mechanisms to optimize the balance between accuracy and computational efficiency. - Experiments on various mathematical benchmarks demonstrate that PATS achieves high accuracy with moderate token usage, outperforming existing methods that use a fixed reasoning strategy. - The analysis of PATS highlights the significance of process-level, difficulty-aware reasoning strategy adaptation, offering valuable insights into efficient inference for LLMs. - Future work involves extending the experiments to larger-scale models and exploring alternative evaluation methods to further validate the proposed paradigm. | ['Question Answering'] | [Link](https://github.com/NJUNLP/PATS) | N/A |
| [ARM: Adaptive Reasoning Model](https://arxiv.org/abs/2505.20258) | Kai Zhang, Aili Chen, Arist12, hsaest, Siye01 | - This paper introduces the Adaptive Reasoning Model (ARM), a novel reasoning model that dynamically selects appropriate reasoning formats based on task difficulty. - ARM incorporates three efficient reasoning formats (Direct Answer, Short CoT, and Code) alongside a more elaborate format (Long CoT) to enhance efficiency. - The model is trained using Ada-GRPO, an improved version of Group Relative Policy Optimization (GRPO), which mitigates the format collapse issue and improves training speed. - Experimental results demonstrate that ARM achieves comparable performance to models solely using Long CoT while reducing the token count by an average of 30% and up to 70%. - In addition to the adaptive mode, ARM offers instruction-guided and consensus-guided modes for better control and performance prioritization. | ['Question Answering'] | [Link](https://team-arm.github.io/arm) | N/A |
| [B-score: Detecting biases in large language models using response
  history](https://arxiv.org/abs/2505.18545) | Daeyoung Kim, anhng8, taesiri, anvo25 | The paper introduces B-score, a novel metric for detecting biases in LLMs using response history.  The study finds that LLMs can reduce bias when allowed to observe previous answers in multi-turn conversations, particularly in random questions.  B-score is shown to significantly improve answer verification accuracy compared to using confidence scores or single-turn answers alone on benchmark datasets (MMLU, HLE, CSQA).  A 2-step verification framework using B-score is also proposed and tested.  The code and data are available at b-score.github.io. | ['Question Answering'] | [Link](https://github.com/b-score/b-score) | [Link](string) |
| [Deciphering Trajectory-Aided LLM Reasoning: An Optimization Perspective](https://arxiv.org/abs/2505.19815) | Linchen Xiao, Hongwei Liu, zsytony, Sudanl, jnanliu | This paper introduces a novel framework, RAML, which interprets LLM reasoning through the lens of meta-learning.  Reasoning trajectories are formalized as pseudo-gradient descent updates to the LLM's parameters, providing a novel way to understand and analyze LLM reasoning.  Empirical evaluations on mathematical reasoning tasks using QwQ-32B and other LLMs demonstrate the strong connection between LLM reasoning and meta-learning.  RAML enhances the understanding of LLM reasoning and provides insights for improving LLMs via established meta-learning techniques.  The paper also analyzes the effects of different training strategies (SFT and RL) on the effectiveness of LLM reasoning. | ['Natural Language Processing'] | [Link](https://github.com/open-compass/RaML) | [Link](https://huggingface.co/datasets/AI-MO/aimo-validation-aime) |
| [Lifelong Safety Alignment for Language Models](https://arxiv.org/abs/2505.20259) | Min Lin, Chao Du, Yifei Zhao, Zeyu Qin, Haoyu Wang | - This paper introduces a lifelong safety alignment framework for Language Models (LLMs) that enables continuous adaptation to new and evolving jailbreaking strategies. - The framework uses a competitive setup between a Meta-Attacker, trained to discover novel jailbreaking strategies, and a Defender, trained to resist them. - To warm-up the Meta-Attacker, the authors leverage the GPT-4 API to extract key insights from a large collection of jailbreak-related research papers. - Iterative training leads to the Defender progressively improving its robustness and reducing the Meta-Attacker's success rate to 7%. - The proposed framework demonstrates improved robustness against both seen and unseen attacks compared to existing methods. | ['Natural Language Processing', 'Text Classification', 'Reinforcement Learning'] | [Link](https://github.com/sail-sg/LifelongSafetyAlignment) | N/A |
| [MOOSE-Chem2: Exploring LLM Limits in Fine-Grained Scientific Hypothesis
  Discovery via Hierarchical Search](https://arxiv.org/abs/2505.19209) | Wei Li, Yujie Liu, Ben Gao, Wanhao Liu, ZonglinY | - This paper introduces a novel task of fine-grained scientific hypothesis discovery, focusing on generating detailed, experimentally actionable hypotheses. - It proposes a hierarchical search method to address the combinatorial optimization problem inherent in this task, showing improvements over baseline methods. - The method leverages LLMs' internal heuristics to formulate hypotheses and evaluates the alignment between LLM-judged hypotheses and ground-truth hypotheses. - Experiments on a new chemistry benchmark demonstrate that the proposed method consistently outperforms strong baselines in LLM self-evaluation, expert evaluation, and recall. - The study also explores the impact of using diverse LLMs versus identical LLMs within an ensemble for improved hypothesis generation. | ['Natural Language Processing', 'Text Generation'] | N/A | N/A |
| [Can MLLMs Guide Me Home? A Benchmark Study on Fine-Grained Visual
  Reasoning from Transit Maps](https://arxiv.org/abs/2505.18675) | Lingdong Kong, Shuyi Ouyang, Song Wang, Huan-WhoRegisteredMyName, FSCCS | - This paper introduces REASONMAP, a benchmark dataset designed to evaluate the fine-grained visual understanding and spatial reasoning capabilities of Multimodal Large Language Models (MLLMs). - REASONMAP contains high-resolution transit maps from 30 cities and includes 1008 question-answer pairs covering two question types and three templates. - The dataset is evaluated using a two-level framework assessing both answer correctness and quality, revealing a counterintuitive pattern where base models outperform reasoning models in open-source settings, but the opposite is true for closed-source models. - Experimental results highlight the importance of visual input for strong performance, even with additional textual information. - The study contributes to a deeper understanding of visual reasoning in MLLMs and investigates the gap between open-source and closed-source models. | ['Multimodal', 'Visual Question Answering'] | [Link](https://fscdc.github.io/Reason-Map) | N/A |
| [Reinforcement Fine-Tuning Powers Reasoning Capability of Multimodal
  Large Language Models](https://arxiv.org/abs/2505.18536) | Yifei Zhao, Yifu Luo, Bo Xia, Jiaqi Wu, Haoyuan Sun | This paper explores the effectiveness of reinforcement fine-tuning (RFT) in enhancing the reasoning capabilities of multimodal large language models (MLLMs).  The authors argue that RFT empowers MLLMs with robust reasoning capabilities across diverse modalities, tasks, and domains.  The paper provides a comprehensive overview of existing RFT methods for MLLMs and proposes five promising directions for future research.  A key contribution is the meticulous summarization of advancements in five key areas: diverse modalities, tasks and domains, training algorithms, benchmarks, and engineering frameworks.  Finally, the authors offer recommendations for future research directions to further advance the state-of-the-art in MLLM reasoning. | ['Multimodal', 'Reinforcement Learning'] | [Link](https://github.com/Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs) | N/A |
| [Flex-Judge: Think Once, Judge Anywhere](https://arxiv.org/abs/2505.18601) | Se-Young Yun, Sungwoo Cho, Jongwoo Ko, sungnyun |  - FLEX-Judge is a reasoning-guided multimodal judge model that generalizes across multiple modalities using minimal textual reasoning data. - The model leverages structured textual reasoning explanations to enable effective transfer to multimodal judgments, including images, videos, and audio. - Empirical results demonstrate that FLEX-Judge achieves competitive or superior performance compared to state-of-the-art commercial APIs and extensively trained multimodal evaluators, despite being trained on significantly fewer text data. - FLEX-Judge demonstrates broad impact in modalities like molecule, where evaluation benchmarks are scarce. - The framework highlights reasoning-based text supervision as a powerful cost-effective alternative to traditional annotation-intensive approaches. | ['Multimodal', 'Image-to-Text', 'Image-to-Image', 'Video-Text-to-Text', 'Text-to-Image', 'Audio', 'Text-to-Speech'] | [Link](https://github.com/jongwooko/flex-judge) | N/A |
| [Which Data Attributes Stimulate Math and Code Reasoning? An
  Investigation via Influence Functions](https://arxiv.org/abs/2505.19949) | Zhijie Deng, Zihao Zeng, Hanwen Xu, Qingyuan Tian, Siqi Kou | - This paper introduces Infra, a novel Influence-based Reasoning Attribution technique, to systematically analyze the impact of individual training examples, sequences, and tokens on Large Language Models' (LLMs) reasoning abilities in math and coding tasks. - Infra reveals that high-difficulty math examples improve both math and code reasoning, while low-difficulty code tasks mainly benefit code reasoning; this finding leads to a dataset reweighting strategy that improves AIME24 accuracy by 100% and LiveCodeBench accuracy by approximately 5%. - The study further explores the impact of sequence-level exploratory behaviors (verification, backtracking, etc.) and finds that such behaviors enhance reasoning performance in both domains. - Fine-grained token-level analysis reveals distinct influence patterns for math (natural language logic) and code (structural syntax) reasoning. - Overall, this research provides valuable insights into the factors that contribute to effective data for training LLMs and offers a novel technique for systematically investigating the effects of training data on LLM reasoning abilities. | ['Natural Language Processing'] | N/A | N/A |
| [Omni-R1: Reinforcement Learning for Omnimodal Reasoning via Two-System
  Collaboration](https://arxiv.org/abs/2505.20256) | Zheng Huang, Zongze Du, Muzhi Zhu, Hao Zhong, Canyu | - This paper introduces Omni-R1, a novel two-system architecture for omnimodal reasoning that uses reinforcement learning to address the trade-off between temporal coverage and spatial resolution. - The architecture consists of a Global Reasoning System that selects informative keyframes and a Detail Understanding System that performs pixel-level grounding on the selected snippets. - Omni-R1 is trained end-to-end using Group Relative Policy Optimization (GRPO), resulting in superior performance on two challenging benchmarks, RefAVS and REVOS, compared to existing state-of-the-art models. - The model shows significant improvements in out-of-domain generalization and reduces multimodal hallucination. - This work demonstrates the first successful application of RL to large-scale omnimodal reasoning. | ['Reinforcement Learning', 'Multimodal', 'Video Classification', 'Image Segmentation', 'Video-Text-to-Text', 'Visual Question Answering'] | [Link](https://github.com/aim-uofa/Omni-R1) | N/A |
| [Done Is Better than Perfect: Unlocking Efficient Reasoning by Structured
  Multi-Turn Decomposition](https://arxiv.org/abs/2505.19788) | Zhijie Deng, Hao Zhang, Boxiu Li, Zihao Zeng, ElysiaTrue | - This paper introduces Multi-Turn Decomposition (MinD), a novel method to improve the efficiency of large reasoning models (LRMs). - MinD decomposes the conventional chain-of-thought (CoT) reasoning process into a sequence of explicit, structured, and turn-wise interactions. - The model is trained using a supervised fine-tuning (SFT) approach, followed by reinforcement learning (RL) with the GRPO algorithm to prioritize correct outputs with fewer turns. - Experimental results show that MinD achieves up to ~70% reduction in both output token usage and time to first token (TTFT) on various reasoning benchmarks, while maintaining competitive performance. - The method is shown to generalize well to out-of-distribution benchmarks. | ['Question Answering'] | N/A | N/A |
| [Hard Negative Contrastive Learning for Fine-Grained Geometric
  Understanding in Large Multimodal Models](https://arxiv.org/abs/2505.20152) | Ji Qi, Jiajie Zhang, Zhen Yang, Yushi Bai, Kai Sun | - The paper introduces MMCLIP, a novel hard negative contrastive learning framework to improve geometric reasoning in Large Multimodal Models (LMMs). - MMCLIP uses image-based and text-based contrastive learning with hard negatives generated by perturbing diagram generation code and modifying geometric descriptions. - The proposed model, MMGeoLM, outperforms existing open-source models on three geometric reasoning benchmarks and rivals powerful closed-source models like GPT-40. - Experiments show that using authentic, exam-based images as hard negatives significantly boosts model performance, demonstrating the importance of high-quality negative samples. - The study analyzes the impact of different negative sample construction methods and the number of negative samples on the geometric reasoning performance of LMMs. | ['Multimodal', 'Visual Question Answering'] | [Link](https://github.com/THU-KEG/MMGeoLM) | [Link](null) |
| [The Quest for Efficient Reasoning: A Data-Centric Benchmark to CoT
  Distillation](https://arxiv.org/abs/2505.18759) | Song Wang, Zhen Tan, Rana Muhammad Shahroz Khan, Ruichen Zhang, wjldw | - This paper introduces DC-CoT, the first data-centric benchmark for evaluating chain-of-thought (CoT) distillation in large language models (LLMs). - DC-CoT investigates data manipulation from method, model, and data perspectives, using various teacher and student models. - The benchmark rigorously evaluates the impact of data augmentation, selection, and mixing strategies on student model performance across multiple reasoning datasets. - Findings provide actionable insights and establish best practices for optimizing CoT distillation through data-centric techniques, ultimately facilitating the development of more accessible and capable reasoning models. - The dataset and code are publicly available. | ['Question Answering'] | N/A | N/A |
| [AdaCtrl: Towards Adaptive and Controllable Reasoning via
  Difficulty-Aware Budgeting](https://arxiv.org/abs/2505.18822) | Jiazhan Feng, Zhaochen Su, Wanjun Zhong, Hongru Wang, JoeYing | - AdaCtrl is a novel framework that supports both difficulty-aware adaptive reasoning budget allocation and explicit user control over reasoning depth. - AdaCtrl dynamically adjusts its reasoning length based on self-assessed problem difficulty while also allowing users to manually control the budget. - This is achieved through a two-stage training pipeline: an initial cold-start fine-tuning phase and a difficulty-aware reinforcement learning (RL) stage. - Empirical results show that AdaCtrl adapts reasoning length based on estimated difficulty, yielding performance improvements and simultaneously reducing response length. - AdaCtrl enables precise user control over the reasoning budget, allowing for tailored responses to meet specific needs. | ['Reinforcement Learning', 'Natural Language Processing', 'Question Answering'] | [Link](https://github.com/JoeYing1019/AdaCtrl) | N/A |
| [G1: Bootstrapping Perception and Reasoning Abilities of Vision-Language
  Model via Reinforcement Learning](https://arxiv.org/abs/2505.13426) | Flood Sung, Zhiqi Huang, Tianyu Liu, Hongcheng Gao, Liang Chen | - This paper introduces VLM-Gym, a reinforcement learning environment designed for training vision-language models (VLMs) in visually rich games. - Two models, G0 and G1, are trained using VLM-Gym, demonstrating emergent perception and reasoning abilities. - G1, which incorporates a perception-enhanced cold start, outperforms leading proprietary models like Claude-3.7-Sonnet-Thinking across various games. - Systematic analysis reveals that perception and reasoning abilities mutually bootstrap each other during RL training. - The source code and training details are publicly released to encourage further research in the field. | ['Reinforcement Learning', 'Multimodal'] | [Link](https://github.com/chenllliang/G1) | N/A |
| [The Coverage Principle: A Framework for Understanding Compositional
  Generalization](https://arxiv.org/abs/2505.20278) | Miyoung Ko, Sohee Yang, Hanseul Cho, Jinho Park, Hoyeon Chang |  - This paper introduces the Coverage Principle, a novel framework for understanding compositional generalization in large language models.  - The principle posits that models relying on pattern matching for compositional tasks cannot reliably generalize beyond substituting fragments that yield identical results in the same contexts.  - The authors empirically demonstrate this principle's predictive power using Transformer models on synthetic compositional tasks, confirming the quadratic growth of required training data with token set size and the context-dependent nature of Transformer representations in path-ambiguous tasks.  - They further propose a mechanism-based taxonomy for generalization, distinguishing between structure-based, property-based, and shared-operator generalization.  - This work provides a unified lens for understanding compositional reasoning and highlights the need for fundamental architectural or training innovations to achieve truly systematic compositionality. | ['Natural Language Processing'] | [Link](https://github.com/kaistAI/coverage-principle) | N/A |
| [ModernGBERT: German-only 1B Encoder Model Trained from Scratch](https://arxiv.org/abs/2505.13136) | Andreas Hotho, Fotis Jannidis, Jan Pfister, Julia Wunderle, Anton Ehrmanntraut | - This paper introduces ModernGBERT, a family of German-only encoder models trained from scratch, with sizes of 134M and 1B parameters. - ModernGBERT incorporates architectural innovations from ModernBERT, such as enhanced relative positional embeddings and efficient attention patterns. - The authors evaluate ModernGBERT on various natural language understanding tasks and demonstrate that the 1B parameter model outperforms existing state-of-the-art German encoders. - Additionally, they present LLäMmlein2Vec, a family of encoders derived from German decoder-only models using LLM2Vec, enabling a controlled comparison. - All models, training data, checkpoints, and code are publicly available to foster advancements in German NLP. | ['Natural Language Processing'] | N/A | N/A |
| [Interleaved Reasoning for Large Language Models via Reinforcement
  Learning](https://arxiv.org/abs/2505.19640) | Yanchao Sun, Dong Lin, Deepak Gopinath, David Qiu, Roy Xie | This paper introduces a novel reinforcement learning training paradigm called interleaved reasoning that enhances Large Language Models' (LLMs) reasoning capabilities by interleaving thinking and answering processes.  The approach improves time-to-first-token (TTFT) by over 80% and boosts Pass@1 accuracy by up to 19.3% across five datasets and three RL algorithms.  A simple rule-based reward incentivizes correct intermediate steps, guiding the model towards accurate reasoning paths. The method generalizes well to complex reasoning tasks, such as MATH, GPQA, and MMLU, demonstrating strong capabilities even without training data from those specific domains. | ['Reinforcement Learning', 'Question Answering'] | N/A | N/A |
| [WINA: Weight Informed Neuron Activation for Accelerating Large Language
  Model Inference](https://arxiv.org/abs/2505.19427) | Colby Banbury, Jongwoo Ko, Dan Zhao, Sihan Chen, tianyic | - This paper introduces WINA, a novel training-free sparse activation framework for accelerating large language model (LLM) inference. - WINA jointly considers hidden state magnitudes and weight matrices to determine neuron activation, unlike existing methods that rely solely on hidden state magnitudes. - Theoretical analysis demonstrates that WINA obtains tighter approximation error bounds compared to state-of-the-art methods. - Empirical results show that WINA outperforms existing methods (e.g., TEAL) by up to 2.94% on average performance across various LLMs and datasets. - The source code for WINA is publicly available on GitHub. | ['Natural Language Processing', 'Text Generation'] | [Link](https://github.com/microsoft/wina) | N/A |
| [LLaDA 1.5: Variance-Reduced Preference Optimization for Large Language
  Diffusion Models](https://arxiv.org/abs/2505.19223) | zhenxuan00, jrwen, lyk423, surfingtomchen, xiaolu0714 |  - This paper introduces LLaDA 1.5, a large language diffusion model that significantly improves upon its predecessor, LLaDA, by incorporating Variance-Reduced Preference Optimization (VRPO). - LLaDA 1.5 demonstrates superior performance across various benchmarks, including mathematical reasoning, code generation, and alignment tasks. - The core of VRPO is a framework for formally analyzing the variance of ELBO estimators and developing unbiased variance reduction strategies. - These strategies include optimal Monte Carlo budget allocation and antithetic sampling, which are shown to significantly improve the performance of MDM alignment. - The results suggest that masked diffusion models (MDMs) are compatible with RL-based alignment algorithms. | ['Natural Language Processing', 'Text Generation', 'Reinforcement Learning'] | [Link](https://ml-gsai.github.io/LLaDA-1.5-Demo/) | N/A |
| [Vibe Coding vs. Agentic Coding: Fundamentals and Practical Implications
  of Agentic AI](https://arxiv.org/abs/2505.19443) | Manoj Karkee, Konstantinos I. Roumeliotis, RanjanSapkota |  - This paper introduces two novel AI-assisted software development paradigms: vibe coding and agentic coding.  Vibe coding emphasizes intuitive human-in-the-loop interaction, while agentic coding allows for more autonomous development through AI agents.  - The authors propose a detailed taxonomy encompassing conceptual foundations, execution models, and real-world tools for each paradigm.  - A comparative analysis is presented across various aspects, including workflow models, debugging techniques, and safety mechanisms.  - The paper presents 20 use cases to illustrate how each approach excels in specific scenarios (e.g., vibe coding for prototyping, agentic coding for automation).  - Finally, the authors articulate a future roadmap for agentic AI, outlining the necessary infrastructure and challenges for building trustworthy, explainable, and collaborative systems. | ['Natural Language Processing', 'Text Generation', 'Text2Text Generation', 'Reinforcement Learning', 'Robotics'] | N/A | N/A |
| [StructEval: Benchmarking LLMs' Capabilities to Generate Structural
  Outputs](https://arxiv.org/abs/2505.20139) | Yuxuan Zhang, Sherman Siu, Lipeng He, Dongfu Jiang, Jialin Yang | - StructEval, a comprehensive benchmark, is introduced to evaluate LLMs' ability to generate structured outputs in diverse formats, including text-only and renderable formats. - StructEval systematically evaluates structural fidelity across diverse formats through two paradigms: generation and conversion tasks. - The benchmark encompasses 18 formats and 44 types of tasks, with novel metrics for format adherence and structural correctness, revealing significant performance gaps between state-of-the-art models. - Generation tasks are found to be more challenging than conversion tasks, and producing correct visual content is more difficult than generating text-only structures. - The results highlight the performance gap between commercial and open-source LLMs, underscoring the need for further research to improve structured output generation. | ['Natural Language Processing', 'Text Generation', 'Text2Text Generation'] | [Link](https://tiger-ai-lab.github.io/StructEval/) | N/A |
| [InfantAgent-Next: A Multimodal Generalist Agent for Automated Computer
  Interaction](https://arxiv.org/abs/2505.10887) | Xi Xie, Winson Chen, Zijian Zhang, Weitai Kang, Bin12345 | - INFANTAGENT-NEXT is a multimodal generalist agent that integrates tool-based and pure vision agents within a modular architecture, enabling different models to collaboratively solve decoupled tasks.- Unlike existing approaches, INFANTAGENT-NEXT achieves high accuracy and broad generality by modularizing agent workflows, tool selection, and tool execution.- The agent's performance is demonstrated on real-world benchmarks (OSWorld, GAIA, and SWE-Bench), showing superior accuracy compared to existing methods.- INFANTAGENT-NEXT uses a unified dialogue context to seamlessly merge outputs from different specialist models (reasoning, visual grounding, audio analysis).- The code and evaluation scripts for INFANTAGENT-NEXT are open-sourced. | ['Multimodal'] | [Link](https://github.com/bin123apple/InfantAgent) | N/A |
| [Error Typing for Smarter Rewards: Improving Process Reward Models with
  Error-Aware Hierarchical Supervision](https://arxiv.org/abs/2505.19706) | Soujanya Poria, Chuan Li, Amir Zadeh, Panshul Sharma, Tej Deep Pala | - This paper introduces PathFinder-PRM, a novel hierarchical, error-aware discriminative Process Reward Model (PRM) that improves mathematical reasoning in large language models. - The model first classifies math and consistency errors at each step before combining these signals to estimate step correctness, using a two-forward-pass approach. - PathFinder-PRM achieves state-of-the-art performance on PRMBench, outperforming existing methods by a margin of 2.2 points (67.7 vs. 65.5), and demonstrates improved performance on ProcessBench as well. - The model uses a 400K sample dataset, created by combining human-annotated and RLHFlow Mistral traces, that leverages three-dimensional step-level labels. - Experiments show that decoupled error detection and reward estimation leads to more accurate end-to-end reward-guided mathematical reasoning. | ['Natural Language Processing'] | [Link](https://github.com/declare-lab/PathFinder-PRM) | N/A |
| [DoctorAgent-RL: A Multi-Agent Collaborative Reinforcement Learning
  System for Multi-Turn Clinical Dialogue](https://arxiv.org/abs/2505.19630) | Yixue Li, Lu Zhou, Yichun Feng, Jarvis1111 | - DoctorAgent-RL, a novel multi-agent collaborative reinforcement learning framework, is proposed for enhanced multi-turn clinical dialogues. - The model uses a reinforcement learning mechanism to dynamically adjust its information-gathering strategy in response to patient interactions. - DoctorAgent-RL outperforms existing models in both multi-turn reasoning and final diagnostic accuracy, as demonstrated through experimental results on the MTMedDialog dataset. - The MTMedDialog dataset is introduced, the first English multi-turn medical consultation dataset to simulate realistic patient interactions. - Future work focuses on extending the model's capabilities to integrate with multimodal data and ethical considerations. | ['Reinforcement Learning', 'Natural Language Processing', 'Question Answering'] | [Link](https://github.com/JarvisUSTC/DoctorAgent-RL) | N/A |
| [Jodi: Unification of Visual Generation and Understanding via Joint
  Modeling](https://arxiv.org/abs/2505.19084) | Xilin Chen, Shiguang Shan, Meina Kan, Zhenliang He, xyfJASON | - Jodi is a novel diffusion model that unifies visual generation and understanding by jointly modeling image and multiple label domains. - The model architecture uses a linear diffusion transformer with a role switch mechanism, enabling it to perform joint generation, controllable generation, and image perception. - Jodi achieves state-of-the-art performance on various image generation and understanding tasks, outperforming existing methods on multiple benchmarks including depth estimation, normal estimation, and semantic segmentation. - The model's efficiency is demonstrated by its linear time and space complexity with respect to the number of domains, allowing it to handle up to 8 visual domains simultaneously. - A new dataset, Joint-1.6M, containing 200,000 high-quality images with automatic labels across 7 visual domains, is introduced and made publicly available. | ['Multimodal', 'Text-to-Image', 'Image-to-Image', 'Image-to-Text', 'Image Segmentation', 'Depth Estimation'] | [Link](https://github.com/VIPL-GENUN/Jodi) | N/A |
| [An Embarrassingly Simple Defense Against LLM Abliteration Attacks](https://arxiv.org/abs/2505.19056) | George Turkiyyah, Bernard Ghanem, Hasan Abed Al Kader Hammoud, Harethah Abu Shairah | - This paper introduces extended-refusal fine-tuning, a novel defense against LLM abliteration attacks, which involves modifying how models express refusals to make them more robust against attacks that neutralize safety mechanisms. - The method involves creating an extended-refusal dataset with comprehensive responses containing a neutral topic overview, explicit refusal, and ethical rationale, and fine-tuning LLMs on this dataset. - Experiments demonstrate that extended-refusal models maintain high refusal rates (dropping at most by 10%) after abliteration, whereas baseline models' refusal rates drop by 70-80%. - The approach neutralizes the abliteration attack while preserving general performance, showcasing its effectiveness in enhancing the robustness of LLMs. - This work offers valuable insights into how safety alignment is represented within neural networks and how it can be effectively integrated with general capabilities. | ['Natural Language Processing'] | N/A | N/A |
| [Strong Membership Inference Attacks on Massive Datasets and (Moderately)
  Large Language Models](https://arxiv.org/abs/2505.18773) | Matthew Jagielski, Christopher A. Choquette-Choo, Ilia Shumailov, Jamie Hayes, pasta41 |  - This paper explores the scalability of strong membership inference attacks (MIAs) on large language models (LLMs).  - The authors scale LiRA, a strong MIA, to GPT-2 architectures ranging from 10M to 1B parameters, training reference models on over 20B tokens from the C4 dataset.  - Their findings show that strong MIAs can succeed on pre-trained LLMs but their effectiveness remains limited (AUC < 0.7) in practical settings.  - The study also reveals a non-straightforward relationship between MIA success and related privacy metrics.  - This research contributes to a better understanding of the potency and reliability of membership inference attacks on LLMs. | ['Natural Language Processing'] | N/A | N/A |
| [EquivPruner: Boosting Efficiency and Quality in LLM-Based Search via
  Action Pruning](https://arxiv.org/abs/2505.16312) | Defu Lian, Quan Liu, Jianshu Zhang, Qisi Chen, Jiawei1222 | - EquivPruner, a novel technique to enhance the efficiency and quality of LLM-based search, is introduced in this paper.  It identifies and prunes semantically equivalent actions during the search process, thereby reducing redundant computations. - The method is evaluated on two benchmark datasets, MATH and GSM8K, showing improvements across various models. For instance, on Qwen2.5-Math-7B-Instruct on GSM8K, EquivPruner reduced token consumption by 48.1% while improving accuracy. - A new dataset, MathEquiv, for mathematical statement equivalence is presented, enabling the training of a lightweight equivalence detector. This detector is used to identify and remove redundant actions. - Experiments show that EquivPruner maintains or improves accuracy while significantly decreasing token consumption, illustrating its effectiveness in boosting efficiency and accuracy in LLM-based complex reasoning tasks.  - The approach is shown to be generalizable across various LLMs and tasks, indicating robustness and broad applicability. | ['Natural Language Processing'] | [Link](https://github.com/Lolo1222/EquivPruner) | [Link](https://huggingface.co/datasets/Jiawei1222/MathEquiv) |
| [MOLE: Metadata Extraction and Validation in Scientific Papers Using LLMs](https://arxiv.org/abs/2505.19800) | Bernard Ghanem, Maged S. Al-Shaibani, Zaid | - This paper introduces MOLE, a framework that leverages Large Language Models (LLMs) to automatically extract metadata attributes from scientific papers. - MOLE processes entire documents across multiple input formats (LaTeX, PDF) and incorporates robust validation mechanisms. - The framework extracts around 30 different metadata attributes per paper, significantly more than existing approaches. - A new benchmark is introduced to evaluate research progress on this task, encompassing datasets in multiple languages. - Systematic analysis demonstrates promising results with modern LLMs, while highlighting areas for future improvements. | ['Natural Language Processing'] | [Link](https://github.com/IVUL-KAUST/MOLE) | [Link](https://huggingface.co/datasets/IVUL-KAUST/MOLE) |
| [Architectural Backdoors for Within-Batch Data Stealing and Model
  Inference Manipulation](https://arxiv.org/abs/2505.18323) | Ilia Shumailov, Conrad Grobler, Ivan Petrov, Nicolas Küchler | - This paper introduces a novel class of architectural backdoors that exploit batched inference in machine learning models to steal data and manipulate model inferences for concurrent users. - The backdoors are designed to be injected into the model architecture and activated by a specific trigger in a user's input. - Once activated, they facilitate information leakage between concurrent users within the same batch, allowing attackers to steal data or manipulate the model's outputs for other users. - The authors propose a deterministic mitigation strategy, the Batch Isolation Checker, which uses static analysis of the model graph to formally guarantee non-interference between user inputs. - The Checker is evaluated on over 200 Hugging Face models to identify vulnerabilities and demonstrate its effectiveness. | ['Natural Language Processing'] | N/A | N/A |
| [Towards Holistic Evaluation of Large Audio-Language Models: A
  Comprehensive Survey](https://arxiv.org/abs/2505.15957) | Hung-yi Lee, Neo S. Ho, zenyn | This paper introduces a comprehensive taxonomy for evaluating Large Audio-Language Models (LALMs), categorizing existing benchmarks into four dimensions: General Auditory Awareness and Processing, Knowledge and Reasoning, Dialogue-oriented Ability, and Fairness, Safety, and Trustworthiness.  It offers a structured overview of the LALM evaluation landscape, highlighting challenges and future directions. The authors propose a novel structured taxonomy for LALM evaluations, providing clear guidelines for researchers and bridging the gap in fragmented existing benchmarks. This survey is the first to specifically focus on LALM evaluations, which is an important contribution to the field. | ['Audio'] | [Link](https://github.com/ckyang1124/LALM-Evaluation-Survey) | N/A |
| [TAGS: A Test-Time Generalist-Specialist Framework with
  Retrieval-Augmented Reasoning and Verification](https://arxiv.org/abs/2505.18283) | Haochen Xue, Ming Hu, Yulong Li, Feilong Tang, JianghaoWu | - This paper introduces TAGS, a test-time framework that combines a generalist and a specialist model for medical question answering. - TAGS utilizes a hierarchical retrieval mechanism to provide multi-scale exemplars for reasoning and a reliability scorer to evaluate reasoning consistency. - The framework achieves state-of-the-art performance on nine MedQA benchmarks, surpassing several fine-tuned medical LLMs without any parameter updates. -  The improvements are significant, boosting GPT-4 accuracy by 13.8% and DeepSeek-R1 by 16.8%. - The code for the framework will be available at https://github.com/JianghaoWu/TAGS. | ['Question Answering'] | [Link](https://github.com/JianghaoWu/TAGS) | N/A |
