

## Papers for 2025-05-29

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [R2R: Efficiently Navigating Divergent Reasoning Paths with Small-Large
  Model Token Routing](https://arxiv.org/abs/2505.21600) | Zhihang Yuan, Enshu Liu, Yi Ge, youyc22, fuvty | - This paper introduces Roads to Rome (R2R), a novel token routing method that improves the efficiency of large language model (LLM) inference by selectively using LLMs only for tokens that cause divergence in reasoning paths compared to small language models (SLMs). - R2R uses a lightweight neural router to identify these critical tokens, automatically generated through a developed data pipeline that labels divergent tokens. - When evaluated on challenging math, coding, and QA benchmarks, R2R outperforms the average accuracy of R1-7B by 1.6x and even surpasses R1-14B, while delivering a 2.8x wall-clock speedup compared to R1-32B. - This method achieves a 4.6x accuracy improvement over the R1-1.5B SLM with only 12.9% LLM usage. - The R2R model combines R1-1.5B and R1-32B models, achieving an average activated parameter size of 5.6B. | ['Question Answering'] | [Link](https://github.com/thu-nics/R2R) | N/A |
| [Sherlock: Self-Correcting Reasoning in Vision-Language Models](https://arxiv.org/abs/2505.22651) | Ruqi Zhang, Tuwhy |  - Sherlock is a novel self-correcting and self-improving training framework for reasoning Vision-Language Models (VLMs) that addresses the challenges of reasoning errors, high data demands, and limited generalization capabilities. - The framework introduces a trajectory-level self-correction objective, a preference data construction method using visual perturbation, and a dynamic beta for preference tuning. - Sherlock achieves state-of-the-art results on eight benchmarks with less than 20% of the annotated data used by existing methods. - The model's self-correction capabilities allow for continued improvement without external supervision after initial training. - An ablation study shows that the trajectory-level objective and dynamic beta are crucial for effective self-correction. | ['Multimodal', 'Visual Question Answering', 'Question Answering'] | [Link](https://dripnowhy.github.io/Sherlock/) | N/A |
| [Unsupervised Post-Training for Multi-Modal LLM Reasoning via GRPO](https://arxiv.org/abs/2505.22453) | Chen Wang, Yuting Li, weiranhuang, weiranhuang, WaltonFuture | - This paper introduces MM-UPT, a novel framework for unsupervised post-training of Multi-modal Large Language Models (MLLMs). - MM-UPT uses GRPO, a stable and scalable online reinforcement learning algorithm, and replaces traditional reward signals with a self-rewarding mechanism based on majority voting. - Experiments demonstrate that MM-UPT significantly improves the reasoning ability of Qwen2.5-VL-7B on multiple benchmarks, even outperforming previous unsupervised baselines and approaching the results of supervised GRPO. - The use of synthetic questions generated by the MLLM itself can further boost performance, highlighting a promising approach for scalable self-improvement. - MM-UPT offers a new paradigm for continual, autonomous enhancement of MLLMs in the absence of external supervision. | ['Multimodal', 'Visual Question Answering'] | [Link](https://github.com/waltonfuture/MM-UPT) | N/A |
| [SageAttention2++: A More Efficient Implementation of SageAttention2](https://arxiv.org/abs/2505.21136) | Pengle Zhang, Haofeng Huang, Jia Wei, Xiaoming Xu, jt-zhang | - This paper introduces SageAttention2++, an improved implementation of SageAttention2, focusing on accelerating the second matrix multiplication in the attention mechanism. - SageAttention2++ utilizes the faster FP8 Matmul instruction accumulated in FP16, resulting in a 3.9x speedup over FlashAttention. - The improved model maintains the accuracy of SageAttention2, demonstrating effectiveness across various models for text, image, and video generation, with negligible end-to-end metric loss. - The enhanced efficiency is achieved by narrowing the quantization range of P and V to ensure that accumulated values remain within the representable range of FP16. - Comprehensive evaluations on various state-of-the-art models show consistent performance improvements, supporting its plug-and-play acceleration capabilities. | ['Text2Text Generation', 'Text-to-Image', 'Text-to-Video'] | [Link](https://github.com/thu-ml/SageAttention) | N/A |
| [Advancing Multimodal Reasoning via Reinforcement Learning with Cold
  Start](https://arxiv.org/abs/2505.22334) | Kaipeng Zheng, Yuting Li, weiranhuang, weiranhuang, WaltonFuture | - This paper introduces a two-stage approach for enhancing multimodal reasoning in large language models (LLMs): first, supervised fine-tuning (SFT) with Chain-of-Thought (CoT) patterns to create a strong foundation and then reinforcement learning (RL) with GRPO to further refine the model's capabilities. - The study demonstrates that the presence of "aha moment" patterns in MLLMs before RL training does not necessarily correlate with improved reasoning performance, challenging existing assumptions. - The proposed approach achieves state-of-the-art performance among open-source MLLMs at both 3B and 7B scales on multiple challenging multimodal reasoning benchmarks, consistently outperforming both SFT-only and RL-only methods. - Ablation studies explore the impact of different SFT strategies and data qualities on subsequent RL performance, revealing that high-quality supervision during SFT is crucial for maximizing gains. - The findings highlight the importance of a well-structured reasoning format, regardless of whether reflective patterns are present, demonstrating that cold-start SFT provides a strong foundation for subsequent RL scaling. | ['Multimodal', 'Reinforcement Learning', 'Question Answering'] | [Link](https://github.com/waltonfuture/RL-with-Cold-Start) | N/A |
| [Universal Reasoner: A Single, Composable Plug-and-Play Reasoner for
  Frozen LLMs](https://arxiv.org/abs/2505.19075) | Jong Chul Ye, Choonghan Kim, Hyunmin Hwang, Hangeol Chang, kjm981995 | - This paper introduces UniR, a lightweight, composable, and plug-and-play reasoning module that enhances the reasoning capabilities of frozen LLMs without retraining. - UniR decomposes rewards into a standalone reasoning module, trained independently using predefined rewards, effectively translating trajectory-level signals into token-level guidance. - UniR outperforms existing baseline fine-tuning methods on mathematical reasoning and machine translation tasks, demonstrating strong weak-to-strong generalization across different LLM sizes. - The additive structure of UniR enables modular composition, allowing multiple UniR modules trained for different tasks to be jointly applied. - UniR is computationally efficient, adaptable, and robust, offering a cost-effective solution for enhancing reasoning in LLMs without compromising their core capabilities. | ['Natural Language Processing', 'Text Generation', 'Reinforcement Learning'] | [Link](https://github.com/hangeol/UniR) | N/A |
| [WebDancer: Towards Autonomous Information Seeking Agency](https://arxiv.org/abs/2505.22648) | Liwen Zhang, Wenbiao Yin, Runnan Fang, Baixuan Li, callanwu | - WebDancer is a novel end-to-end agentic information-seeking agent built upon the ReAct framework. - The model utilizes a data-centric approach, constructing diverse and challenging deep information-seeking QA pairs through two methods: CRAWLQA and E2HQA. - A two-stage training paradigm is employed: rejection sampling fine-tuning (RFT) with subsequent on-policy RL using the DAPO algorithm. - WebDancer demonstrates strong performance on the challenging information seeking benchmarks, GAIA and WebWalkerQA, outperforming existing methods. - Further analysis reveals valuable insights into developing more capable agentic models. | ['Question Answering'] | [Link](https://github.com/Alibaba-NLP/WebAgent) | N/A |
| [Judging Quality Across Languages: A Multilingual Approach to Pretraining
  Data Filtering with Language Models](https://arxiv.org/abs/2505.22232) | Abbas Goher Khan, Elias Wendt, Max LÃ¼bbering, Mehdi Ali, mbrack | This paper introduces JQL, a novel multilingual data filtering approach that uses pretrained multilingual embeddings and lightweight annotators to efficiently curate high-quality training data.  JQL significantly outperforms existing heuristic methods, demonstrating robust performance across 35 languages, including low-resource languages.  The proposed pipeline includes four stages: human annotation, LLM-as-a-judge annotation, lightweight annotator training, and data filtering.  JQL achieves high data retention rates and enhances downstream model training quality. | ['Natural Language Processing'] | [Link](https://github.com/JQL-AI/JQL-Annotation-Pipeline/) | [Link](https://huggingface.co/spaces/Jackal-AI), [Link](https://huggingface.co/datasets/Jackal-AI/jql_human_edu_annotations), [Link](https://huggingface.co/datasets/Jackal-AI/jql_llms_edu_annotations), [Link](https://huggingface.co/Jackal-AI/JQL-Edu-Heads), [Link](https://huggingface.co/datasets/HuggingFaceFW/fineweb-2) |
| [LIMOPro: Reasoning Refinement for Efficient and Effective Test-time
  Scaling](https://arxiv.org/abs/2505.19187) | Kaishuai Xu, Chunpu Xu, Ruifeng Yuan, Jiashuo Wang, YangXiao-nlp | This paper introduces PIR (Perplexity-based Importance Refinement), a novel framework that refines large language model (LLM) reasoning chains by systematically pruning low-importance functional steps while preserving progressive reasoning.  The framework identifies and removes low-importance functional steps using perplexity scores, improving the computational efficiency of reasoning-capable LLMs.  The approach demonstrates significant improvements in accuracy (+0.9% to +6.6%) and reduced token usage (-3% to -41%) across various benchmarks. The method is shown to generalize across different model sizes and data sources, offering a practical solution for deploying reasoning-capable LLMs with efficient test-time scaling.  The code and dataset are publicly available. | ['Natural Language Processing', 'Question Answering'] | N/A | N/A |
| [Towards Dynamic Theory of Mind: Evaluating LLM Adaptation to Temporal
  Evolution of Human States](https://arxiv.org/abs/2505.17663) | Chunpu Xu, Changhe Song, Qiancheng Xu, Jiashuo Wang, YangXiao-nlp | - This paper introduces DYNTOM, a novel benchmark designed to evaluate LLMs' ability to track and understand the temporal evolution of mental states in social interactions. - DYNTOM comprises 1,100 social contexts, 5,500 scenarios, and 78,100 multiple-choice questions, each validated for realism and quality. - Evaluation of ten state-of-the-art LLMs reveals that their average performance underperforms humans by 44.7%, with performance significantly degrading when tracking mental state shifts. - The performance gap highlights the limitations of current LLMs in modeling the dynamic nature of human mental states. - This work provides a comprehensive framework for evaluating LLMs' understanding of temporal evolution in mental states and a benchmark with extensive empirical evaluation results. | ['Natural Language Processing'] | N/A | N/A |
| [VRAG-RL: Empower Vision-Perception-Based RAG for Visually Rich
  Information Understanding via Iterative Reasoning with Reinforcement Learning](https://arxiv.org/abs/2505.22019) | Zehui Chen, Ruixue Ding, Lin-Chen, YuZeng260, autumncc | - This paper introduces VRAG-RL, a novel reinforcement learning framework for training Vision-Language Models (VLMs) to reason and understand visually rich information. - VRAG-RL incorporates a visual perception action space, allowing VLMs to extract information from a coarse-to-fine perspective and enhance reasoning capabilities. - A comprehensive reward structure, integrating retrieval performance and model-based outcome rewards, bridges the gap between user inquiries and retriever outputs, aligning with real-world applications. - Extensive experiments on various benchmarks demonstrate that VRAG-RL outperforms existing methods, achieving over 20% improvement. - The code is available at https://github.com/Alibaba-NLP/VRAG. | ['Multimodal', 'Document Question Answering', 'Reinforcement Learning'] | [Link](https://github.com/Alibaba-NLP/VRAG) | N/A |
| [RICO: Improving Accuracy and Completeness in Image Recaptioning via
  Visual Reconstruction](https://arxiv.org/abs/2505.22613) | Linli Yao, Sihan Yang, Shuhuai Ren, Yishuo Cai, Yuchi Wang | - This paper introduces RICO, a novel framework for image recaptioning that refines captions through visual reconstruction. - RICO leverages a text-to-image model to reconstruct a caption into a reference image, and then uses an MLLM to identify discrepancies between the original and reconstructed images to refine the caption iteratively. - RICO-Flash, a more efficient end-to-end variant of RICO, is also introduced; it uses Direct Preference Optimization (DPO) to learn to generate captions like RICO. - Extensive experiments demonstrate that RICO significantly improves caption accuracy and completeness, outperforming most baselines by approximately 10% on both CapsBench and CompreCap. - The code for RICO is released on GitHub. | ['Image-to-Text', 'Text-to-Image', 'Multimodal'] | [Link](https://github.com/wangyuchi369/RICO) | N/A |
| [Let's Predict Sentence by Sentence](https://arxiv.org/abs/2505.22202) | Hoyeon Chang, Jiyeon Kim, Seungone Kim, Byeongguk Jeon, Hyeonbin Hwang | - This paper introduces a novel framework that allows pretrained Language Models (LMs) to reason over higher-level abstractions like sentences rather than raw token sequences. - The framework adapts a pretrained token-level LM to operate in sentence space by autoregressively predicting continuous embeddings of the next sentences. - Two embedding paradigms are explored: semantic embeddings (learned via autoencoding) and contextual embeddings (trained via next-sentence prediction). - The proposed approach, using contextual embeddings under a continuous inference regime, achieves competitive performance with Chain-of-Thought (CoT) while reducing inference-time FLOPs by half. - The effectiveness of this approach was demonstrated across four domains: mathematics, logic, commonsense reasoning, and planning. | ['Question Answering'] | N/A | N/A |
| [Thinking with Generated Images](https://arxiv.org/abs/2505.22525) | Jiadi Su, Siqi Kou, Steffi Chern, Zhulin Hu, ethanchern | - This paper introduces "Thinking with Generated Images", a novel paradigm that fundamentally transforms how large multimodal models (LMMs) engage with visual reasoning by enabling them to natively think across text and vision modalities. - The core contribution is a new method called "native long-multimodal thought process", which enables unified LMMs to seamlessly generate intermediate visual thoughts, establish visual subgoals, and iteratively critique their visual hypotheses. - Two complementary mechanisms are proposed: vision generation with intermediate visual subgoals and vision generation with self-critique, both showing substantial performance improvements over baseline approaches on vision generation benchmarks. - The proposed approach achieves up to a 50% relative improvement in handling complex multi-object scenarios, demonstrating the effectiveness of the native long-multimodal thought process. - The authors release an open-source suite at https://github.com/GAIR-NLP/thinking-with-generated-images. | ['Multimodal', 'Text-to-Image', 'Image-to-Image'] | [Link](https://github.com/GAIR-NLP/thinking-with-generated-images) | N/A |
| [Text2Grad: Reinforcement Learning from Natural Language Feedback](https://arxiv.org/abs/2505.22338) | Si Qin, Tianjun Mao, Chaoyun Zhang, Lu Wang, Hanyang Wang | - This paper introduces TEXT2GRAD, a novel reinforcement learning paradigm that converts free-form natural language feedback into span-level gradients for precise policy optimization. - TEXT2GRAD surpasses traditional RLHF and prompt-only baselines in summarization, code generation, and question answering tasks. - The method comprises three components: a feedback-annotation pipeline, a fine-grained reward model, and a span-level policy optimizer. - Unlike prior work, TEXT2GRAD directly incorporates textual feedback into gradient updates, leading to more targeted and interpretable learning. - Experimental results show that TEXT2GRAD consistently outperforms existing methods, with higher task metrics and improved interpretability. | ['Reinforcement Learning', 'Text Generation', 'Natural Language Processing'] | [Link](https://github.com/microsoft/Text2Grad) | N/A |
| [EPiC: Efficient Video Camera Control Learning with Precise Anchor-Video
  Guidance](https://arxiv.org/abs/2505.21876) | Han Lin, Jialu Li, Jaemin Cho, Zun Wang, jaehong31 | - The paper introduces EPiC, a novel framework that learns precise camera control using a lightweight conditioning module called Anchor-ControlNet and precisely-aligned anchor videos generated by masking source videos based on first-frame visibility. - Anchor-ControlNet uses less than 1% of backbone parameters and integrates anchor video guidance in visible regions to pretrained video diffusion models. - Unlike previous methods, EPiC doesn't require camera trajectory annotations or modifications to the diffusion model backbone to mitigate misalignments. - EPiC achieves state-of-the-art performance on RealEstate10K and MiraData for I2V camera control tasks and generalizes to V2V scenarios. - The proposed method demonstrates efficiency with fewer parameters, training steps, and data compared to existing methods. | ['Image-to-Video', 'Text-to-Video', 'Video Classification', 'Multimodal'] | [Link](https://zunwang1.github.io/Epic) | N/A |
| [GRE Suite: Geo-localization Inference via Fine-Tuned Vision-Language
  Models and Enhanced Reasoning Chains](https://arxiv.org/abs/2505.18700) | Yiren Song, Haofan Wang, Zihao Pan, Xiaoran Pan, Chun Wang | - The paper introduces GRE Suite, a novel framework for geo-localization inference that augments VLMs with structured reasoning chains. - GRE Suite is composed of three key components: a high-quality geo-localization dataset (GRE30K), a multi-stage reasoning model (GRE), and a comprehensive evaluation benchmark (GREval-Bench). - The GRE model uses a multi-stage reasoning strategy to progressively infer scene attributes, local details, and semantic features to enhance precision in location inference. - Experimental results demonstrate that GRE significantly outperforms existing methods across all granularities of geo-localization tasks, highlighting the effectiveness of reasoning-augmented VLMs. - The GRE30K dataset and the GREval-Bench are systematically developed to facilitate fine-grained visual and contextual analysis for improved accuracy and interpretability. | ['Multimodal'] | [Link](https://github.com/Thorin215/GRE) | N/A |
| [Just as Humans Need Vaccines, So Do Models: Model Immunization to Combat
  Falsehoods](https://arxiv.org/abs/2505.17870) | Deval Pandya, Marcelo Lotif, Rizwan Qureshi, amanchadha, Shainarazavi | - The paper introduces a novel training framework called "Model Immunization" to combat the generation of false information by large language models (LLMs). - Model Immunization involves fine-tuning the model on a small, curated set of explicitly labeled falsehoods, analogous to biological immunization, to enhance the model's ability to identify and reject misleading claims. - The authors demonstrate through a case study that immunized models generate substantially less misinformation than baseline models, improving truthfulness while maintaining overall accuracy. - The proposed framework incorporates ethical safeguards and governance controls to ensure the responsible use of false data in model training. - Model Immunization offers a proactive approach to aligning AI systems with factuality, by immunizing models to falsehoods before they propagate, rather than merely reacting after misinformation is generated. | ['Natural Language Processing', 'Text Generation'] | N/A | N/A |
| [Unveiling Instruction-Specific Neurons & Experts: An Analytical
  Framework for LLM's Instruction-Following Capabilities](https://arxiv.org/abs/2505.21191) | Zhaorui Hou, Jungang Li, Yibo Yan, Yubo Gao, Junyan Zhang | - This paper introduces HEXAINST, a meticulously curated and balanced instructional dataset, and SPARCOM, a novel analytical framework for examining how fine-tuning modifies LLMs' instruction-following capabilities. - SPARCOM comprises three key components: a method for identifying instruction-specific sparse components (neurons and experts), an evaluation of their functional generality and uniqueness, and a systematic comparison of their alterations. - Through experiments on LLaMA, Mistral, and Qwen-MoE model families, the study demonstrates the critical role of these sparse components in instruction execution, showing functional generality and uniqueness. - The findings elucidate the relationship between fine-tuning-induced adaptations and sparse computational substrates, offering insights into how LLMs internalize instruction-following behavior. - The study also proposes a three-stage framework for understanding the internal mechanism of LLMs' instruction-following capabilities. | ['Natural Language Processing'] | N/A | [Link](https://huggingface.co/meta-llama/Llama-2-7b-hf), [Link](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf), [Link](https://huggingface.co/meta-llama/Llama-2-13b-hf), [Link](https://huggingface.co/meta-llama/Llama-2-13b-chat-hf), [Link](https://huggingface.co/mistralai/Mistral-7B-v0.1), [Link](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1), [Link](https://huggingface.co/Qwen/Qwen1.5-MoE-A2.7B), [Link](https://huggingface.co/Qwen/Qwen1.5-MoE-A2.7B-Chat) |
| [Characterizing Bias: Benchmarking Large Language Models in Simplified
  versus Traditional Chinese](https://arxiv.org/abs/2505.22645) | Allison Koenecke, Jian Kang, Jiebo Luo, Hanjia Lyu | This paper introduces SC-TC-BENCH, a benchmark dataset designed to evaluate large language models' (LLMs) performance in both Simplified and Traditional Chinese.  The study focuses on identifying biases in LLMs' responses to prompts presented in these two Chinese variants by evaluating the LLMs on two tasks, one focusing on regional term selection and the other on regional name selection.  The results reveal that LLMs exhibit biases based on both the task and the prompting language.  Finally, the authors provide an open-sourced benchmark dataset to facilitate reproducible evaluations of future LLMs. | ['Natural Language Processing'] | [Link](https://github.com/brucelyu17/SC-TC-Bench) | N/A |
| [MangaVQA and MangaLMM: A Benchmark and Specialized Model for Multimodal
  Manga Understanding](https://arxiv.org/abs/2505.20298) | Yuki Imajuku, Atsuyuki Miyai, Shota Onohara, Kazuki Egashira, Jeonghun Baek | - This paper introduces two benchmarks for multimodal manga understanding: MangaOCR (for in-page text recognition) and MangaVQA (a novel benchmark for contextual understanding through visual question answering). - MangaVQA consists of 526 high-quality, manually constructed question-answer pairs, enabling reliable evaluation across diverse narrative and visual scenarios. - They develop MangaLMM, a manga-specialized model fine-tuned from the open-source LMM Qwen2.5-VL to jointly handle both tasks (MangaOCR and MangaVQA). - Through extensive experiments, including comparisons with proprietary models such as GPT-40 and Gemini 2.5, they assess how well LMMs understand manga.  - The benchmark and model provide a comprehensive foundation for evaluating and advancing LMMs in the richly narrative domain of manga. | ['Visual Question Answering', 'Multimodal'] | [Link](https://github.com/manga109/MangaLMM/) | N/A |
| [Efficient Data Selection at Scale via Influence Distillation](https://arxiv.org/abs/2505.19051) | Vahab Mirrokni, Dan Alistarh, Vincent Cohen-Addad, Mahdi Nikdan |  - Influence Distillation, a novel framework for data selection, is introduced, using second-order information to optimally weigh training samples.  - The method assigns model-specific weights for selecting training data, improving LLM performance in the target domain.  - Optimal weights are derived for Gradient Descent and Adam optimizers, with a landmark-based approximation for scalability.  - Experiments on instruction tuning using the Tulu V2 dataset show that Influence Distillation matches or outperforms state-of-the-art methods, while being up to 3.5 times faster.  - The method is validated across several LLMs from the Llama and Qwen families, targeting tasks such as GSM8k, SQUAD, and MMLU. | ['Natural Language Processing'] | N/A | N/A |
| [AITEE -- Agentic Tutor for Electrical Engineering](https://arxiv.org/abs/2505.21582) | Christian Bernhardt, Alexander Bernhardt, CKnievel | - This paper introduces AITEE, an intelligent tutoring system for electrical engineering that combines large language models with agent-based tutoring to provide personalized learning experiences. - AITEE uses a novel graph-based similarity measure to identify relevant context from lecture materials and employs a Socratic dialogue approach to guide students toward solutions. - The system supports both hand-drawn and digital circuits through an adapted circuit reconstruction process and employs SPICE simulation for enhanced accuracy. - Experimental evaluations demonstrate that AITEE significantly outperforms baseline approaches in domain-specific knowledge application, particularly for complex circuits. - The results suggest that agentic tutors have the potential to deliver scalable and effective personalized learning environments for electrical engineering education. | ['Multimodal', 'Question Answering', 'Object Detection', 'Graph Machine Learning', 'Text2Text Generation'] | [Link](https://github.com/CKnievel/aitee-dataset) | [Link](string) |
| [First Finish Search: Efficient Test-Time Scaling in Large Language
  Models](https://arxiv.org/abs/2505.18149) | Tanmoy Chakraborty, Ayan Sengupta, aradhye |  - First Finish Search (FFS) is a novel training-free, parallel decoding strategy that improves reasoning in large language models (LLMs) at test time.   - FFS launches multiple independent samples and returns the first completed sample, significantly reducing compute cost and latency.   - Empirical evidence shows shorter traces are more likely to be correct in reasoning tasks, supporting FFS's early stopping mechanism.  - Experiments on four reasoning models and four datasets demonstrate that FFS consistently outperforms existing test-time scaling methods in accuracy, efficiency, and scalability.   - Theoretical analysis explains why shorter traces tend to be correct and how FFS's compute efficiency increases with more samples. | ['Question Answering'] | [Link](https://github.com/Aradhye2002/reasoning_exps) | [Link](https://huggingface.co) |
