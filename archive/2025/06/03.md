

## Papers for 2025-06-03

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [Taming LLMs by Scaling Learning Rates with Gradient Grouping](https://arxiv.org/abs/2506.01049) | danxu, MarcusB3n, ZedongWangAI, Juanxi, Lupin1998 | This paper introduces Scaling with Gradient Grouping (SGG), a novel optimizer wrapper designed to improve adaptive learning rate estimation in Large Language Models (LLMs).  SGG dynamically groups gradient statistics within each layer into clusters and applies cluster-specific scaling to calibrate learning rates. Experiments across various model sizes and benchmarks demonstrate that SGG consistently improves performance and convergence speed compared to baselines.  The method seamlessly integrates with existing optimizers and PEFT techniques, offering a robust and efficient optimization solution. SGG's efficacy is validated across diverse tasks including pre-training, supervised fine-tuning, and parameter-efficient fine-tuning, highlighting its broad applicability. | ['Natural Language Processing'] | [Link](https://github.com/ScalingOpt/SGG) | N/A |
| [Jigsaw-R1: A Study of Rule-based Visual Reinforcement Learning with
  Jigsaw Puzzles](https://arxiv.org/abs/2505.23590) | Feiyu Xiong, Zhiyu Li, Bo Tang, RyanZhu, wangzifu | - This paper introduces Jigsaw-R1, a novel rule-based reinforcement learning framework for training multimodal large language models (MLLMs) on jigsaw puzzles. - The framework uses jigsaw puzzles as a structured environment to study rule-based visual reinforcement learning, revealing that MLLMs can generalize to complex, unseen configurations and other visual tasks through fine-tuning. - The study demonstrates that RL outperforms supervised fine-tuning (SFT) in generalization, and an initial SFT phase can hinder subsequent RL optimization. - Experiments show that complex reasoning patterns appear to be pre-existing rather than emergent, and their frequency increases with training and task difficulty. - The findings contribute to a better understanding of rule-based visual RL and its potential in multimodal learning. | ['Multimodal', 'Reinforcement Learning', 'Visual Question Answering'] | [Link](https://github.com/zifuwanggg/Jigsaw-R1) | N/A |
| [ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and
  Understanding](https://arxiv.org/abs/2506.01853) | Jun Zhu, Shenghao Xie, Zhengyi Wang, Junliang Ye, zzzrw | - This paper introduces ShapeLLM-Omni, a novel multimodal large language model (MLLM) capable of understanding and generating 3D content from text or images. - The model architecture uses a 3D vector-quantized variational autoencoder (VQVAE) to map 3D objects into a discrete latent space, enabling efficient and accurate shape representation and reconstruction. - ShapeLLM-Omni is trained on a large-scale dataset called 3D-Alpaca, encompassing generation, comprehension, and editing tasks, which provides rich resources for future research and training. -  The experimental results demonstrate that ShapeLLM-Omni outperforms other baselines on multiple benchmarks, including text-to-3D and image-to-3D generation and 3D captioning tasks. - Overall, ShapeLLM-Omni provides a comprehensive solution for multimodal 3D generation and understanding, exhibiting promising results across various tasks. | ['Text-to-3D', 'Image-to-3D', 'Multimodal'] | [Link](https://github.com/JAMESYJL/ShapeLLM-Omni/) | N/A |
| [SRPO: Enhancing Multimodal LLM Reasoning via Reflection-Aware
  Reinforcement Learning](https://arxiv.org/abs/2506.01713) | Dongfei Cui, Yu Zhang, Che Liu, Zhihao Dou, Zhongwei Wan | - This paper introduces SRPO, a novel two-stage reflection-aware reinforcement learning framework designed to enhance multimodal LLM reasoning. - SRPO uses a high-quality reflection-focused dataset, constructed using an advanced MLLM, to help a policy model learn reasoning and self-reflection. - The framework introduces a novel reward mechanism that encourages meaningful reflection while avoiding redundancy. - Extensive experiments show that SRPO significantly outperforms state-of-the-art models across multiple multimodal reasoning benchmarks, such as MathVista, MathVerse, and MMMU-Pro. - SRPO achieves notable improvements in both reasoning accuracy and reflection quality. | ['Multimodal', 'Reinforcement Learning'] | N/A | N/A |
| [EarthMind: Towards Multi-Granular and Multi-Sensor Earth Observation
  with Large Multimodal Models](https://arxiv.org/abs/2506.01667) | Luc Van Gool, Danda Pani Paudel, Zhitong Xiong, Bin Ren, Yan Shu | - This paper introduces EarthMind, a novel vision-language framework for multi-granular and multi-sensor Earth Observation (EO) data understanding. - EarthMind features two core components: Spatial Attention Prompting (SAP) and Cross-modal Fusion. - The model achieves state-of-the-art performance on EarthMind-Bench, a comprehensive benchmark with over 2,000 human-annotated multi-sensor image-question pairs. - EarthMind outperforms existing methods on multiple public EO benchmarks, showcasing its potential to handle both multi-granular and multi-sensor challenges in a unified framework. - The effectiveness of EarthMind is demonstrated through extensive experiments on multiple public benchmarks and a newly proposed benchmark called EarthMind-Bench. | ['Multimodal', 'Image-Text-to-Text', 'Visual Question Answering', 'Image Segmentation', 'Mask Generation', 'Multimodal', 'Image-Text-to-Text'] | [Link](https://github.com/shuyansy/EarthMind) | N/A |
| [Incentivizing Reasoning for Advanced Instruction-Following of Large
  Language Models](https://arxiv.org/abs/2506.01413) | Yuchen Shi, Zihan Xu, Zongyi Li, Gang Li, yolay | This paper introduces a novel method to enhance the instruction-following capabilities of Large Language Models (LLMs) by incentivizing reasoning.  The method addresses the limitations of existing chain-of-thought prompting by employing reinforcement learning with rule-centric reward signals.  Experimental results across multiple benchmarks show significant performance improvements, with a 1.5B LLM achieving comparable results to an 8B LLM in some cases. The approach also incorporates self-evolving instruction generation and behavior cloning techniques to improve robustness. The proposed method boosts the ability of LLMs to handle complex instructions effectively. | ['Natural Language Processing', 'Reinforcement Learning', 'Text Generation'] | [Link](https://github.com/yuleiqin/RAIF) | N/A |
| [DyePack: Provably Flagging Test Set Contamination in LLMs Using
  Backdoors](https://arxiv.org/abs/2505.23001) | Soheil Feizi, mmoayeri, wangwenxiao, yizecheng | - DyePack is a novel framework that uses backdoor attacks to detect test set contamination in large language models (LLMs) without needing access to internal model details. - It incorporates multiple backdoors with stochastic targets, enabling exact false positive rate (FPR) computation, and provably prevents false accusations. - DyePack is evaluated on five models across three datasets (MMLU-Pro, Big-Bench-Hard, and Alpaca), demonstrating its effectiveness in detecting contamination with guaranteed low FPRs. - The framework generalizes well to both multiple-choice and open-ended generation tasks, successfully identifying all contaminated models. - The approach enhances the reliability and trustworthiness of open benchmarks by providing a principled method for detecting test set contamination. | ['Natural Language Processing'] | N/A | N/A |
| [Reasoning Like an Economist: Post-Training on Economic Problems Induces
  Strategic Generalization in LLMs](https://arxiv.org/abs/2506.00577) | Yifang Chen, Xiangqi Jin, Xingyu Dong, Steven-Shaobo, MasterZhou | - This paper introduces Recon, a 7B parameter open-source Large Language Model (LLM) post-trained on a curated dataset of 2100 high-quality economic reasoning problems. - Recon employs Supervised Fine-Tuning (SFT) and Group Relative Policy Optimization (GRPO) to enhance its reasoning capabilities. - Evaluation on economic reasoning benchmarks and multi-agent games demonstrates improvements in structured reasoning and strategic decision-making. - The results highlight the potential of domain-aligned post-training for improving reasoning and agent alignment in LLMs. - The code for Recon is publicly available on GitHub. | ['Natural Language Processing', 'Reinforcement Learning', 'Text Generation', 'Question Answering'] | [Link](https://github.com/MasterZhou1/Recon) | N/A |
| [VisualSphinx: Large-Scale Synthetic Vision Logic Puzzles for RL](https://arxiv.org/abs/2505.23977) | Bhaskar Ramasubramanian, Yuetai Li, Fengqing Jiang, zhangchenxu, EthanSta | - This paper introduces VISUALSPHINX, a large-scale synthetic dataset containing over 660K visual logic puzzles designed to enhance the logical reasoning capabilities of vision-language models (VLMs) through reinforcement learning. - The dataset is generated using a four-stage pipeline that leverages rule abstraction, rule-level genetic algorithms, program-based image synthesis, and strategic puzzle assembly. - Experiments demonstrate that a vision language model fine-tuned using reinforcement learning on VISUALSPHINX outperforms existing models on various benchmarks. - The dataset exhibits strong generalizability and robustness, improving the model's accuracy in solving various visual logic puzzles and other reasoning tasks. - VISUALSPHINX is cost-effective, generated at a cost of less than \$1000, making it scalable and accessible. | ['Reinforcement Learning', 'Multimodal', 'Visual Question Answering'] | [Link](https://visualsphinx.github.io) | [Link](https://hf.co/VisualSphinx) |
| [From Token to Action: State Machine Reasoning to Mitigate Overthinking
  in Information Retrieval](https://arxiv.org/abs/2505.23059) | Seung-won Hwang, yeonseokjeong, waylight3 | - This paper introduces State Machine Reasoning (SMR), a novel framework for mitigating overthinking in information retrieval by using large language models. - SMR formulates reasoning as transitions between structured states, enabling fine-grained control and early stopping, which avoids generating redundant or misaligned reasoning steps. - The framework consists of discrete actions (REFINE, RERANK, STOP) guided by an LLM, enabling efficient token usage and improved retrieval performance. - Experiments on benchmark datasets (BEIR and BRIGHT) demonstrate that SMR improves retrieval performance (nDCG@10) while significantly reducing token usage. - This method generalizes across LLMs and retrievers without requiring task-specific tuning. | ['Natural Language Processing'] | [Link](https://github.com/ldilab/SMR) | N/A |
| [WHEN TO ACT, WHEN TO WAIT: Modeling Structural Trajectories for Intent
  Triggerability in Task-Oriented Dialogue](https://arxiv.org/abs/2506.01881) | Kyrie Zhixuan Zhou, Yuanli Wang, Jindan Huang, simonycl, FreaxRuby | This paper introduces STORM, a novel framework for modeling the evolution of user intent in task-oriented dialogues.  STORM uses two LLMs, one simulating the user's internal state and another observing only dialogue history, reflecting real-world information asymmetry.  Experimental results across four language models indicate that moderate uncertainty can outperform complete transparency in certain scenarios, showing model-specific patterns.  The framework contributes to understanding asymmetric reasoning dynamics and informs uncertainty-calibrated dialogue system design.  STORM's contributions include formalizing asymmetric information processing, modeling intent formation tracking, and introducing new evaluation metrics.  These findings suggest that excessive profile information might lead to presumptive reasoning, and moderate uncertainty encourages more exploratory interaction strategies that better support user’s understanding of their own needs. | ['Natural Language Processing'] | N/A | N/A |
| [Stepsize anything: A unified learning rate schedule for
  budgeted-iteration training](https://arxiv.org/abs/2505.24452) | Zhouchen Lin, zhou Xun, Yiming Dong, Anda Tang, Taoer |  - This paper introduces the Unified Budget-Aware (UBA) learning rate schedule for budgeted-iteration training.  - UBA is theoretically grounded, explicitly addressing robustness to landscape curvature variations.  - It outperforms existing schedules across diverse vision and language tasks using various network architectures under different training budgets.  - UBA is controlled by a single hyperparameter that balances flexibility and simplicity, removing the need for per-network numerical optimization.  - Extensive experiments demonstrate UBA's consistent superiority across various tasks, scales, and architectures. | ['Natural Language Processing', 'Computer Vision'] | [Link](https://github.com/Ttt-answer/UBA.git) | N/A |
| [CodeV-R1: Reasoning-Enhanced Verilog Generation](https://arxiv.org/abs/2505.24183) | Chongxiao Li, Xiaoyun Zhang, Hanqi Lyu, dihuang, zhuyaoyu |  - CodeV-R1 is a novel reinforcement learning framework designed for training large language models (LLMs) to generate Verilog code from natural language descriptions.  - It addresses the challenges of automated Verilog verification, high-quality data scarcity, and high computational cost of reinforcement learning by introducing a rule-based testbench generator, a round-trip data synthesis method, and an adaptive DAPO algorithm.  - CodeV-R1-7B, the model trained using this framework, surpasses previous state-of-the-art methods by 12-20% on VerilogEval v2 and RTLLM v1.1 benchmarks.  - The model, training pipeline, and dataset are publicly released to facilitate further research in electronic design automation (EDA) and LLM communities.  - CodeV-R1 employs a two-stage training pipeline that consists of a supervised fine-tuning (distillation) phase followed by reinforcement learning.  | ['Reinforcement Learning', 'Text Generation', 'Text2Text Generation'] | [Link](https://iprc-dip.github.io/CodeV-R1) | N/A |
| [Stress-testing Machine Generated Text Detection: Shifting Language
  Models Writing Style to Fool Detectors](https://arxiv.org/abs/2505.24523) | Giovanni Puccetti, Alessio Miaschi, Cristiano Ciaccio, Michele Papucci, andreapdr | - This paper introduces a novel pipeline to generate synthetic texts that are harder for machine-generated text (MGT) detectors to identify by fine-tuning LLMs with Direct Preference Optimization (DPO) to align their writing style with human-written text (HWT). - The pipeline is evaluated on existing state-of-the-art MGT detectors using two datasets: XSUM and arXiv Abstracts, demonstrating a significant drop in their accuracy after the alignment process. - The work highlights the importance of improving detection methods to make them more robust to unseen in-domain texts. - The authors further conduct a human evaluation to assess the effectiveness of their method, comparing the ability of human raters to identify MGT before and after the DPO runs. - Finally, this work provides valuable insights into linguistic characteristics of both HWT and MGT and explores the relationship between detection performance and linguistic features. | ['Natural Language Processing', 'Text Classification', 'Text Generation'] | [Link](https://github.com/gpucce/control_mgt) | N/A |
| [VAU-R1: Advancing Video Anomaly Understanding via Reinforcement
  Fine-Tuning](https://arxiv.org/abs/2505.23504) | Xiaodong Cun, Xi Shen, Qixiang Chen, Liyun Zhu | - This paper introduces VAU-R1, a novel data-efficient framework that leverages reinforcement fine-tuning to improve the reasoning capabilities of Multimodal Large Language Models (MLLMs) for video anomaly understanding. - The framework is built upon Group Relative Policy Optimization (GRPO) and decomposes the video anomaly understanding task into four sub-tasks: multiple-choice QA, temporal anomaly grounding, anomaly reasoning, and anomaly classification. - VAU-R1 outperforms supervised fine-tuning (SFT) methods on reasoning-intensive tasks, demonstrating its effectiveness in enhancing anomaly reasoning and generalization. - The paper also introduces VAU-Bench, a new Chain-of-Thought benchmark for video anomaly reasoning that includes a diverse set of video clips and rich annotations. -  Empirical results on multiple datasets (MSAD, UCF-Crime, and ECVA) demonstrate that VAU-R1 improves accuracy, temporal grounding, and reasoning coherence across diverse contexts. | ['Video Classification', 'Reinforcement Learning', 'Multimodal', 'Visual Question Answering'] | [Link](https://github.com/GVCLab/VAU-R1) | N/A |
| [LLM in the Loop: Creating the PARADEHATE Dataset for Hate Speech
  Detoxification](https://arxiv.org/abs/2506.01484) | Helmut Schmid, Ashish Yashwanth Kangen, Lukas Kouba, Ercong Nie, shuzyuan | - This paper introduces PARADEHATE, a new large-scale parallel dataset for hate speech detoxification, containing over 8K hate/non-hate text pairs. - The dataset was created using a novel LLM-in-the-loop pipeline, which leverages GPT-40-mini to automatically generate detoxified versions of hate speech. - Experimental results demonstrate that models fine-tuned on PARADEHATE achieve better performance in style accuracy, content preservation, and fluency compared to baselines. - The study replicates the ParaDetox pipeline using LLMs instead of human annotators, showing comparable performance. - PARADEHATE is released as a benchmark for hate speech detoxification, offering a scalable alternative to human annotation. | ['Natural Language Processing', 'Text2Text Generation', 'Text Classification'] | N/A | N/A |
| [zip2zip: Inference-Time Adaptive Vocabularies for Language Models via
  Token Compression](https://arxiv.org/abs/2506.01084) | Chris Wendler, Maxime Peyrard, Yunzhen yao, Saibo Geng, nathanrchn | This paper introduces zip2zip, a framework that dynamically adjusts a language model's vocabulary at inference time using Lempel-Ziv-Welch (LZW) compression.  The method incrementally merges co-occurring tokens into reusable hypertokens, reducing input and output sequence lengths by 20-60%.  Zip2zip consists of three components: an LZW-based tokenizer, an embedding layer for new hypertokens, and a causal language modeling variant.  Experiments show significant improvements in inference latency with minimal performance degradation on downstream tasks.  The code is publicly available. | ['Natural Language Processing', 'Text Generation'] | [Link](https://github.com/epfl-dlab/zip2zip) | N/A |
| [SATA-BENCH: Select All That Apply Benchmark for Multiple Choice
  Questions](https://arxiv.org/abs/2506.00643) | Stephanie Eckman, Chi Xue, Xi Fang, Shixian Cui, xwjzds | This paper introduces SATA-BENCH, the first benchmark specifically designed to evaluate Large Language Models (LLMs) on Select All That Apply (SATA) questions.  The benchmark includes 1604 human-validated SATA questions across diverse domains.  Evaluation of 27 LLMs reveals a significant performance gap, with even the strongest model achieving only 41.8% exact match.  To address this, the authors propose Choice Funnel, a decoding strategy that achieves up to 29% higher exact match accuracy than competitive baselines while reducing inference cost by over 64%. The SATA-BENCH dataset and Choice Funnel decoding algorithm are publicly released to encourage further LLM development. | ['Question Answering'] | [Link](https://github.com/sata-bench/sata-bench) | [Link](https://huggingface.co/datasets/sata-bench/sata-bench) |
| [Cascading Adversarial Bias from Injection to Distillation in Language
  Models](https://arxiv.org/abs/2505.24842) | Milad Nasr, Ilia Shumailov, Matthew Jagielski, Jamie Hayes, Harsh Chaudhari | This paper introduces BIASED-Roots, a novel data poisoning attack against language models, where an adversary injects adversarial biases into a teacher model during training. The attack demonstrates two distinct modes of bias propagation: Untargeted Propagation and Targeted Propagation. In the Untargeted Propagation scenario, the adversarial bias affects multiple tasks, while in the Targeted Propagation scenario, the bias focuses on a specific task. This bias gets amplified when transferred to the student model via distillation. The paper validates these findings across multiple bias types, distillation methods, and data modalities, revealing that current defense mechanisms are insufficient to mitigate this issue.  The paper proposes practical design principles to build more effective adversarial bias mitigation strategies in the future. | ['Natural Language Processing', 'Text Generation', 'Text Classification'] | N/A | N/A |
| [MagiCodec: Simple Masked Gaussian-Injected Codec for High-Fidelity
  Reconstruction and Generation](https://arxiv.org/abs/2506.00385) | Ziyang Ma, Chenpeng Du, Jiawei Chen, Yakun Song, xiaobinzhuang | - The paper introduces MagiCodec, a novel single-layer, streaming Transformer-based audio codec designed for both high-fidelity reconstruction and generation. - MagiCodec utilizes a multi-stage training pipeline incorporating Gaussian noise injection and latent regularization to improve the semantic expressiveness of generated codes. - Experimental results demonstrate that MagiCodec outperforms state-of-the-art codecs in reconstruction quality and downstream tasks such as text-to-speech and automatic speech recognition. - The tokens produced by MagiCodec exhibit Zipf-like distributions, enhancing compatibility with language-model-based generative architectures. - Theoretical analysis of noise injection in the frequency domain shows its efficacy in attenuating high-frequency components. | ['Audio', 'Audio-to-Audio', 'Automatic Speech Recognition', 'Text-to-Speech'] | [Link](https://github.com/Ereboas/MagiCodec) | N/A |
| [OmniResponse: Online Multimodal Conversational Response Generation in
  Dyadic Interactions](https://arxiv.org/abs/2505.21724) | Bernard Ghanem, Siyang Song, Bing Li, Jianghui Wang, Cheng Luo | - This paper introduces Online Multimodal Conversational Response Generation (OMCRG), a novel task focusing on generating synchronized verbal and non-verbal listener feedback based on speaker's multimodal input. - The proposed model, OmniResponse, is a Multimodal Large Language Model (MLLM) that autoregressively generates high-quality multimodal listener responses by leveraging a pretrained LLM enhanced with Chrono-Text and TempoVoice components. - Chrono-Text temporally anchors generated text tokens, while TempoVoice is a controllable online TTS module that synchronizes speech with facial reactions. - A new dataset, ResponseNet, containing 696 high-quality dyadic interactions, is introduced to support further OMCRG research. - Comprehensive evaluations on ResponseNet demonstrate that OmniResponse significantly outperforms baseline models in terms of semantic speech content, audio-visual synchronization, and generation quality. | ['Multimodal', 'Text-to-Speech', 'Text-to-Audio', 'Video-Text-to-Text', 'Any-to-Any'] | [Link](https://omniresponse.github.io/) | N/A |
| [Think Again! The Effect of Test-Time Compute on Preferences, Opinions,
  and Beliefs of Large Language Models](https://arxiv.org/abs/2505.19621) | Michal Shmueli-Scheuer, Ateret Anaby-Tavor, Itay Nakash, George Kour | - This paper introduces the Preference, Opinion, and Belief Survey (POBS) benchmark, designed to evaluate the subjective tendencies of Large Language Models (LLMs) across various domains. - The benchmark is applied to several leading LLMs, assessing their reliability, neutrality, and consistency in expressing opinions on various topics. - The study examines the impact of increasing test-time compute (through reasoning and self-reflection mechanisms) on these metrics, revealing limited gains. - Interestingly, newer LLM versions exhibited increased bias and reduced consistency compared to older versions. - The findings highlight the concerning trend of LLMs becoming more biased and less consistent, underscoring the need for ongoing evaluation and improved methods to mitigate these issues. | ['Natural Language Processing', 'Question Answering'] | [Link](https://ibm.github.io/POBS) | N/A |
| [LIFT the Veil for the Truth: Principal Weights Emerge after Rank
  Reduction for Reasoning-Focused Supervised Fine-Tuning](https://arxiv.org/abs/2506.00772) | Tianjin Huang, Chaoqun Yang, Oleg Balabanov, Tianyu Pang, Zihang Liu |  - This paper introduces LIFT, a novel low-rank informed sparse fine-tuning method for LLMs that focuses on updating only the most important weights for reasoning tasks.  - LIFT outperforms Full FT and other state-of-the-art parameter-efficient methods on various reasoning benchmarks.  - LIFT consistently achieves better performance than Full FT while maintaining comparable memory efficiency to popular methods like LoRA.  - The method identifies principal weights by applying low-rank approximation and selecting weights with the largest magnitudes.  - LIFT balances learning and forgetting, retaining pre-training knowledge and adapting to new downstream tasks effectively. | ['Natural Language Processing'] | [Link](https://github.com/zihanghliu/LIFT) | N/A |
| [CityLens: Benchmarking Large Language-Vision Models for Urban
  Socioeconomic Sensing](https://arxiv.org/abs/2506.00530) | Tianjian Ouyang, Xin Zhang, Hetian Pang, Jie Feng, Tianhui Liu | - CityLens, a comprehensive benchmark, is introduced to evaluate large language-vision models (LLVMs) for predicting socioeconomic indicators from visual data. - The benchmark comprises a multi-modal dataset covering 17 cities globally, encompassing 6 key domains (economy, education, crime, transport, health, and environment) and 11 prediction tasks. - Three evaluation paradigms are utilized: Direct Metric Prediction, Normalized Metric Estimation, and Feature-Based Regression, benchmarking 17 state-of-the-art LLVMs. - While LLVMs show promise, limitations remain in accurately predicting urban socioeconomic indicators, particularly for nuanced domains such as health and education. - CityLens offers a unified framework for diagnosing these limitations and guiding future research in using LLVMs for urban socioeconomic sensing. | ['Multimodal'] | [Link](https://github.com/tsinghua-fib-lab/CityLens) | N/A |
| [Massively Multilingual Adaptation of Large Language Models Using
  Bilingual Translation Data](https://arxiv.org/abs/2506.00469) | Hengyu Luo, Indraneil Paul, Jaakko Paavola, Zihao Li, jisx | This paper introduces the MaLA bilingual translation corpus, containing data from more than 2,500 language pairs, and four massively multilingual models continually pre-trained on Llama 3.  The EMMA-500 models were trained with monolingual and bilingual data mixes. Experiments on seven tasks and twelve benchmarks demonstrate that bilingual data generally enhances language transfer and performance, especially for low-resource languages. The EMMA-500 models outperform baselines on multiple benchmarks, particularly in machine translation, showcasing superior multilingual abilities. The MaLA corpus, EMMA-500 Llama 3 models, and code are open-sourced. | ['Natural Language Processing', 'Translation', 'Summarization', 'Text Classification', 'Question Answering'] | [Link](https://github.com/MaLA-LM/emma-500) | [Link](https://huggingface.co/collections/MaLA-LM), [Link](https://hugface.co/datasets/MaLA-LM/mala-bilingual-translation-corpus) |
| [From Guidelines to Practice: A New Paradigm for Arabic Language Model
  Evaluation](https://arxiv.org/abs/2506.01920) | Abdulrahman Al-Batati, Yasser Al-Habashi, Adel Ammar, Omer Nacar, Serry Sibaee | - This paper introduces the Arabic Depth Mini Dataset (ADMD), a new evaluation framework for Arabic language models that addresses the limitations of existing datasets. - ADMD consists of 490 challenging questions across ten major domains, requiring deep cultural understanding and specialized knowledge. - Five leading language models were evaluated using ADMD, revealing significant variations in performance across domains. - Claude 3.5 Sonnet demonstrated the highest overall accuracy, highlighting the importance of cultural competence in model evaluation. - The study provides theoretical guidelines and practical insights for improving Arabic language model evaluation, emphasizing the need for culturally aware and methodologically rigorous benchmarks. | ['Question Answering'] | [Link](https://github.com/serrysibaee/EAED) | [Link](https://huggingface.co/CohereForAI/c4ai-command-r), [Link](https://qwenlm.github.io/blog/qwen2.5-max/) |
| [MIKU-PAL: An Automated and Standardized Multi-Modal Method for Speech
  Paralinguistic and Affect Labeling](https://arxiv.org/abs/2505.15772) | Jiatong Shi, Ruoyi Zhang, Yifan Cheng | - MIKU-PAL, a novel multimodal framework, is introduced to automate emotion annotation in audio, visual, and text modalities. - MIKU-PAL achieves high consistency in emotion judgments (Fleiss's kappa of 0.93) with flexible emotion categories, expanding them to 26 categories validated by human annotators. - MIKU-PAL outperforms human annotators on IEMOCAP and MELD in terms of both accuracy and consistency, with significant cost and time reduction. - A new fine-grained emotional speech dataset, MIKU-EmoBench (131.2 hours), is released as a benchmark for emotional text-to-speech and visual voice cloning. - MIKU-EmoBench demonstrates better performance for fine-tuned emotional TTS models compared to existing datasets, including IEMOCAP, MELD and MSP-Podcast. | ['Audio', 'Text-to-Speech', 'Multimodal'] | N/A | [Link](https://huggingface.co/datasets/WhaleDolphin/MIKU-EmoBench) |
