

## Papers for 2025-06-05

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [MiMo-VL Technical Report](https://arxiv.org/abs/2506.03569) | Prestonprom, dwzhu, tobiaslee, gsh33, ShuhuaiRen |  - This paper introduces MiMo-VL-7B-SFT and MiMo-VL-7B-RL, two powerful vision-language models.  - MiMo-VL-7B-RL outperforms Qwen2.5-VL-7B on 35 out of 40 evaluated tasks and achieves a score of 59.4 on OlympiadBench, surpassing models with up to 78B parameters. - The models are trained using a four-stage pre-training phase (2.4 trillion tokens) combined with Mixed On-policy Reinforcement Learning (MORL).  - The training incorporates high-quality reasoning data with long Chain-of-Thought and addresses challenges in simultaneous multi-domain optimization.  - Model checkpoints and a comprehensive evaluation suite are available at https://github.com/XiaomiMiMo/MiMo-VL. | ['Multimodal'] | [Link](https://github.com/XiaomiMiMo/MiMo-VL) | N/A |
| [Advancing Multimodal Reasoning: From Optimized Cold Start to Staged
  Reinforcement Learning](https://arxiv.org/abs/2506.04207) | Yafu Li, Yue Guo, Shuang Chen, JC-Chen, Warrieryes | - This paper introduces ReVisual-R1, a novel 7B parameter open-source multimodal large language model (MLLM) that achieves state-of-the-art performance on various challenging multimodal reasoning benchmarks. - ReVisual-R1 employs a three-stage training curriculum: a text-only cold start phase, a multimodal reinforcement learning phase using a novel Prioritized Advantage Distillation (PAD) algorithm, and a final text-only reinforcement learning phase. - The PAD algorithm addresses the gradient stagnation problem in standard Group Relative Policy Optimization (GRPO) by prioritizing informative training samples. - Experiments demonstrate that ReVisual-R1 significantly outperforms existing open-source models and even surpasses some commercial models on several key benchmarks. - The findings highlight the importance of a well-designed training curriculum that balances perceptual grounding and cognitive reasoning development in MLLMs. | ['Multimodal', 'Reinforcement Learning'] | [Link](https://github.com/CSfufu/Revisual-R1) | N/A |
| [SuperWriter: Reflection-Driven Long-Form Generation with Large Language
  Models](https://arxiv.org/abs/2506.04180) | Roy Ka-Wei Lee, Juanzi Li, Yushi Bai, Yuhao Wu, Zhiqiang007 | This paper introduces SuperWriter-Agent, a novel agent-based framework designed to improve the quality and consistency of long-form text generation.  It incorporates explicit structured thinking through planning and refinement stages, guiding the model using a more deliberate process. The framework is used to create a supervised fine-tuning dataset to train a 7B SuperWriter-LM. SuperWriter-LM outperforms larger-scale baseline models in both automatic and human evaluation.  Hierarchical Direct Preference Optimization (DPO) further enhances performance by optimizing each generation step using Monte Carlo Tree Search (MCTS). The code and models are publicly available. | ['Text Generation'] | [Link](https://github.com/mozhu621/SuperWriter) | N/A |
| [Voyager: Long-Range and World-Consistent Video Diffusion for Explorable
  3D Scene Generation](https://arxiv.org/abs/2506.04225) | Zhenwei Wang, Yuhao Liu, Tengfei Wang, Wangguandong Zheng, tyhuang | - Voyager is a novel video diffusion framework that generates world-consistent 3D point-cloud sequences from a single image with user-defined camera paths. - It jointly generates aligned depth and RGB videos, ensuring global coherence and eliminating the need for 3D reconstruction pipelines. - The model employs a world cache mechanism and auto-regressive inference with smooth video sampling for efficient long-range scene generation. - Voyager outperforms existing methods in visual quality and geometric accuracy, as demonstrated by quantitative evaluations on the RealEstate 10K dataset. - The framework also incorporates a scalable data engine for efficient data curation without manual 3D annotations, further enhancing its versatility. | ['Image-to-Video', 'Text-to-Video', 'Image-to-3D', 'Video Classification', 'Depth Estimation', 'Multimodal'] | N/A | N/A |
| [SVGenius: Benchmarking LLMs in SVG Understanding, Editing and Generation](https://arxiv.org/abs/2506.03139) | Xingyu Wu, Xinyu Dong, yanyc, zjuxhl, xiaoooobai |  - The paper introduces SVGenius, a comprehensive benchmark for evaluating LLMs' capabilities in SVG processing.  - SVGenius evaluates models across three progressive dimensions: understanding, editing, and generation, using real-world data from 24 application domains.  - The benchmark features a novel complexity stratification framework based on quantitative metrics, allowing for a systematic assessment of model performance across varying complexities.  - Experiments on 22 mainstream models reveal that proprietary models significantly outperform open-source counterparts, but all models exhibit systematic performance degradation with increasing complexity.  - Reasoning-enhanced training proves more effective than pure scaling for overcoming these limitations. | ['Multimodal'] | [Link](https://github.com/ZJU-REAL/SVGenius-Bench) | N/A |
| [Unleashing the Reasoning Potential of Pre-trained LLMs by Critique
  Fine-Tuning on One Problem](https://arxiv.org/abs/2506.03295) | Wenhu Chen, Lijun Wu, Kai Zou, Ping Nie, Yubo Wang | - This paper introduces Critique Fine-Tuning (CFT), a novel technique for enhancing the reasoning capabilities of pre-trained large language models (LLMs). - CFT constructs critique data by collecting diverse model-generated solutions to a single problem and using teacher LLMs to provide detailed critiques, then fine-tunes the model on this data. - Experiments show that CFT, even when applied to only one problem, significantly improves the performance of LLMs on various reasoning tasks, outperforming reinforcement learning methods while requiring considerably less compute. - The effectiveness of one-shot CFT is demonstrated across different model sizes and problem types, showcasing its robustness and generalizability. - Ablation studies highlight the impact of model scale and the diversity of candidate solutions on the performance of CFT. | ['Natural Language Processing'] | N/A | N/A |
| [Rectified Sparse Attention](https://arxiv.org/abs/2506.04108) | Jian Chen, Yuqing Xia, Li Dong, Tianzhu Ye, Yutao Sun | - This paper introduces Rectified Sparse Attention (ReSA), a novel method for efficient long-sequence generation in large language models. - ReSA combines block-sparse attention with periodic dense rectification to mitigate the accumulation of approximation errors in the key-value cache, which is a common problem in sparse decoding methods. - Experimental results across various tasks demonstrate that ReSA significantly improves efficiency while maintaining near-lossless generation quality compared to dense attention methods. - ReSA achieves up to a 2.42x end-to-end speedup under decoding at 256K sequence length, making it practical for real-world deployment. - The code for ReSA is publicly available. | ['Text Generation'] | [Link](https://aka.ms/ReSA-LM) | N/A |
| [Beyond the Surface: Measuring Self-Preference in LLM Judgments](https://arxiv.org/abs/2506.02592) | Yankai Lin, Enrui Hu, Xinyu Zhang, Hao Wang, JaxChen | - This paper introduces the DBG score, a novel metric for measuring self-preference bias in LLMs, which addresses the confounding effect of response quality.- The DBG score uses gold judgments as proxies for actual response quality, mitigating the confounding influence of response quality on bias measurement.- Comprehensive experiments using the DBG score reveal that self-preference bias exists across LLMs with varying versions, sizes, and reasoning abilities; larger models tend to exhibit less bias.- It investigates the impact of response text style and post-training data on self-preference bias, showing that aligning response styles and training on the same data can help alleviate the bias.- An attention-based perspective explores the potential underlying mechanisms of self-preference bias, showing that models naturally tend to assign higher attention scores to their own responses. | ['Natural Language Processing'] | [Link](https://github.com/zhiyuanc2001/self-preference) | N/A |
| [Establishing Trustworthy LLM Evaluation via Shortcut Neuron Analysis](https://arxiv.org/abs/2506.04142) | Juanzi Li, Lei Hou, Zhuoran Jin, Shangqing Tu, Kejian Zhu | - This paper introduces a novel method for establishing trustworthy Large Language Model (LLM) evaluation by analyzing shortcut neurons. - The method identifies shortcut neurons through comparative and causal analysis, focusing on neurons exhibiting significant activation differences between contaminated and uncontaminated models. - A shortcut neuron patching technique is proposed to mitigate the impact of contamination by suppressing shortcut neuron activation, leading to more reliable evaluation results. - Experiments demonstrate the effectiveness of the method, showing a strong correlation with existing trustworthy benchmarks (Spearman coefficient exceeding 0.95). - The method's generalizability is validated across various benchmarks and hyperparameter settings. | ['Natural Language Processing'] | [Link](https://github.com/GaryStack/Trustworthy-Evaluation) | N/A |
| [Robustness in Both Domains: CLIP Needs a Robust Text Encoder](https://arxiv.org/abs/2506.03355) | Matthias Hein, Yongtao Wu, Naman Deep Singh, Elias Abad Rocamora, chs20 | This paper introduces LEAF, an adversarial finetuning method for improving the robustness of CLIP text encoders. LEAF is efficient and scalable to large CLIP models, significantly improving zero-shot adversarial accuracy in the text domain while maintaining vision performance.  When combined with text-to-image diffusion models, LEAF improves generation quality under adversarial noise and enhances recall in multimodal retrieval tasks.  Finally, LEAF facilitates better text reconstruction from embeddings.  Experiments demonstrate improved robustness across various tasks compared to standard CLIP models and other methods. | ['Multimodal', 'Text-to-Image', 'Zero-Shot Image Classification', 'Text Classification'] | [Link](https://github.com/LIONS-EPFL/LEAF) | [Link](https://huggingface.co/LEAF-CLIP) |
| [Quantitative LLM Judges](https://arxiv.org/abs/2506.02945) | Pranchal Agarwal, Tushar Parmanand Budhwani, Jeevana Kruthi Karnuthala, Aishwarya Sahoo, Franck-Dernoncourt | - This paper introduces quantitative LLM judges, a novel framework that enhances existing LLM judges by using regression models to align their evaluation scores with human scores. - The framework decouples qualitative reasoning from quantitative assessment, improving accuracy and efficiency. - Four quantitative judges are proposed for different types of feedback, demonstrating the framework's versatility. - Experiments on four datasets show that quantitative judges effectively improve the predictive power of existing judges, outperforming both base judges and fine-tuned models in most cases. - The framework is more computationally efficient than supervised fine-tuning, making it particularly useful when human feedback is limited. | ['Natural Language Processing'] | N/A | N/A |
| [BenchHub: A Unified Benchmark Suite for Holistic and Customizable LLM
  Evaluation](https://arxiv.org/abs/2506.00482) | Hitesh Patel, Guijin Son, Haneul Yoo, aliceoh, EunsuKim |  - This paper introduces BenchHub, a unified benchmark suite designed for holistic and customizable LLM evaluation.  - BenchHub aggregates and automatically classifies benchmark datasets from various domains, integrating 303K questions across 38 benchmarks.  - It supports continuous updates, scalable data management, and flexible and customizable evaluation.  - Experiments demonstrate that model performance varies significantly across domains, emphasizing the importance of domain-aware benchmarking.  - BenchHub provides a critical infrastructure for advancing LLM evaluation research. | ['Question Answering'] | [Link](https://github.com/rladmstn1714/BenchHub) | [Link](https://huggingface.co/BenchHub) |
| [DLP: Dynamic Layerwise Pruning in Large Language Models](https://arxiv.org/abs/2505.23807) | Yingting Li, Yingying Zhang, Jiale Han, Bo Cheng, yulichen |  - This paper introduces a novel dynamic layerwise pruning method called Dynamic Layerwise Pruning (DLP) for Large Language Models (LLMs).  - DLP adaptively determines the relative importance of each layer by integrating model weights with input activation information and assigns pruning rates accordingly, overcoming the limitations of existing methods that rely on predefined values.  - Experimental results on multiple LLMs demonstrate that DLP effectively preserves model performance at high sparsity levels, outperforming state-of-the-art methods.  Specifically, at 70% sparsity, DLP reduces the perplexity of LLaMA2-7B by 7.79 and improves average accuracy by 2.7%.  - The method is compatible with various LLM compression techniques and seamlessly integrates into Parameter-Efficient Fine-Tuning (PEFT).  - The code for DLP is publicly available on Github. | ['Natural Language Processing'] | [Link](https://github.com/ironartisan/DLP) | N/A |
| [TRiSM for Agentic AI: A Review of Trust, Risk, and Security Management
  in LLM-based Agentic Multi-Agent Systems](https://arxiv.org/abs/2506.04133) | Christos Emmanouilidis, Manoj Karkee, Ranjan Sapkota, shainar | This paper reviews Trust, Risk, and Security Management (TRISM) in Large Language Model (LLM)-based Agentic Multi-Agent Systems (AMAS).  It introduces a conceptual TRISM framework tailored to agentic AI, detailing four pillars: governance, explainability, ModelOps, and privacy/security.  Unique threat vectors for AMAS are identified and a comprehensive risk taxonomy is presented.  The paper surveys state-of-the-art explainability strategies and trust-building mechanisms, along with security and privacy measures. Finally, it provides a roadmap for future research directions for responsible agentic AI. | ['Natural Language Processing'] | N/A | N/A |
| [Rex-Thinker: Grounded Object Referring via Chain-of-Thought Reasoning](https://arxiv.org/abs/2506.04034) | Lei Zhang, Junzhi Yu, Zhaoyang Zeng, Xingyu Chen, Qing Jiang | Rex-Thinker is a novel multimodal large language model that performs object referring via Chain-of-Thought (CoT) reasoning.  The model first extracts candidate object boxes corresponding to a given referring expression and then performs step-by-step reasoning over each candidate box.  A large-scale CoT-style referring dataset named HumanRef-CoT was created to support this paradigm. Experiments demonstrate that the CoT-based approach outperforms existing methods in terms of both precision and interpretability, while also showing strong generalization ability.  The model uses a two-stage training process: cold-start supervised fine-tuning followed by reinforcement learning. | ['Multimodal', 'Object Detection', 'Visual Question Answering'] | [Link](https://github.com/IDEA-Research/Rex-Thinker) | N/A |
| [VLMs Can Aggregate Scattered Training Patches](https://arxiv.org/abs/2506.03614) | Chaochao Lu, Chao Yang, Lingjie Chen, Zhanhui Zhou | - This paper introduces the concept of visual stitching in Vision-Language Models (VLMs), where the model integrates visual information from scattered training patches to generate coherent responses. - The authors demonstrate that visual stitching enables adversarial attacks by splitting harmful images into benign-looking patches, bypassing data moderation, and causing the VLM to incorrectly label harmful content as safe. - Three synthetic datasets (food, animal, and landmark) are used to evaluate the emergent capabilities of visual stitching in various open-source VLMs. - Experiments show that most open-source VLMs exhibit strong image-based visual stitching, even when trained on extremely small patches, while reference-based visual stitching shows less reliability. - The paper highlights the safety implications of visual stitching, demonstrating a potential vulnerability in data moderation techniques and urging further research on mitigating this risk. | ['Multimodal'] | [Link](https://github.com/ZHZisZZ/visual-stitching) | N/A |
| [Follow the Flow: Fine-grained Flowchart Attribution with Neurosymbolic
  Agents](https://arxiv.org/abs/2506.01344) | Ryan A. Rossi, Nedim Lipka, Manan Suri, Franck-Dernoncourt, puneetm | - This paper introduces the task of Fine-grained Flowchart Attribution, aiming to identify the optimal path within a flowchart that supports the model's response. - A novel benchmark, FlowExplainBench, is presented for evaluating flowchart attribution across diverse styles, domains, and question types. - The paper proposes FlowPathAgent, a neurosymbolic agent that performs fine-grained post-hoc attribution through graph-based reasoning, outperforming strong baselines by 10-14% on FlowExplainBench. - FlowPathAgent leverages graph tools to precisely attribute the model's reasoning steps to specific decision points within the flowchart, enhancing the interpretability and reliability of automated decision-making. - The study also addresses challenges in handling diverse flowchart styles and explores potential future directions for dynamic flowchart processing and more robust handling of complex structures. | ['Visual Question Answering', 'Graph Machine Learning', 'Multimodal'] | N/A | N/A |
| [FinChain: A Symbolic Benchmark for Verifiable Chain-of-Thought Financial
  Reasoning](https://arxiv.org/abs/2506.02515) | Rushil Thareja, Georgi Georgiev, Debopriyo Banerjee, Dhruv Sahnan, Zhuohan Xie | - This paper introduces FINCHAIN, a new symbolic benchmark dataset designed for verifiable chain-of-thought financial reasoning. - The dataset includes 54 topics across 12 financial domains, each with five parameterized templates varying in reasoning complexity. - Each dataset instance has an executable Python trace, enabling automatic generation of training data and easy adaptation to other domains. - The paper introduces CHAINEVAL, a new metric for automatic evaluation of both final answers and intermediate reasoning steps. - Experimental results show that even state-of-the-art LLMs have significant room for improvement in multi-step financial reasoning tasks. | ['Natural Language Processing', 'Question Answering', 'Text Generation'] | [Link](https://github.com/mbzuai-nlp/finchain) | N/A |
