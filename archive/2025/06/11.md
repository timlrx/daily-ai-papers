

## Papers for 2025-06-11

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [Geopolitical biases in LLMs: what are the "good" and the "bad" countries
  according to contemporary language models](https://arxiv.org/abs/2506.06751) | Dmitrii Korzh, tlenusik, apanc, IvanLazichny, msalnikov | - This paper introduces a novel dataset containing neutral event descriptions and contrasting viewpoints from different countries to evaluate geopolitical biases in LLMs. - The findings reveal significant geopolitical biases in LLMs, with models exhibiting preferences for specific national narratives. - Simple debiasing prompts show limited effectiveness in mitigating these biases. - Experiments manipulating participant labels demonstrate models' sensitivity to attribution, sometimes amplifying biases or highlighting inconsistencies. - The study offers a framework and dataset for future research into geopolitical bias in LLMs. | ['Natural Language Processing', 'Text Classification'] | [Link](https://github.com/AIRI-Institute/geopolitical_llm_bias) | N/A |
| [RuleReasoner: Reinforced Rule-based Reasoning via Domain-aware Dynamic
  Sampling](https://arxiv.org/abs/2506.08672) | Jiaqi Li, Yang Liu, zlzheng |  - This paper introduces RuleReasoner, a novel method for rule-based reasoning that uses reinforcement learning and domain-aware dynamic sampling.  - RuleReasoner resamples each training batch by updating the sampling weights of different domains based on historical rewards, which improves both training efficiency and task performance.  - Experiments show that RuleReasoner outperforms existing large reasoning models (LRMs) by a significant margin on both in-distribution (ID) and out-of-distribution (OOD) benchmarks.  - The model achieves an average improvement of 4.1% on eight ID tasks and 10.4% on three OOD tasks over OpenAI-01.  - RuleReasoner demonstrates its effectiveness and efficiency by reducing training steps while achieving comparable performance to other state-of-the-art methods. | ['Reinforcement Learning', 'Natural Language Processing', 'Question Answering'] | [Link](https://github.com/bigai-nlco/RuleReasoner) | [Link](https://huggingface.co/RuleReasoner) |
| [Solving Inequality Proofs with Large Language Models](https://arxiv.org/abs/2506.07927) | Alex Gu, Tony Xia, Jikai Jin, Luna Lyu, Jiayi Sheng | This paper introduces INEQMATH, a new dataset of Olympiad-level inequality problems, designed to evaluate large language models' (LLMs) ability to prove inequalities.  The authors propose a novel LLM-as-judge framework for evaluation, measuring both final-answer accuracy and step-wise soundness. The experiments show a significant gap between final-answer accuracy and overall proof correctness in leading LLMs. The findings highlight promising research directions, such as theorem-guided reasoning and self-refinement. The paper also presents an informal yet verifiable task formulation for inequality proving, decomposing it into two automatically checkable subtasks.  The dataset and evaluation framework are made publicly available. | ['Natural Language Processing'] | [Link](https://ineqmath.github.io/) | [Link](https://huggingface.co/spaces/AI4Math/IneqMath-Leaderboard) |
| [Look Before You Leap: A GUI-Critic-R1 Model for Pre-Operative Error
  Diagnosis in GUI Automation](https://arxiv.org/abs/2506.04614) | Junyang Wang, Haowei Liu, Haiyang Xu, Xi Zhang, Yuyang Wanyan | - The paper introduces GUI-Critic-R1, a pre-operative critic model for GUI automation that uses a Suggestion-aware Group Relative Policy Optimization (S-GRPO) strategy to enhance the reliability of its feedback. - GUI-Critic-R1 incorporates a novel suggestion reward to improve the quality of the model's feedback, helping to prevent errors before they occur. - The model was evaluated on both mobile and web domains, outperforming existing MLLMs on a GUI automation benchmark. - A reasoning-bootstrapping based data collection pipeline was developed to create the GUI-Critic-Train and GUI-Critic-Test datasets, addressing the lack of publicly available GUI critic data. - Experiments demonstrated that GUI-Critic-R1 offers significant advantages in critic accuracy and operational efficiency compared to current MLLMs. | ['Reinforcement Learning', 'Multimodal'] | [Link](https://github.com/X-PLUG/MobileAgent/tree/main/GUI-Critic-R1) | N/A |
| [Aligning Text, Images, and 3D Structure Token-by-Token](https://arxiv.org/abs/2506.08002) | Georgia Gkioxari, Vansh Tibrewal, Aadarsh Sahoo |  - Kyvo is a novel unified multimodal large language model that aligns text, images, and structured 3D scenes in a token-by-token manner. - The model architecture is a decoder-only transformer that uses a structured 3D modality representing scenes as lists of objects with attributes such as shape, type, position, pose, and size. - Kyvo achieves state-of-the-art performance on four core 3D tasks including rendering, recognition, instruction following, and question answering. - The model generalizes well to complex object shapes and real-world scenarios demonstrating effectiveness on real-world datasets. - Kyvo also uses a vector-quantized 3D shape representation and significantly reduces sequence length compared to text-only tokenizers. | ['Multimodal', 'Image-to-3D', 'Text-to-3D', 'Image-Text-to-Text', 'Visual Question Answering', 'Question Answering', 'Text-to-Image', 'Image-to-Image', 'Image-Text-to-Text', 'Text Generation', 'Image-Text-to-Text', 'Object Detection', 'Image Classification'] | N/A | N/A |
| [MoA: Heterogeneous Mixture of Adapters for Parameter-Efficient
  Fine-Tuning of Large Language Models](https://arxiv.org/abs/2506.05928) | Wenqiao Zhang, Rolan Yan, Hongyang He, Tianwei Lin, cajie | - This paper introduces a novel heterogeneous Mixture-of-Adapters (MoA) method for parameter-efficient fine-tuning of large language models (LLMs). - The MoA architecture dynamically integrates PEFT adapter experts with diverse structures, leveraging their complementary representational capabilities to enhance knowledge transfer to downstream tasks. -  MoA supports two variants: Soft MoA (weighted fusion of all expert outputs) and Sparse MoA (sparsely activates experts based on contribution). - Experimental results demonstrate that heterogeneous MoA outperforms homogeneous MoE-LORA methods in both performance and parameter efficiency. - The project's code is available on GitHub. | ['Natural Language Processing'] | [Link](https://github.com/DCDmllm/MoA) | N/A |
| [Institutional Books 1.0: A 242B token dataset from Harvard Library's
  collections, refined for accuracy and usability](https://arxiv.org/abs/2506.08300) | Kristi Mukk, Jack Cushman, John Hess, Catherine Brobston, Matteo Cargnelutti | This research paper introduces Institutional Books 1.0, a 242B token dataset comprising public domain books from Harvard Library.  The dataset undergoes several processing steps, including OCR extraction, text analysis, and rights determination, and is released with comprehensive metadata.  The authors created a topic classification model (achieving 97.8% accuracy during benchmarking) to categorize the volumes into 20 high-level topics.  They also offer post-processed OCR text alongside the original.  The goal is to create a publicly available, high-quality dataset to promote further research and development in LLMs. | ['Natural Language Processing', 'Text Classification'] | [Link](https://github.com/instdin/institutional-books-1-pipeline), [Link](https://github.com/instdin/institutional-books-1-0) | [Link](https://huggingface.co/datasets/instdin/institutional-books-1.0), [Link](https://huggingface.co/instdin/institutional-books-topic-classifier-bert) |
| [Mathesis: Towards Formal Theorem Proving from Natural Languages](https://arxiv.org/abs/2506.07047) | Roozbeh Yousefzadeh, Pengyi Zhai, Zijin Feng, Yu Xuejun, Jianyuan1 | - This paper introduces Mathesis, a novel end-to-end theorem proving pipeline that processes informal problem statements in natural language. - Mathesis-Autoformalizer, a reinforcement learning-based autoformalizer, enhances the formalization ability of natural language problems and outperforms existing methods by 22% in pass rate on the Gaokao-Formal benchmark. - A novel LeanScorer framework provides nuanced formalization quality assessment. - Mathesis-Prover generates formal proofs from formalized statements, achieving state-of-the-art accuracy on MiniF2F (64%) and Gaokao-Formal (18%). - The Gaokao-Formal benchmark, comprising 488 complex problems from China's national college entrance exam, is introduced to evaluate the real-world applicability of the system. | ['Natural Language Processing'] | N/A | N/A |
| [RKEFino1: A Regulation Knowledge-Enhanced Large Language Model](https://arxiv.org/abs/2506.05700) | Jeff Zhao, Ruoyu Xiang, Yueru He, YanAdjeNole | - This paper introduces RKEFino1, a regulation knowledge-enhanced large language model built upon Fino1 and fine-tuned with domain knowledge from XBRL, CDM, and MOF. - The model is evaluated on three tasks: knowledge-based QA, mathematical reasoning QA, and a novel Numerical NER task covering financial entities in sentences and tables. - RKEFino1 significantly outperforms Fino1 across all three tasks, demonstrating the effectiveness of incorporating regulatory knowledge. - The improvement is particularly noticeable in tasks requiring precise answers or detailed explanations of financial regulations. - The authors have released their model on Hugging Face. | ['Question Answering'] | N/A | [Link](https://huggingface.co/YanAdjeNole/RKEFino1-14B) |
| [QQSUM: A Novel Task and Model of Quantitative Query-Focused
  Summarization for Review-based Product Question Answering](https://arxiv.org/abs/2506.04020) | Zhuang Li, Minh Ngoc Dinh, Xiuzhen Zhang, An Quang Tang | - This paper introduces a novel task, Quantitative Query-Focused Summarization (QQSUM), aiming to generate comprehensive answers to product questions by summarizing diverse customer opinions and quantifying their prevalence. - The proposed model, QQSUM-RAG, extends the Retrieval-Augmented Generation (RAG) framework by integrating KP-oriented retrieval and summarization, ensuring the generation of diverse and representative summaries. - QQSUM-RAG jointly trains a KP-oriented retriever and a KP summary generator using a co-training strategy, achieving superior performance in both textual quality and quantification accuracy compared to state-of-the-art RAG baselines. - The model leverages few-shot learning, addressing the challenge of limited training data for this specialized task, and utilizes a carefully curated dataset of queries with KPs and their prevalence quantification for few-shot learning. - Experimental results demonstrate that QQSUM-RAG significantly outperforms existing RAG baselines, showcasing improvement in textual similarity with ground-truth KPs and quantification performance over state-of-the-art systems. | ['Question Answering', 'Summarization'] | [Link](https://github.com/antangrocket1312/QQSUMM) | N/A |
