

## Papers for 2025-06-13

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [ReasonMed: A 370K Multi-Agent Generated Dataset for Advancing Medical
  Reasoning](https://arxiv.org/abs/2506.09513) | Weiwen Xu, Xingyu Qian, Swrooy, 26hzhang, YuSun-AI | - ReasonMed, a new 370K medical reasoning dataset, is introduced.  It was generated using a multi-agent system and refined through a multi-stage process. - The dataset includes diverse medical insights and combines detailed chain-of-thought reasoning with concise answer summaries. - A new benchmark, ReasonMed-7B, is presented, outperforming the previous state-of-the-art by 4.17% and exceeding LLaMA3.1-70B on PubMedQA by 4.60%. - The study systematically investigates best practices for training medical reasoning models and finds that combining detailed Chain-of-Thought reasoning with concise answer summaries is most effective. - ReasonMed is publicly released to facilitate future research in medical reasoning. | ['Question Answering'] | N/A | N/A |
| [Text-Aware Image Restoration with Diffusion Models](https://arxiv.org/abs/2506.09993) | Jihye Park, Jaeeun Lee, paulcho98, jinlovespho, Min-Jaewon |  - This paper introduces a novel task called Text-Aware Image Restoration (TAIR), which aims to simultaneously recover visual content and textual fidelity in degraded images.  - A large-scale benchmark dataset called SA-Text (100K high-quality images with dense text annotations) is created to facilitate research on TAIR.  - A multi-task diffusion model named TeReDiff is proposed. TeReDiff integrates internal features from diffusion models into a text-spotting module, allowing both components to benefit from joint training.  - TeReDiff outperforms existing state-of-the-art restoration methods on SA-Text, achieving significant improvements in text recognition accuracy.  - Extensive experiments demonstrate that the proposed model consistently achieves higher performance in both perceptual quality and character legibility compared to existing methods. | ['Computer Vision', 'Image-to-Image', 'Multimodal'] | [Link](https://cvlab-kaist.github.io/TAIR/) | N/A |
| [Domain2Vec: Vectorizing Datasets to Find the Optimal Data Mixture
  without Training](https://arxiv.org/abs/2506.10952) | Xipeng Qiu, Lu Wang, Howe77, mzzhang |  - This paper introduces DOMAIN2VEC, a novel method that vectorizes datasets into linear combinations of meta-domains to identify optimal data mixtures for large language models (LLMs). - DOMAIN2VEC uses a classifier to decompose datasets into domain vectors representing distributions over meta-domains, enabling training-free identification of optimal mixtures under the Distribution Alignment Assumption (DA2). - The method is shown to enhance downstream task performance with minimal computational overhead; achieving the same validation loss as the original mixture using only 51.5% of the computational cost, and a 2.83% average performance improvement under equal compute budget. - DOMAIN2VEC seamlessly integrates with previous methods, improving efficiency and scalability by modeling the relationship between domain vectors and LLM performance. - Extensive experiments demonstrate that DOMAIN2VEC effectively finds data mixtures that enhance downstream task performance. | ['Natural Language Processing'] | N/A | N/A |
| [Optimus-3: Towards Generalist Multimodal Minecraft Agents with Scalable
  Task Experts](https://arxiv.org/abs/2506.10357) | Weili Guan, Gongwei Chen, Rui Shao, Yuquan Xie, Zaijing Li | - This paper introduces Optimus-3, a generalist multimodal agent for Minecraft that integrates perception, planning, action, grounding, and reflection capabilities. - Optimus-3 utilizes a Mixture-of-Experts (MoE) architecture with task-level routing to mitigate interference among heterogeneous tasks and improve scalability. - The model employs a Multimodal Reasoning-Augmented Reinforcement Learning approach to enhance reasoning capabilities and adapt to the visual diversity of Minecraft. - Experimental results demonstrate that Optimus-3 surpasses both generalist multimodal large language models and existing state-of-the-art agents across a range of Minecraft tasks. - The authors address the challenges of insufficient domain-specific data, task interference, and visual diversity in open-world environments through three key contributions: a knowledge-enhanced data generation pipeline, a task-level routing MoE architecture, and a multimodal reasoning-augmented reinforcement learning approach. | ['Reinforcement Learning', 'Multimodal', 'Robotics'] | [Link](https://cybertronagent.github.io/Optimus-3.github.io/) | N/A |
| [ChineseHarm-Bench: A Chinese Harmful Content Detection Benchmark](https://arxiv.org/abs/2506.10960) | Bozhong Tian, Siyuan Cheng, Kangwei Liu, Jasonchen123, Ningyu | - This paper introduces ChineseHarm-Bench, a new benchmark dataset for Chinese harmful content detection, addressing the scarcity of such resources. - The dataset comprises six categories of harmful content (gambling, pornography, abuse, fraud, illicit ads, and non-violation), with each category containing approximately 15,000 real-world examples and a total of 52,000 non-violation samples. -  A knowledge rule base is created during the annotation process, providing explicit expert knowledge to assist LLMs in detection and improve resource efficiency for smaller models. - A knowledge-augmented baseline is proposed to enhance the performance of smaller LLMs by integrating both annotated knowledge rules and implicit knowledge from large language models, achieving performance comparable to state-of-the-art LLMs. -  Extensive experiments demonstrate the effectiveness of the proposed approach, particularly in improving the performance of smaller models and addressing the challenges of Chinese harmful content detection. | ['Text Classification'] | [Link](https://github.com/zjunlp/ChineseHarm-bench) | N/A |
| [Magistral](https://arxiv.org/abs/2506.10910) | Gabrielle Berrada, Andy Lo, Albert Q. Jiang, Abhinav Rastogi, Mistral-AI | - Introduced Magistral, Mistral's first reasoning model, trained using a novel reinforcement learning pipeline. - The pipeline does not rely on existing implementations or RL traces, instead relying solely on Mistral's own models and infrastructure. - Magistral Medium, trained for reasoning on top of Mistral Medium 3 with RL alone, achieved a nearly 50% boost in AIME-24 (pass@1) over the initial Mistral Medium 3 checkpoint, demonstrating the effectiveness of the approach. - The model maintains or improves multimodal understanding, instruction following, and function calling. - Magistral Small (Apache 2.0) was open-sourced, further including cold-start data from Magistral Medium. | ['Reinforcement Learning', 'Multimodal', 'Question Answering'] | N/A | [Link](https://huggingface.co/mistralai/Magistral-Small-2506) |
| [Resa: Transparent Reasoning Models via SAEs](https://arxiv.org/abs/2506.09967) | Ömer Faruk Akgül, Julian Asilis, willieneis, deqing, upup-ashton-wang | This paper introduces Resa, a family of 1.5B reasoning language models trained via a novel Sparse Autoencoder Tuning (SAE-Tuning) procedure.  SAE-Tuning first trains a sparse autoencoder (SAE) to capture reasoning abilities from a source model and then uses the trained SAE to guide standard supervised fine-tuning to elicit these abilities in a target model. Resa models achieve comparable reasoning performance to reinforcement learning (RL)-trained counterparts while reducing training costs by over 2000x and training time by over 450x.  The extracted reasoning abilities demonstrate generalizability and modularity, meaning they transfer across different datasets and models without retraining.  The SAE-Tuning method offers increased transparency into the model's reasoning process. | ['Natural Language Processing', 'Question Answering', 'Feature Extraction'] | [Link](https://github.com/shangshang-wang/Resa) | [Link](https://huggingface.co/Resa-Yi) |
| [Ming-Omni: A Unified Multimodal Model for Perception and Generation](https://arxiv.org/abs/2506.09344) | Chunluan Zhou, Chuanyang Zheng, Cheng Zou, Biao Gong, Inclusion AI |  - Ming-Omni is a unified multimodal model that processes images, text, audio, and video, exhibiting strong performance in speech and image generation. - It uses a Mixture-of-Experts (MoE) architecture with modality-specific routers for efficient multimodal input processing and fusion. - The model supports audio and image generation via an advanced audio decoder and Ming-Lite-Uni, enabling versatile tasks like context-aware chatting and image editing. - Experimental results demonstrate Ming-Omni's superior performance in various tasks, matching GPT-4's modality support. - All code and model weights are open-sourced to encourage further research and development. | ['Multimodal'] | [Link](https://github.com/inclusionAI/Ming/tree/main) | N/A |
| [Eliciting Fine-Tuned Transformer Capabilities via Inference-Time
  Techniques](https://arxiv.org/abs/2506.08060) | codelion | - This paper presents a novel method for approximating the capabilities of fine-tuned transformer models using inference-time techniques, without altering the model parameters. - The approach leverages in-context learning (ICL), where the model is prompted with a subset of the fine-tuning dataset to elicit desired behaviors. - The authors provide theoretical proofs demonstrating that this approach can accurately approximate fine-tuned behavior under idealized conditions, with minimal data requirements. - These results are extended to more realistic scenarios with finite context lengths and partial dataset access, with dataset size bounds provided for text generation and linear classification tasks. - The study establishes a theoretical foundation for resource-efficient deployment of large language models, bridging the gap between theory and practice through practical techniques such as retrieval-augmented generation. | ['Natural Language Processing', 'Text Generation'] | N/A | N/A |
| [Compound AI Systems Optimization: A Survey of Methods, Challenges, and
  Future Directions](https://arxiv.org/abs/2506.08234) | Guan-Bo Yang, Jui-Chao Lu, Mei-Yi Liu, Guan-Ting Yi, Yu-Ang Lee | - This paper surveys recent advances in optimizing compound AI systems, which are systems integrating multiple components like LLMs, simulators, and code interpreters. - It proposes a 2x2 taxonomy of existing optimization methods based on structural flexibility and learning signals (numerical or language-based). - The paper identifies four key dimensions for analyzing compound AI system optimization methods: structural flexibility, learning signals, component options, and system representations. - It highlights open research challenges, such as manual hyperparameter configuration, excessive computation burden, and limited experimental scope. - The authors suggest future directions, including developing automated optimization algorithms, reducing computational overhead, expanding experimental scope, and providing more theoretical guarantees for existing methods. | ['Natural Language Processing'] | [Link](https://github.com/MiuLab/AISysOpt-Survey) | N/A |
| [LLM Unlearning Should Be Form-Independent](https://arxiv.org/abs/2506.07795) | Shu Wu, Mengqi Zhang, Acruxos | - This paper introduces Rank-One Concept Redirection (ROCR), a novel training-free method for LLM unlearning that addresses the issue of form-dependent bias. - ROCR modifies model parameters to redirect the activation of dangerous concepts to harmless ones, improving unlearning effectiveness and generalization. - The method is shown to significantly outperform existing unlearning methods in terms of both unlearning effectiveness and knowledge preservation across various downstream tasks. - Extensive experiments demonstrate ROCR's superior performance and its ability to generate highly natural outputs, showcasing its potential as a practical and robust solution for LLM unlearning. - A new benchmark, ORT, is introduced to systematically evaluate the robustness of unlearning methods against variations in knowledge expression, highlighting the prevalence of form-dependent bias. | ['Natural Language Processing'] | N/A | N/A |
| [What Makes a Good Natural Language Prompt?](https://arxiv.org/abs/2506.06950) | Nancy F. Chen, Kenji Kawaguchi, Ngoc-Hai Nguyen, Duy Dinh, Do Xuan Long | This paper introduces a novel property-and-human-centric framework for evaluating the quality of natural language prompts, identifying 21 key properties across six dimensions.  A meta-analysis of 150+ prompting-related papers reveals significant research gaps and imbalances across models and tasks.  Correlations among properties in high-quality prompts are analyzed to derive practical prompting recommendations.  Empirical exploration on reasoning tasks demonstrates that single-property enhancements often yield greater impact than multi-property enhancements, and instruction-tuning on property-enhanced prompts leads to superior reasoning models.  Finally, it introduces various open questions regarding model-specific impacts and task-specific versus universal properties. | ['Natural Language Processing'] | N/A | N/A |
| [Draft-based Approximate Inference for LLMs](https://arxiv.org/abs/2506.08373) | Hyung Il Koo, Minjae Lee, Wonjun Kang, Ethan Ewer, Kevin Galim |  - This paper introduces a novel framework for approximate inference in Large Language Models (LLMs) that leverages smaller "draft" models to predict token and key-value pair importance more accurately than existing methods. - Two instantiations of this framework are presented: SpecKV, for effective KV cache dropping, and SpecPC, for prompt compression, both showing strong correlations between the draft and target models. - SpecKV and SpecPC consistently outperform existing baselines on long-context benchmarks, achieving higher accuracy while maintaining improvements in memory usage, latency, and throughput. - Theoretical analyses support the methods' effectiveness, showing a strong correlation between the attention patterns of draft and target models. - The proposed methods are evaluated extensively on multiple benchmarks, demonstrating consistent improvements in accuracy over existing methods. | ['Natural Language Processing', 'Text Generation'] | [Link](https://github.com/furiosa-ai/draft-based-approx-llm) | N/A |
| [MCA-Bench: A Multimodal Benchmark for Evaluating CAPTCHA Robustness
  Against VLM-based Attacks](https://arxiv.org/abs/2506.05982) | Yiren Song, Xin Wei, Yule Xue, Zonglin Wu | - The paper introduces MCA-Bench, a comprehensive multimodal benchmark for evaluating CAPTCHA robustness against vision-language model (VLM)-based attacks. - MCA-Bench integrates various CAPTCHA types into a single evaluation protocol, leveraging a shared VLM backbone to fine-tune specialized cracking agents for each CAPTCHA category. - Extensive experiments demonstrate that MCA-Bench effectively maps the vulnerability spectrum of modern CAPTCHA designs and provides quantitative analysis of challenge complexity, interaction depth, and model solvability. - Based on the experimental findings, the paper proposes three actionable design principles for next-generation CAPTCHAs to enhance security against VLM-based attacks. - Datasets and code are publicly available for further research and community collaboration. | ['Multimodal'] | [Link](https://github.com/noheadwuzonglin/MCA-Bench) | [Link](https://www.kaggle.com/datasets/luffy798/mca-benchmultimodal-captchas) |
| [Discovering Hierarchical Latent Capabilities of Language Models via
  Causal Representation Learning](https://arxiv.org/abs/2506.10378) | Hanlin Zhang, Sham Kakade, Vasilis Syrgkanis, Jikai Jin |  - This paper introduces a novel causal representation learning framework for evaluating language model capabilities.  - The framework models observed benchmark performance as a linear transformation of latent capability factors, identified as causally interrelated after controlling for base model variations.  - Applying this approach to a large dataset of over 1500 models, the authors identify a three-node linear causal structure that reliably explains performance variations across six benchmarks from the Open LLM Leaderboard.  - The causal structure reveals a clear causal direction from general problem-solving capabilities through instruction-following proficiency to mathematical reasoning ability.  - This work underscores the importance of controlling for base model variations during evaluation to accurately uncover causal relationships between latent model capabilities. | ['Natural Language Processing'] | [Link](https://github.com/hlzhang109/causal-eval) | [Link](https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard#/) |
