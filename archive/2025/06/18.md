

## Papers for 2025-06-18

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [Scaling Test-time Compute for LLM Agents](https://arxiv.org/abs/2506.12928) | Dehua Ma, Tianshun Xing, Siwei Wu, Hanhao Li, King Zhu | - This paper introduces a novel method for scaling test-time compute for large language model (LLM) agents, improving their reasoning abilities. - The approach systematically explores various test-time scaling strategies, including parallel sampling, sequential revision, verification and merging, and rollout diversification. - Experimental results show significant performance improvements compared to baselines, demonstrating the effectiveness of test-time scaling for LLM agents. - Among the tested strategies, list-wise verification and merging methods and increasing diversified rollouts yield the best results. - The findings align with observations from previous test-time scaling research on LLMs, highlighting the potential for further advancements in this area. | ['Natural Language Processing'] | [Link](https://github.com/OPPO-PersonalAI/OAgents) | N/A |
| [LongLLaDA: Unlocking Long Context Capabilities in Diffusion LLMs](https://arxiv.org/abs/2506.14429) | Ziwei He, Qipeng Guo, Zengfeng Huang, Zhigeng Liu, Xiaoran Liu | - This paper introduces LongLLaDA, a training-free method for extending the context window of diffusion Large Language Models (LLMs). - LongLLaDA integrates LLaDA with NTK-based RoPE extrapolation to achieve this context extension, empirically validating the effectiveness of established extrapolation scaling laws for diffusion LLMs. - The study presents a systematic comparison of the long-context performance of diffusion LLMs and traditional autoregressive LLMs, identifying unique characteristics of diffusion LLMs such as stable perplexity during context extrapolation and a "local perception" phenomenon enabling successful retrieval from recent context segments. - LongLLaDA successfully extends context windows, showing that it maintains effective extrapolation up to a 6x extension in context length, without additional training. - The paper provides empirical benchmarks and theoretical insights into the long-context behavior of diffusion LLMs, crucial for future research in this area. | ['Natural Language Processing'] | N/A | N/A |
| [Stream-Omni: Simultaneous Multimodal Interactions with Large
  Language-Vision-Speech Model](https://arxiv.org/abs/2506.13642) | Yang Feng, Yan Zhou, Qingkai Fang, Shoutao Guo, Shaolei Zhang | - This paper introduces Stream-Omni, a novel large language-vision-speech model designed for simultaneous multimodal interactions. - The model architecture employs an LLM backbone, aligning vision and speech modalities to text through sequence-dimension concatenation and CTC-based layer-dimension mapping respectively. - Stream-Omni demonstrates strong performance on various benchmarks, including visual understanding, speech interaction, and vision-grounded speech interaction tasks, often outperforming existing methods. - It achieves these results using only 23,000 hours of speech data, highlighting its efficient modality alignment. - The model simultaneously generates intermediate text outputs during speech interaction, providing a comprehensive multimodal user experience. | ['Multimodal', 'Text-to-Speech', 'Automatic Speech Recognition', 'Visual Question Answering'] | [Link](https://github.com/ictnlp/Stream-Omni) | [Link](https://huggingface.co/ICTNLP/stream-omni-8b) |
| [Efficient Medical VIE via Reinforcement Learning](https://arxiv.org/abs/2506.13363) | Chong Li, Chenglin Zhu, Lijun Liu, zhaocheng, lryyyy | - This paper introduces a novel method for efficient medical visual information extraction (VIE) using reinforcement learning with verifiable rewards (RLVR). - The proposed RLVR framework addresses the challenges of domain-specific schemas and high annotation costs in medical VIE by using only 100 annotated samples. - The method incorporates a balanced precision-recall reward mechanism and innovative sampling strategies to enhance reasoning capabilities and reduce hallucinations. - The authors achieve state-of-the-art performance on medical VIE tasks by fine-tuning Qwen2.5-VL-7B with their RLVR method, significantly improving F1 score, precision, and recall. - Case studies demonstrate the effectiveness of reasoning during training and inference for VIE, highlighting the need for domain-specific optimization. | ['Reinforcement Learning', 'Image-to-Text', 'Multimodal'] | N/A | N/A |
| [Xolver: Multi-Agent Reasoning with Holistic Experience Learning Just
  Like an Olympiad Team](https://arxiv.org/abs/2506.14234) | Md Rizwan Parvez, Md Kishor Morol, Salman Rahman, Md Tanzib Hosain | This paper introduces Xolver, a training-free multi-agent reasoning framework that enhances large language models (LLMs) by incorporating a persistent memory of holistic experiences.  Xolver integrates diverse experience modalities, including external and self-retrieval, tool use, collaborative agent interactions, agent-driven evaluation, and iterative reasoning refinement.  Empirical results demonstrate that Xolver consistently outperforms specialized reasoning agents and achieves state-of-the-art results on several benchmarks, including GSM8K, AIME'24, and LiveCodeBench.  The authors attribute Xolver's success to its holistic experience learning approach, which allows it to leverage past experiences to inform future reasoning. Xolver is open-sourced. | ['Natural Language Processing'] | [Link](https://kagnlp.github.io/xolver.github.io/) | [Link](null) |
| [QFFT, Question-Free Fine-Tuning for Adaptive Reasoning](https://arxiv.org/abs/2506.12860) | Ke Ji, Yukang Lin, Fei Yu, Junxiao Xu, lwl-uestc | - This paper introduces Question-Free Fine-Tuning (QFFT), a novel fine-tuning approach that removes the input question during training to enable adaptive reasoning in language models. - QFFT learns exclusively from Long Chain-of-Thought (CoT) responses, allowing the model to adaptively switch between Short CoT and Long CoT patterns based on the complexity of the question. - Experiments on mathematical datasets demonstrate that QFFT reduces the average response length by over 50% while maintaining performance comparable to Supervised Fine-Tuning (SFT). - QFFT exhibits superior performance compared to SFT in noisy, out-of-domain, and low-resource scenarios. - The QFFT method is publicly available on GitHub. | ['Question Answering'] | [Link](https://github.com/LWL-cpu/Question-Free-Fine-Tuning) | N/A |
| [Can LLMs Generate High-Quality Test Cases for Algorithm Problems?
  TestCase-Eval: A Systematic Evaluation of Fault Coverage and Exposure](https://arxiv.org/abs/2506.12278) | Xue Xia, Zexi Kuang, Zheyuan Yang, yilunzhao | - This paper introduces TestCase-Eval, a new benchmark for evaluating LLMs' ability to generate high-quality test cases for algorithm problems. - The benchmark comprises 500 algorithm problems and 100,000 human-crafted solutions from the Codeforces platform, focusing on two tasks: Fault Coverage and Fault Exposure. - A comprehensive evaluation of 19 state-of-the-art LLMs on TestCase-Eval reveals that even top-performing models significantly underperform compared to human experts in the Fault Exposure task (43.8% vs. 93.3%). - The study provides valuable insights into LLMs' strengths and limitations in generating effective test cases, highlighting the challenges in achieving human-level performance. - The findings underscore the inherent difficulty of generating diverse, impactful test cases that can effectively expose subtle bugs in algorithm implementations. | ['Natural Language Processing', 'Text Generation'] | [Link](https://github.com/FlowRays/TestCase-Eval) | N/A |
| [CRITICTOOL: Evaluating Self-Critique Capabilities of Large Language
  Models in Tool-Calling Error Scenarios](https://arxiv.org/abs/2506.13977) | Junjie Ye, Siyu Yuan, Zehui Chen, Shiting Huang, CostaliyA | This paper introduces CRITICTOOL, a new benchmark designed to evaluate the self-critique capabilities of Large Language Models (LLMs) in tool-calling scenarios.  CRITICTOOL includes diverse error patterns and evaluates models from multiple perspectives, addressing limitations in existing benchmarks. The proposed evolutionary strategy for dataset construction improves the diversity and realism of the benchmark, better reflecting real-world scenarios.  Extensive experiments on CRITICTOOL reveal insights into LLMs' self-critique abilities and highlight performance differences across various models.  The code for the benchmark is publicly available. | ['Natural Language Processing'] | [Link](https://github.com/Shellorley0513/CriticTool) | N/A |
| [Taming Polysemanticity in LLMs: Provable Feature Recovery via Sparse
  Autoencoders](https://arxiv.org/abs/2506.14002) | Zhuoran Yang, Tianhao Wang, Xuyuan Xiong, Heejune Sheen, Siyu Chen |  - A novel statistical framework is proposed to address the feature recovery problem for Large Language Models (LLMs), which models polysemantic features as sparse mixtures of underlying monosemantic features.  - A new SAE training algorithm called Group Bias Adaptation (GBA) is introduced, which uses bias adaptation to directly control neuron activation sparsity.  - GBA achieves superior empirical performance on LLMs with up to 1.5 billion parameters compared to existing methods, achieving the sparsity-loss frontier.  - The proposed method provides the first provable recovery guarantee for SAE training algorithms.  - The theoretical findings are validated through experiments on synthetic and real-world data. | ['Feature Extraction', 'Natural Language Processing'] | N/A | N/A |
| [VideoMolmo: Spatio-Temporal Grounding Meets Pointing](https://arxiv.org/abs/2506.05336) | Zhiqiang Shen, Abdelrahman Shaker, Hanan Gani, Ghazi Shazan Ahmad, ahmedheakl | - This paper introduces VIDEOMOLMO, a large multimodal model for spatio-temporal grounding that improves upon existing methods by decomposing the task into two steps: precise point localization and sequential mask fusion. - The model architecture incorporates a temporal module using an attention mechanism for temporal consistency and a novel temporal mask fusion pipeline using SAM2 for bidirectional point propagation. - VIDEOMOLMO demonstrates improved spatio-temporal reasoning in visual grounding, producing more accurate and coherent segmentation masks compared to previous approaches, as shown in Figure 1. - The model was trained and evaluated on a new dataset curated by the authors, including a comprehensive dataset of 72k video-caption pairs annotated with 100k object points and a challenging out-of-distribution benchmark called VPoS-Bench. - Results on various benchmarks (VPoS-Bench, Refer-VOS, Reason-VOS) show that VIDEOMOLMO substantially improves spatio-temporal pointing accuracy and reasoning capability compared to existing methods. | ['Video-Text-to-Text', 'Multimodal', 'Mask Generation', 'Keypoint Detection'] | [Link](https://github.com/mbzuai-oryx/VideoMolmo) | N/A |
| [Treasure Hunt: Real-time Targeting of the Long Tail using Training-Time
  Markers](https://arxiv.org/abs/2506.14702) | Sara Hooker, Ahmet Üstün, Adrien Morisot, Julia Kreutzer, Daniel D'souza | This paper introduces a novel approach to improve the performance of large language models (LLMs) on low-frequency tasks.  The method involves introducing training-time markers that capture various data characteristics. These markers allow for flexible control over generation attributes and improved performance, especially on long-tail data. The authors demonstrate substantial improvements in win rates on open-ended generation tasks, achieving an average lift of 5.7% and gains exceeding 9.1% in underrepresented domains.  Their method shows effectiveness on various tasks such as code generation and length instruction following, with relative improvements up to 14.1%. The introduced framework is flexible and optional at inference time, since the markers can be inferred accurately. | ['Natural Language Processing'] | [Link](None) | [Link](None) |
| [Alignment Quality Index (AQI) : Beyond Refusals: AQI as an Intrinsic
  Alignment Diagnostic via Latent Geometry, Cluster Divergence, and Layer wise
  Pooled Representations](https://arxiv.org/abs/2506.13901) | Utkarsh Bhatt, Danush Khanna, Chhavi Sharma, Abhilekh Borah, amanchadha |  - The paper introduces a novel intrinsic metric called Alignment Quality Index (AQI) to diagnose large language model (LLM) alignment.   - AQI assesses alignment by analyzing the latent geometry of safe and unsafe activations, unlike existing methods that rely on behavioral proxies.  - The method leverages layerwise pooled representations and cluster quality indices such as Davies-Bouldin and Calinski-Harabasz to detect hidden misalignments and jailbreak risks, even when outputs appear compliant.  - The experimental evaluation on LITMUS dataset demonstrates that AQI correlates strongly with external human judgments and is robust to decoding variation and prompt paraphrasing.  - Unlike other metrics, AQI provides insights into latent model behaviour. | ['Natural Language Processing', 'Text Classification'] | N/A | N/A |
| [CAMS: A CityGPT-Powered Agentic Framework for Urban Human Mobility
  Simulation](https://arxiv.org/abs/2506.13599) | Yong Li, Jian Yuan, Yuwei Du, JJ-TMT | - This paper introduces CAMS, a novel agentic framework for simulating human mobility in urban environments using CityGPT, an urban-foundation large language model. - CAMS comprises three core modules: MobExtractor, GeoGenerator, and TrajEnhancer, which work synergistically to generate realistic and plausible trajectories. - The model integrates urban spatial knowledge into the reasoning process of LLMs, enabling more accurate and generalizable simulations of human mobility. - Experiments on real-world datasets demonstrate that CAMS outperforms existing methods in terms of generating more realistic trajectories while not relying on external geospatial information. - CAMS establishes a new paradigm that integrates agentic frameworks with urban-knowledgeable LLMs for human mobility simulation. | ['Natural Language Processing'] | N/A | N/A |
| [TR2M: Transferring Monocular Relative Depth to Metric Depth with
  Language Descriptions and Scale-Oriented Contrast](https://arxiv.org/abs/2506.13387) | Hongliang Ren, Long Bai, Yiming Huang, Beilei Cui | - This paper introduces TR2M, a novel framework that transfers monocular relative depth to metric depth using image and text descriptions. - The model architecture consists of separate frozen image and text encoders, a cross-modality attention module, and two lightweight decoder heads to predict scale and shift maps for pixel-wise rescaling. - A scale-oriented contrastive learning strategy is used to enforce feature consistency based on depth distribution, improving scale perception. - TR2M outperforms other language-based methods on several datasets and exhibits superior zero-shot capabilities on unseen datasets. - The authors demonstrate the potential of pixel-wise relative-to-metric depth transfer with language assistance. | ['Depth Estimation', 'Multimodal'] | [Link](https://github.com/BeileiCui/TR2M) | N/A |
| [Universal Jailbreak Suffixes Are Strong Attention Hijackers](https://arxiv.org/abs/2506.12880) | Mahmood Sharif, Mor Geva, MatanBT | - This paper introduces a novel technique to enhance and mitigate suffix-based jailbreaks against large language models (LLMs). - The core contribution is the identification of a shallow, critical mechanism in GCG attacks, focusing on information flow from the adversarial suffix to the chat template tokens. - The authors quantify the dominance of the adversarial suffix in the contextualization process and link this to the universality of the attacks. - Practical implications are demonstrated by enhancing GCG universality (up to 5x in some cases) and surgically mitigating attacks (at least halving attack success). - Code and data are released for reproducibility. | ['Natural Language Processing', 'Text Generation'] | [Link](http://github.com/matanbt/interp-jailbreak) | N/A |
