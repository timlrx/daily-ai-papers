

## Papers for 2025-06-19

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [GenRecal: Generation after Recalibration from Large to Small
  Vision-Language Models](https://arxiv.org/abs/2506.15681) | Yueh-Hua Wu, Yu-Chiang Frank Wang, Yong Man Ro, rhachiuma, BK-Lee | This paper introduces GenRecal, a novel general-purpose distillation framework for Vision-Language Models (VLMs).  GenRecal incorporates a recalibrator module that aligns feature representations between heterogeneous VLMs, enabling effective knowledge transfer regardless of token type differences.  Extensive experiments demonstrate that GenRecal significantly improves baseline performance, surpassing both large-scale open- and closed-source VLMs.  The recalibrator effectively bridges the gap between large and small VLMs, making knowledge transfer possible even with diverse architectures. GenRecal is shown to work for various model sizes and across many challenging benchmarks. | ['Multimodal'] | N/A | N/A |
| [ProtoReasoning: Prototypes as the Foundation for Generalizable Reasoning
  in LLMs](https://arxiv.org/abs/2506.15211) | Yunqi Qiu, Tingting Ma, Xinnian Liang, Zijun Chen, Feng He | - This paper introduces ProtoReasoning, a novel framework that enhances the reasoning capabilities of Large Language Models (LLMs) by leveraging scalable and verifiable prototypical representations. - The framework uses Prolog and PDDL as core representations for logical reasoning and planning, respectively, to transform problems into corresponding prototype representations. - ProtoReasoning features an automated pipeline for prototype construction and a comprehensive verification system using Prolog/PDDL interpreters, ensuring correctness and scalability. - Experiments demonstrate that ProtoReasoning achieves significant improvements (4.7% on Enigmata-Eval, 6.3% on planning, and 4.0% on general reasoning) over baseline models, showcasing enhanced generalization. - Ablation studies confirm that learning in prototype space improves generalization compared to training solely on natural language representations, supporting the hypothesis that reasoning prototypes are crucial for generalizable reasoning in LLMs. | ['Natural Language Processing'] | N/A | N/A |
| [Embodied Web Agents: Bridging Physical-Digital Realms for Integrated
  Agent Intelligence](https://arxiv.org/abs/2506.15677) | Maxine Wu, Xingcheng Yao, Bingxuan Li, Rui Sun, Yining Hong | This paper introduces EMBODIED WEB AGENTS, a novel paradigm for AI agents that integrates web-scale reasoning with physical embodiment.  A new benchmark is presented with diverse tasks requiring coordinated reasoning across physical and digital domains (cooking, navigation, shopping, tourism, geolocation).  State-of-the-art LLMs are evaluated on this benchmark, revealing significant performance gaps compared to human capabilities.  The platform incorporates realistic 3D indoor and outdoor environments with functional web interfaces.  The results highlight challenges and opportunities in cross-domain intelligence. | ['Multimodal', 'Reinforcement Learning', 'Robotics'] | [Link](https://embodied-web-agent.github.io/) | N/A |
| [Semantically-Aware Rewards for Open-Ended R1 Training in Free-Form
  Generation](https://arxiv.org/abs/2506.15068) | Zichao Liang, Xiyang Wu, Yuhang Zhou, Yapei Chang, Zongxia Li | - This paper introduces PrefBERT, a lightweight scoring model for evaluating open-ended long-form text generation. - PrefBERT is trained on two response evaluation datasets with diverse long-form styles and Likert-rated quality and uses ModernBERT architecture. -  The model offers better semantic reward feedback for guiding the training of RL models than traditional metrics such as ROUGE-L and BERTScore. - Experiments using LLM-as-a-judge, human ratings, and qualitative analysis demonstrate that PrefBERT consistently aligns with human preferences. -  Training policy models with PrefBERT yields responses better aligned with human preferences than those trained with traditional metrics. | ['Reinforcement Learning', 'Text Generation'] | [Link](https://github.com/zli12321/long_form_rl) | N/A |
| [SciVer: Evaluating Foundation Models for Multimodal Scientific Claim
  Verification](https://arxiv.org/abs/2506.15569) | Arman Cohan, Zexi Kuang, Yifei Shen, Chengye Wang, yilunzhao | - We introduce SCIVER, the first benchmark for evaluating multimodal scientific claim verification. - SCIVER consists of 3,000 expert-annotated examples across 1,113 scientific papers, covering four reasoning types. - We evaluate 21 state-of-the-art multimodal foundation models, revealing a substantial performance gap between models and human experts. - Through in-depth analysis of RAG and human-conducted error evaluations, we identify critical model limitations. - Our findings offer key insights for advancing models' comprehension and reasoning in multimodal scientific literature. | ['Multimodal', 'Question Answering'] | [Link](https://github.com/chengyewang/SciVer) | [Link](https://huggingface.co/QDRhhhh/SciVer) |
| [CoMemo: LVLMs Need Image Context with Image Memory](https://arxiv.org/abs/2506.06279) | Jifeng Dai, Wenhai Wang, Xizhou Zhu, jackroos, CLLBJ16 | - CoMemo, a novel dual-path framework for Large Vision-Language Models (LVLMs), is proposed to address the limitations of existing architectures in handling dynamic high-resolution images and long sequences. - The model employs a context path for autoregressive processing and a memory path for cross-attention, effectively alleviating visual information neglect. - A novel positional encoding mechanism, ROPE-DHR, is introduced to maintain 2D spatial awareness while mitigating remote decay issues. - Evaluations across seven benchmarks demonstrate CoMemo's superior performance compared to conventional LVLM architectures, especially in long-context comprehension and multi-image reasoning tasks. - The three-stage training strategy effectively balances the contributions of the two visual pathways, preventing over-reliance on either path. | ['Multimodal'] | [Link](https://lalbj.github.io/projects/CoMemo/) | N/A |
| [SwarmAgentic: Towards Fully Automated Agentic System Generation via
  Swarm Intelligence](https://arxiv.org/abs/2506.15672) | Shijie Zhou, Haokun Chen, Shijie Tang, Chenyang Lin, Yao Zhang |  - SwarmAgentic is a novel framework that generates fully automated agentic systems from scratch, optimizing both agent functionality and collaboration through language-driven exploration. - It uses a population-based optimization scheme inspired by Particle Swarm Optimization (PSO) to efficiently search over system-level structures. - The framework outperforms all baselines on six real-world tasks involving high-level planning, system-level coordination, and creative reasoning, achieving a +261.8% improvement over ADAS on the TravelPlanner benchmark. - SwarmAgentic introduces three core capabilities: From-Scratch Agent Generation, Self-Optimizing Agent Functionality, and Self-Optimizing Agent Collaboration. - The code for SwarmAgentic is publicly available on GitHub. | ['Natural Language Processing', 'Text Generation', 'Reinforcement Learning'] | [Link](https://github.com/SwarmAgentic) | N/A |
| [MoTE: Mixture of Ternary Experts for Memory-efficient Large Multimodal
  Models](https://arxiv.org/abs/2506.14435) | Yitao Zhai, Yan Feng, Ruiping Wang, Jiayu Xu, Hongyu Wang | - This paper introduces MoTE, a novel Mixture-of-Ternary-Experts (MoTE) model for memory-efficient large multimodal models. - The MoTE architecture uses a pre-trained full-precision feed-forward network (FFN) as a shared expert and trains ternary routed experts with parameters in {-1, 0, 1} during up-cycling. - Experiments demonstrate that MoTE achieves comparable performance to full-precision baseline MoE-LLaVA while offering a lower memory footprint. - MoTE's performance further improves when combined with post-training quantization methods, outperforming MoE-LLaVA by 4.3% average accuracy on end tasks with the same expert memory footprint. - The results highlight MoTE's effectiveness and potential for memory-constrained devices. | ['Multimodal'] | N/A | N/A |
| [OS-Harm: A Benchmark for Measuring Safety of Computer Use Agents](https://arxiv.org/abs/2506.14866) | Zico Kolter, Francesco Croce, Hao Zhao, Agatha Duzan, Thomas Kuntz | - This paper introduces OS-HARM, a new benchmark for evaluating the safety of computer use agents. - OS-HARM tests agents across three categories of harm: deliberate user misuse, prompt injection attacks, and model misbehavior. - The benchmark includes 150 tasks that require agents to interact with various OS applications. - An automated LLM judge is proposed to evaluate both accuracy and safety, achieving high agreement with human annotations. - The results show that current frontier models tend to directly comply with many deliberate misuse queries and are vulnerable to prompt injection attacks. | ['Multimodal', 'Any-to-Any'] | [Link](https://github.com/tml-epfl/os-harm) | N/A |
