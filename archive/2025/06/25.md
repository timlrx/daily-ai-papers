

## Papers for 2025-06-25

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [AnimaX: Animating the Inanimate in 3D with Joint Video-Pose Diffusion
  Models](https://arxiv.org/abs/2506.19851) | lsheng2024, pookiefoof, Yang-Tian, fenghora, huanngzh | - AnimaX is a novel feed-forward 3D animation framework that leverages video diffusion models and skeleton-based animation for generating high-quality animations from articulated 3D meshes and textual descriptions. - The model architecture employs a joint video-pose diffusion model, which processes multi-view 2D pose maps and video frames simultaneously to effectively transfer motion knowledge from the video domain to the 3D animation domain. - It introduces shared positional encodings and modality-aware embeddings to ensure spatial-temporal alignment between the video and pose streams. - AnimaX achieves state-of-the-art results on VBench, outperforming existing methods in generalization, motion fidelity, and efficiency, as evidenced by quantitative comparisons and user studies. - The framework supports diverse articulated meshes with arbitrary skeletons, demonstrating significant improvements in generating high-quality animations compared to prior work that primarily focuses on fixed skeletal topologies or relies on costly optimization. | ['Text-to-3D', 'Image-to-3D', 'Video-Text-to-Text', 'Multimodal'] | [Link](https://anima-x.github.io/) | N/A |
| [GRPO-CARE: Consistency-Aware Reinforcement Learning for Multimodal
  Reasoning](https://arxiv.org/abs/2506.16141) | Junhao Cheng, Yixiao Ge, Rui Wang, Yuying Ge, Yi Chen | - This paper introduces GRPO-CARE, a novel consistency-aware reinforcement learning framework that enhances the reasoning capabilities of multimodal large language models (MLLMs). - GRPO-CARE addresses the limitation of standard outcome-supervised methods by jointly optimizing for both answer correctness and reasoning coherence, improving interpretability and generalization. - The proposed method introduces a two-tiered reward mechanism: a base reward for accuracy and a consistency bonus based on the likelihood that a reference model reproduces the same answer given the reasoning trace. - Experiments on SEED-Bench-R1, a new benchmark specifically designed to evaluate post-training methods for MLLMs, demonstrate that GRPO-CARE consistently outperforms standard GRPO, achieving a 6.7% performance gain on the most challenging evaluation level and a 24.5% improvement in consistency rates. - The effectiveness of GRPO-CARE is further validated by its strong transferability across diverse video understanding benchmarks. | ['Video-Text-to-Text', 'Reinforcement Learning', 'Multimodal'] | [Link](https://github.com/TencentARC/GRPO-CARE) | N/A |
| [Skywork-SWE: Unveiling Data Scaling Laws for Software Engineering in
  LLMs](https://arxiv.org/abs/2506.19290) | Changshi Li, Yuzhen Xiao, chrisliu298, lycfight, zengliangcs | - This paper introduces Skywork-SWE, a new dataset for software engineering tasks containing 10,169 real-world Python instances from 2,531 distinct GitHub repositories. - The dataset includes natural language descriptions, code, and validated unit tests, addressing limitations of existing datasets. - They fine-tune a 32B parameter LLM, achieving state-of-the-art performance on the SWE-bench Verified benchmark (38% pass@1 accuracy without verifiers). - The authors empirically demonstrate a data scaling law for software engineering in LLMs, showing consistent performance improvements with increased training data size. - They release their model checkpoint and dataset to facilitate future research. | ['Natural Language Processing', 'Text2Text Generation', 'Reinforcement Learning'] | [Link](https://github.com/SkyworkAI/Skywork-SWE) | [Link](https://huggingface.co/Skywork/Skywork-SWE-32B) |
| [SWE-SQL: Illuminating LLM Pathways to Solve User SQL Issues in
  Real-World Applications](https://arxiv.org/abs/2506.18951) | Per Jacobsson, Ge Qu, Jinyang Li, Tebmer, xia01ongLi | - This paper introduces BIRD-CRITIC, a new benchmark for SQL issue debugging, comprising 530 PostgreSQL tasks and 570 multi-dialect tasks distilled from real user issues. - It presents SIX-GYM, a training environment leveraging the SQL-Rewind strategy to automatically generate executable issue-solution datasets. - The paper proposes f-Plan Boosting, a method to extract high-level debugging plans from SQL solutions to improve training. - BIRD-FIXER, an open-source agent based on Qwen-2.5-Coder-14B, achieves a success rate of 38.11% on BIRD-CRITIC-PG and 29.65% on BIRD-CRITIC-MULTI, surpassing many leading proprietary models. - The results demonstrate the potential of open-source models for SQL issue debugging and highlight the challenges of the task. | ['Natural Language Processing'] | [Link](https://bird-critic.github.io/) | N/A |
| [JarvisArt: Liberating Human Artistic Creativity via an Intelligent Photo
  Retouching Agent](https://arxiv.org/abs/2506.17612) | Panwang Pan, Jinbin Bai, Kunjie Lin, Zixu Lin, LYL1015 |  - This paper introduces JarvisArt, a novel intelligent photo retouching agent that leverages a multi-modal large language model (MLLM) to understand user intent and coordinate over 200 retouching tools within Adobe Lightroom. - JarvisArt undergoes a two-stage training process: Chain-of-Thought supervised fine-tuning and Group Relative Policy Optimization for Retouching (GRPO-R). - The proposed Agent-to-Lightroom Protocol facilitates seamless integration between JarvisArt and Lightroom. - Experiments on the MMArt-Bench, a novel benchmark, show that JarvisArt outperforms GPT-4 by 60% on average pixel-level metrics while maintaining comparable instruction-following capabilities. - User preference studies demonstrate that JarvisArt achieves superior performance in ease of use, consistency, efficiency, and overall satisfaction compared to existing methods. | ['Image-to-Image', 'Multimodal', 'Reinforcement Learning'] | N/A | N/A |
| [Lost in the Mix: Evaluating LLM Understanding of Code-Switched Text](https://arxiv.org/abs/2506.14012) | Michalis Vazirgiannis, Yang Zhang, guokan-shang, amr-mohamed | - This paper introduces a novel evaluation framework for assessing the comprehension capabilities of large language models (LLMs) when processing code-switched (CSW) text. - The framework uses a multi-step pipeline to generate linguistically grounded CSW variants of established benchmarks. - Experiments reveal that code-switching has a nuanced effect on LLM comprehension, with degradation evident when foreign tokens disrupt English text. - Fine-tuning LLMs on code-switched data provides a more stable path to mitigating comprehension degradation compared to prompt-based methods. - The findings highlight the importance of developing more robust and adaptable LLMs to effectively process the increasingly prevalent mixed-language data found online. | ['Natural Language Processing'] | [Link](https://github.com/amr-mohamedd/Lost-in-the-Mix.git) | N/A |
| [Can Large Language Models Capture Human Annotator Disagreements?](https://arxiv.org/abs/2506.19467) | Alexander Hoyle, Donya Rooein, Vil√©m Zouhar, Yu Fan, JingweiNi | This research paper's main contribution is a comprehensive evaluation of LLMs' capacity to predict human annotator disagreements without access to repeated human labels.  The findings reveal that LLMs struggle with this task, a limitation often overlooked by majority label-based evaluations.  Interestingly, RLVR-style reasoning, which generally improves LLM performance, degrades its performance in disagreement prediction.  The authors highlight the need for improved methods for evaluating and enhancing LLMs' capabilities in this area.  The study uses various datasets and LLM architectures, examining both verbalized and sampling-based distribution expression methods. | ['Natural Language Processing', 'Text Classification'] | [Link](https://github.com/EdisonNi-hku/Disagreement_Prediction) | N/A |
