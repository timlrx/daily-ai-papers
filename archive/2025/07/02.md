

## Papers for 2025-07-02

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable
  Reinforcement Learning](https://arxiv.org/abs/2507.01006) | tanghme0www, bigganbing, xgeric, iyuge2, wenyi | The paper introduces GLM-4.1V-Thinking, a vision-language model (VLM) designed for versatile multimodal reasoning.  The model architecture consists of a ViT encoder, an MLP projector, and a large language model decoder.  It utilizes Reinforcement Learning with Curriculum Sampling (RLCS) for training, achieving state-of-the-art results on 28 public benchmarks, outperforming even significantly larger models in many tasks. The model and training code are open-sourced to facilitate further research.  The authors also highlight various strategies employed for efficiency and stability during training. | ['Multimodal'] | [Link](https://github.com/THUDM/GLM-4.1V-Thinking) | N/A |
| [MoCa: Modality-aware Continual Pre-training Makes Better Bidirectional
  Multimodal Embeddings](https://arxiv.org/abs/2506.23115) | Nan Yang, Liang Wang, roosephu, hongliu9903, Haon-Chen | - This paper introduces MoCa, a two-stage framework designed to enhance bidirectional multimodal embeddings by leveraging pre-trained Vision Language Models (VLMs). - The first stage, Modality-aware Continual Pre-training, introduces a joint reconstruction objective that simultaneously denoises interleaved text and image inputs, improving bidirectional context-aware reasoning. - The second stage, Heterogeneous Contrastive Fine-tuning, utilizes diverse multimodal data (beyond image-caption pairs) to improve generalization and alignment. - Experiments on MMEB and ViDoRe-v2 benchmarks demonstrate that MoCa consistently outperforms existing state-of-the-art methods, achieving new state-of-the-art results on MMEB. - MoCa exhibits strong scalability with both model size and training data, showcasing its effectiveness in various downstream applications. | ['Multimodal'] | [Link](https://haon-chen.github.io/MoCa/) | N/A |
| [SciArena: An Open Evaluation Platform for Foundation Models in
  Scientific Literature Tasks](https://arxiv.org/abs/2507.01001) | Ronan Le Bras, Sihong Wu, HughieHu, maxzky, yilunzhao | SciArena is an open-source platform designed to evaluate foundation models' performance on tasks related to scientific literature.  It uses a community voting system to compare models, allowing for open-ended questions and long-form responses.  The platform currently supports 23 models and has collected over 13,000 votes.  SciArena also provides a meta-evaluation benchmark, SciArena-Eval, to assess the accuracy of automated evaluation systems.  The results show that even the best-performing model achieves only 65.1% accuracy compared with human preference. | ['Question Answering'] | [Link](https://github.com/yale-nlp/SciArena) | [Link](https://huggingface.co/datasets/yale-nlp/SciArena) |
| [Does Math Reasoning Improve General LLM Capabilities? Understanding
  Transferability of LLM Reasoning](https://arxiv.org/abs/2507.00432) | Seungone Kim, Xiaoyu Xu, Yuetai Li, Maggie Huan, aaabiao |  - This paper introduces a novel metric, the Transferability Index, to evaluate the generalization capabilities of large language models (LLMs) trained on mathematical reasoning tasks. - The study reveals that reinforcement learning (RL)-tuned models generalize better across various reasoning and non-reasoning tasks than supervised fine-tuning (SFT)-tuned models. - Latent-space representation and token-space distribution shift analyses are employed to show that SFT induces significant representation and output drift, whereas RL preserves the general-domain structure. - Controlled experiments on Qwen3-14B models using math-only data and different tuning methods confirm that RL-tuned models generalize well across domains, while SFT-tuned models often forget general capabilities. - The findings suggest a need to rethink standard post-training recipes, particularly the reliance on SFT-distilled data for advancing reasoning models. | ['Natural Language Processing'] | [Link](https://github.com/ReasoningTransfer/Transferability-of-LLM-Reasoning) | [Link](huggingface.co/ReasoningTransferability) |
| [DiffuCoder: Understanding and Improving Masked Diffusion Models for Code
  Generation](https://arxiv.org/abs/2506.20639) | Navdeep Jaitly, Jiatao Gu, Huangjie Zheng, Ruixiang Zhang, Shansan Gong | This paper introduces DiffuCoder, a 7B parameter diffusion language model (LLM) specifically designed for code generation.  The model architecture is based on masked diffusion models and is trained on a large-scale corpus of 130B code tokens.  The authors investigate the decoding behavior of DiffuCoders, revealing differences from autoregressive (AR) models, such as the ability to control the causality of generation. A novel RL training framework, coupled-GRPO, significantly improves DiffuCoder's performance, surpassing existing methods by +4.4% on EvalPlus benchmarks and demonstrating the effectiveness of RL aligned with diffusion principles.  Further experiments showcase the impact of temperature on the model's autoregressive nature, with higher temperatures leading to increased generation diversity. | ['Text Generation'] | [Link](https://github.com/apple/ml-diffucoder) | N/A |
| [HumanOmniV2: From Understanding to Omni-Modal Reasoning with Context](https://arxiv.org/abs/2506.21277) | Weixuan Chen, Shimin Yao, BBBBCHAN, fushh7, PhilipC | - HumanOmniV2 is a novel multimodal large language model designed to enhance omni-modal reasoning capabilities by focusing on global context understanding and preventing shortcut problems. - The model incorporates context, format, accuracy, and logical rewards, using an LLM to assess context and logical reasoning, ensuring a thorough understanding of multimodal information. - A new reasoning training dataset is introduced, incorporating context information across various tasks (images, videos, and audio), and a new benchmark, IntentBench, evaluates models' ability to understand complex human intentions. - HumanOmniV2 outperforms existing open-source omni-modal models across multiple benchmarks, demonstrating superior performance in understanding complex human intentions and emotions. | ['Multimodal', 'Video-Text-to-Text', 'Visual Question Answering', 'Reinforcement Learning'] | [Link](https://github.com/HumanMLLM/HumanOmniV2) | N/A |
| [Thinking Beyond Tokens: From Brain-Inspired Intelligence to Cognitive
  Foundations for Artificial General Intelligence and its Societal Impact](https://arxiv.org/abs/2507.00951) | Abbas Shah, Ranjan Sapkota, Rizwan Qureshi, amanchadha, shainaraza | This paper reviews the current state of artificial general intelligence (AGI) research, emphasizing the limitations of token-level prediction models and highlighting the need for architectures grounded in cognitive neuroscience and embodied understanding.  It proposes a unified framework that integrates insights from artificial intelligence, cognitive neuroscience, and psychology, with a focus on agentic reasoning and modular architectures.  The paper discusses emergent AGI-enabling methods and challenges, including generalization strategies and alignment issues. Finally, it advocates for systems that are not only intelligent but also transparent, value-aligned, and socially grounded.  | ['Multimodal'] | N/A | N/A |
| [Data Efficacy for Language Model Training](https://arxiv.org/abs/2506.21545) | Chong Li, Wenshan Wu, Xin Zhang, Yangyu Huang, Yalun Dai | - This paper introduces a novel paradigm called DELT for improving the data efficacy of language model training by optimizing the organization of training data, rather than just focusing on data efficiency. - DELT consists of three components: Data Scoring, Data Selection, and Data Ordering, which are used to assign scores, select subsets, and organize the training data, respectively. - The paper proposes a new Data Scoring method called Learnability-Quality Scoring (LQS) and a new Data Ordering method called Folding Ordering (FO), which are shown to enhance LM performance. - Experiments demonstrate that DELT instances enhance Language Model performance without increasing the data scale and model size, and that the combination of LQS and FO achieves the most significant improvement. - The authors conclude that data efficacy is a promising foundational area in LM training and complements data efficiency. | ['Natural Language Processing'] | N/A | N/A |
