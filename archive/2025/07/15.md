

## Papers for 2025-07-15

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [SpeakerVid-5M: A Large-Scale High-Quality Dataset for Audio-Visual
  Dyadic Interactive Human Generation](https://arxiv.org/abs/2507.09862) | Deyu Zhou, Jiahe Zhang, Duomin Wang, Zhaoyang Li, Youliang Zhang | - SpeakerVid-5M, a large-scale, high-quality dataset for audio-visual dyadic interactive human generation, is introduced.  The dataset contains over 8,743 hours of data and 5.2 million video clips, offering rich annotations such as structured text, skeletal sequences, and blur scores. - The dataset is structured along two key dimensions: interaction type (dialogue, single, listening, multi-turn) and data quality (pre-training and SFT subsets). - An autoregressive method for audio-visual dyadic human generation is proposed, using Qwen2.5-Omni for multimodal understanding and a next-chunk prediction model for joint audio and video generation. - The proposed method achieves state-of-the-art performance on the VidChatBench benchmark, showcasing improvements across metrics such as FID, FVD, PSNR, SSIM, and ArcFace. - The dataset and code are publicly released to facilitate research in audio-visual dyadic interactive human generation. | ['Multimodal', 'Video-Text-to-Text', 'Text-to-Video', 'Image-to-Video', 'Audio'] | [Link](https://dorniwang.github.io/SpeakerVid-5M/) | N/A |
| [EmbRACE-3K: Embodied Reasoning and Action in Complex Environments](https://arxiv.org/abs/2507.10548) | Kui Wu, Chengjie Jiang, Yitang Li, Wei Huang, Mingxian Lin | - EmbRACE-3K, a novel dataset of over 3,000 language-guided embodied tasks in diverse photorealistic environments, is introduced to address limitations of existing vision-language models (VLMs) in embodied settings. - The dataset contains approximately 26,000 decision steps, each annotated with multimodal context and step-wise reasoning, enabling fine-grained evaluation of embodied reasoning capabilities. - Experiments with state-of-the-art VLMs such as GPT-40, Gemini 2.5 Pro, and Qwen2.5-VL-7B reveal significant performance limitations in zero-shot settings, underscoring the challenges posed by embodied tasks. - Fine-tuning Qwen2.5-VL-7B using a two-stage approach (supervised fine-tuning followed by reinforcement learning) on EmbRACE-3K yields substantial improvements across three key dimensions: exploration, dynamic spatial-semantic reasoning, and multi-stage goal execution. - The results demonstrate the effectiveness of EmbRACE-3K in facilitating the development of embodied reasoning capabilities in VLMs. | ['Robotics', 'Reinforcement Learning', 'Multimodal'] | [Link](https://mxllc.github.io/EmbRACE-3K/) | N/A |
| [REST: Stress Testing Large Reasoning Models by Asking Multiple Problems
  at Once](https://arxiv.org/abs/2507.10541) | Zinan Tang, Qiyao Sun, Yu Li, Qizhi Pei, Zhuoshi Pan | - This paper introduces REST, a novel evaluation framework designed to rigorously assess the reasoning capabilities of Large Language Models (LLMs) by presenting them with multiple reasoning problems simultaneously. - REST significantly enhances the discriminative power of existing benchmarks, revealing weaknesses in LLMs that are not apparent in traditional single-question evaluations. - The experimental results demonstrate that under REST stress testing, the performance of various LLMs, even state-of-the-art models, degrades substantially. - A detailed error analysis pinpoints common issues such as question omission and reasoning errors which can inform the future development of more robust and capable LLMs. - The study identifies key factors affecting LLM performance under stress, including overthinking, output length limitations, and question ordering bias. | ['Question Answering'] | N/A | N/A |
| [Mixture-of-Recursions: Learning Dynamic Recursive Depths for Adaptive
  Token-Level Computation](https://arxiv.org/abs/2507.10524) | Jiyoun Ha, Sungnyun Kim, Reza Bayat, Yujin Kim, Sangmin Bae | - Mixture-of-Recursions (MoR) is a novel Transformer architecture that uses dynamic recursive depths for adaptive token-level computation, achieving unified parameter efficiency and memory efficiency. - MoR introduces two key mechanisms: expert-choice routing and recursive key-value caching, which dynamically adjust the recursion depth and manage memory usage efficiently. - Experimental results demonstrate that MoR significantly improves upon existing Transformer models, achieving better performance with lower computational and memory costs. - Ablation studies confirm the importance of both expert-choice routing and recursive key-value caching, showing their substantial contributions to MoR's performance. - The paper provides comprehensive analysis of MoR's adaptive computation capabilities, showing its scalability and robustness across various model sizes and sequence lengths. | ['Natural Language Processing'] | [Link](https://github.com/raymin0223/mixture_of_recursions) | [Link](string) |
| [LayerCake: Token-Aware Contrastive Decoding within Large Language Model
  Layers](https://arxiv.org/abs/2507.04404) | Yanqiang Zheng, Jiawang Cao, Wenbo Zhu, Yongliang Wu, Jingze Zhu | - This paper introduces LayerCake, a novel decoding-time method that improves the factuality of large language models (LLMs) without requiring additional training or model modifications. - LayerCake leverages both layer-wise dynamics and token-specific information to guide decoding, addressing the limitations of existing methods that treat these signals in isolation. - The method involves suppressing attention to specific token types at their most influential layers to induce controlled factual degradation and derive contrastive signals to guide final factual decoding. - Experiments demonstrate that LayerCake consistently improves factuality across multiple LLMs and various benchmarks, outperforming existing state-of-the-art contrastive decoding methods. - The code for LayerCake is available on GitHub. | ['Question Answering'] | [Link](https://github.com/Styxiian/LayerCake) | N/A |
| [CompassJudger-2: Towards Generalist Judge Model via Verifiable Rewards](https://arxiv.org/abs/2507.09104) | Kai Chen, Songyang Zhang, Alexander Lam, Maosong Cao, Taolin Zhang | - CompassJudger-2 is a novel generalist judge model that uses a task-driven, multi-domain data curation strategy and verifiable rewards to improve the robustness and generalization of LLM judgment. - The model employs rejection sampling to select high-quality training examples and uses a margin policy gradient loss to enhance performance. - CompassJudger-2 achieves superior results across multiple judge and reward benchmarks, outperforming larger models like DeepSeek-V3 and Qwen3-235B-A22B. - The paper introduces JudgerBenchV2, a comprehensive benchmark that evaluates cross-domain judgment accuracy and rank consistency. - Overall, CompassJudger-2 advances robust, scalable LLM judgment and sets new performance and evaluation standards. | ['Natural Language Processing'] | [Link](https://github.com/open-compass/CompassJudger) | N/A |
| [From KMMLU-Redux to KMMLU-Pro: A Professional Korean Benchmark Suite for
  LLM Evaluation](https://arxiv.org/abs/2507.08924) | Yeonjung Hong, Soyeon Kim, Guijin Son, Sunkyoung Kim, Seokhee Hong | - This paper introduces KMMLU-Redux and KMMLU-Pro, two benchmarks designed to evaluate large language models (LLMs) on Korean professional knowledge.- KMMLU-Redux is a revised version of the KMMLU benchmark, with improved data quality and a focus on eliminating challenging problems.- KMMLU-Pro expands on KMMLU-Redux by incorporating questions from actual Korean professional license exams, making it a more rigorous and realistic evaluation.- The authors conduct experiments on various LLMs and show that their performance varies widely across the two benchmarks, highlighting the importance of evaluating models' real-world professional capabilities.- The results demonstrate the need for further research and development of LLMs tailored to the specific requirements of the Korean professional domain. | ['Question Answering'] | N/A | N/A |
| [DreamPoster: A Unified Framework for Image-Conditioned Generative Poster
  Design](https://arxiv.org/abs/2507.04218) | Dexiang Hong, Hui Zhang, Zhongqi Qi, Haokun Chen, Xiwei Hu | - DreamPoster is a novel framework that generates high-quality posters from user-provided images and text prompts, addressing the limitations of existing methods by integrating multimodal information and supporting flexible resolution and layout. - The model is built upon a transformer-based diffusion architecture that processes text and image inputs jointly using positional embeddings, allowing for better alignment of textual and visual information in the generated posters. - DreamPoster employs a three-stage progressive training strategy, starting with single-task pretraining, progressing to multi-task mixed training, and finally fine-tuning for aesthetic alignment, enabling more sophisticated poster generation. - Quantitative evaluations demonstrate DreamPoster's superiority over existing methods, achieving a high usability rate of 88.55%, compared to GPT-40 (47.56%) and SeedEdit3.0 (25.96%), signifying its effectiveness in generating aesthetically pleasing and relevant posters. - The results suggest that DreamPosterâ€™s progressive training strategy successfully improves poster design quality across several tasks and addresses several limitations of previously existing methods. | ['Image-to-Image', 'Text-to-Image', 'Multimodal'] | N/A | N/A |
