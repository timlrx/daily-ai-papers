

## Papers for 2025-07-17

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [Towards Agentic RAG with Deep Reasoning: A Survey of RAG-Reasoning
  Systems in LLMs](https://arxiv.org/abs/2507.09477) | Wei-Chieh Huang, Yuyao Yang, Yangning Li, TreeForest, WZDavid |  - This paper surveys Retrieval-Augmented Generation (RAG) systems that incorporate deep reasoning in large language models (LLMs). - The authors categorize RAG-Reasoning methods into Reasoning-Enhanced RAG, RAG-Enhanced Reasoning, and Synergized RAG-Reasoning, based on how retrieval and reasoning interact. - The paper further categorizes methods within each category by their approach to retrieval optimization, integration enhancement, and generation enhancement. -  A taxonomy of recent advances in RAG-reasoning systems is presented in the paper along with a list of benchmarks and datasets used to evaluate them. - The paper concludes by discussing open challenges and research avenues for improving the effectiveness, adaptability, and trustworthiness of RAG-Reasoning systems. | ['Natural Language Processing', 'Question Answering'] | [Link](https://github.com/DavidZWZ/Awesome-RAG-Reasoning) | N/A |
| [MOSPA: Human Motion Generation Driven by Spatial Audio](https://arxiv.org/abs/2507.11949) | Leo Ho, Liang Pan, Mingyi Shi, frankzydou, JimSYXu | - This paper introduces MOSPA, a novel diffusion-based generative model for human motion generation driven by spatial audio, and a new Spatial Audio-Driven Human Motion (SAM) dataset. - The MOSPA model effectively captures the relationship between body motion and spatial audio through an effective fusion mechanism, integrating spatial features such as Mel-Frequency Cepstral Coefficients (MFCCs), Tempograms, and root mean square (RMS) energy. - The SAM dataset contains diverse and high-quality spatial audio and motion data, including diverse spatial audio signals and high-quality 3D human motion pairs. - Extensive experiments demonstrate that MOSPA achieves state-of-the-art performance, outperforming existing baselines in generating realistic and diverse motion responses to spatial audio. - The model and dataset are planned to be open-sourced upon acceptance. | ['Multimodal', 'Audio', 'Text-to-3D'] | N/A | N/A |
| [MMHU: A Massive-Scale Multimodal Benchmark for Human Behavior
  Understanding](https://arxiv.org/abs/2507.12463) | Mingyang Wu, Renjie Li, vztu, waynefan, jerryye0110 | - This paper introduces MMHU, a large-scale multimodal benchmark dataset for human behavior understanding in autonomous driving scenarios. - The dataset contains 57k human instances with diverse behaviors and 1.73M frames from various sources, including Waymo, YouTube, and self-collected videos. - MMHU provides rich annotations such as motion and trajectory, text descriptions, and critical behavior labels relevant to driving safety. - Multiple tasks are benchmarked including motion prediction, motion generation, and human behavior question answering, offering a comprehensive evaluation suite. - The dataset improves performance on several baseline models and demonstrates its effectiveness in various human-centric tasks. | ['Multimodal', 'Visual Question Answering', 'Video Classification', 'Keypoint Detection', 'Text Generation', 'Text2Text Generation'] | [Link](https://MMHU-Benchmark.github.io) | N/A |
| [SWE-Perf: Can Language Models Optimize Code Performance on Real-World
  Repositories?](https://arxiv.org/abs/2507.12415) | Zhijie Fan, Lin Yan, Xinyi He, Elfsong, SivilTaram | - SWE-Perf is introduced as the first benchmark designed to systematically evaluate LLMs on code performance optimization tasks within authentic repository contexts. - It comprises 140 instances derived from performance-improving pull requests from popular GitHub repositories. - Each instance includes the codebase, target functions, performance-related tests, expert-authored patches, and executable environments. - The benchmark reveals a substantial capability gap between existing LLMs and expert-level optimization performance. - This highlights critical research opportunities in this emerging field. | ['Natural Language Processing'] | [Link](https://swe-perf.github.io) | [Link](null) |
| [Lizard: An Efficient Linearization Framework for Large Language Models](https://arxiv.org/abs/2507.09025) | Franck-Dernoncourt, Nikosapa, TrungBui1111, jasubram, haniehds | - This paper introduces Lizard, a novel linearization framework that transforms pre-trained transformer-based large language models (LLMs) into flexible subquadratic architectures for infinite-context generation. - Lizard addresses the quadratic complexity of softmax attention and the growing key-value cache by introducing a subquadratic attention mechanism that closely approximates softmax attention while preserving output quality. - Unlike previous linearization methods, Lizard incorporates a gating module, enabling adaptive memory control, constant-memory inference, and strong length generalization. - Experimental results demonstrate that Lizard achieves near-lossless recovery of the teacher model's performance across standard language modeling tasks, significantly outperforming previous linearization methods by 8-18 points on the 5-shot MMLU benchmark. - The authors also introduce a hardware-aware algorithm that accelerates the training speed of Lizard models by up to 24%. | ['Natural Language Processing', 'Text Generation'] | N/A | N/A |
