

## Papers for 2025-07-24

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [Pixels, Patterns, but No Poetry: To See The World like Humans](https://arxiv.org/abs/2507.16863) | Xinhao Li, Jingyi Tang, Lin Xu, Zihao Huang, Hongcheng Gao | - This paper introduces the Turing Eye Test (TET), a new benchmark designed to evaluate the perceptual capabilities of Multimodal Large Language Models (MLLMs). - TET consists of four challenging tasks that involve intuitive human perception, focusing on synthetic images. - The results show that state-of-the-art MLLMs fail catastrophically on TET, indicating a significant gap between machine and human perception. - Fine-tuning the vision tower improves performance, suggesting that the problem lies in visual generalization and not in the knowledge and reasoning capabilities of the language backbone. - The authors plan to release the full set of TET tasks with more diverse challenges and will further explore methods to improve visual generalization in future work. | ['Multimodal'] | [Link](https://TuringEyeTest.github.io) | N/A |
| [Re:Form -- Reducing Human Priors in Scalable Formal Software
  Verification with RL in LLMs: A Preliminary Study on Dafny](https://arxiv.org/abs/2507.16331) | Xin Li, Xu Xu, Xuhan Huang, Fengdi Che, Chuanhao Yan | This paper introduces Re:Form, a novel pipeline that leverages reinforcement learning (RL) within large language models (LLMs) to reduce reliance on human priors in scalable formal software verification.  The pipeline is built around the Dafny formal language verifier and a newly designed benchmark, DafnyComp. Re:Form surpasses prior methods by achieving stronger generalization to out-of-domain tasks and outperforming strong baselines on DafnyComp.  The RL designs incorporates feedback from the formal language verifier, and automatically generates formal specifications using proprietary frontier LLMs to seed the training data.  The use of smaller LLMs (0.5B to 14B parameters) highlights efficiency gains.  | ['Reinforcement Learning', 'Text2Text Generation', 'Natural Language Processing'] | [Link](https://github.com/Veri-Code/ReForm) | [Link](https://huggingface.co/Veri-Code) |
| [RAVine: Reality-Aligned Evaluation for Agentic Search](https://arxiv.org/abs/2507.16725) | Jinhua Gao, Zhi Zheng, Xiang Long, Yilong Xu |  - This paper introduces RAVine, a novel evaluation framework designed to address misalignments in existing evaluation methods for agentic search.  - RAVine targets multi-point queries and long-form answers, reflecting real-world user scenarios more accurately.  - It employs an attributable ground truth construction strategy and examines the iterative process inherent to agentic search.  - The framework also accounts for efficiency factors, providing a more comprehensive assessment of model performance.  - RAVine benchmarks a series of models, providing insights into the strengths and limitations of current agentic search systems. | ['Natural Language Processing'] | [Link](https://github.com/SwordFaith/RAVine) | N/A |
