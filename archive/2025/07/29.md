

## Papers for 2025-07-29

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [ARC-Hunyuan-Video-7B: Structured Video Comprehension of Real-World
  Shorts](https://arxiv.org/abs/2507.20939) | Junfu Pu, Teng Wang, Chen Li, Yixiao Ge, Yuying Ge | - This paper introduces ARC-Hunyuan-Video-7B, a 7B-parameter multimodal model for structured video comprehension. - The model architecture incorporates an audio encoder with fine-grained visual-audio synchronization and timestamp overlay mechanism for temporal awareness. - The model undergoes a comprehensive training regimen including pre-training, instruction fine-tuning, cold start, reinforcement learning, and final instruction fine-tuning. - ARC-Hunyuan-Video-7B outperforms existing baselines on ShortVid-Bench, a new benchmark for real-world short video comprehension, and excels in temporal video grounding. - The model's real-world deployment shows improvements in user engagement and satisfaction, and stress tests indicate an inference time of just 10 seconds for a one-minute video on H20 GPU. | ['Video Classification', 'Video-Text-to-Text', 'Multimodal', 'Summarization', 'Question Answering', 'Reinforcement Learning'] | [Link](https://github.com/TencentARC/ARC-Hunyuan-Video-7B) | N/A |
| [SmallThinker: A Family of Efficient Large Language Models Natively
  Trained for Local Deployment](https://arxiv.org/abs/2507.20984) | Dongliang Wei, Zhenliang Xue, qsstcl, Sorrymaker2024, yixinsong | - This paper introduces SmallThinker, a family of LLMs designed for local deployment, addressing limitations of existing cloud-based models. - SmallThinker utilizes a two-level sparse structure combining fine-grained Mixture-of-Experts (MoE) with sparse feed-forward networks, and a pre-attention router to optimize performance on devices with limited memory and slow storage. - The models achieve state-of-the-art performance, exceeding 20 tokens/s on ordinary CPUs with Q4_0 quantization, while consuming only 1GB and 8GB of memory, respectively. - SmallThinker-4B-A0.6B and SmallThinker-21B-A3B outperform comparable models in terms of both speed and accuracy, demonstrating the efficiency of its design. - The research challenges the traditional paradigm of adapting cloud-based LLMs for local deployment by designing them natively for resource-constrained environments. | ['Natural Language Processing', 'Text Generation'] | N/A | [Link](hf.co/PowerInfer/SmallThinker-4BA0.6B-Instruct), [Link](hf.co/PowerInfer/SmallThinker-21BA3B-Instruct) |
| [Region-based Cluster Discrimination for Visual Representation Learning](https://arxiv.org/abs/2507.20025) | Yongle Zhao, Yin Xie, Athinklo, xiangan, Kaichengalex | - This paper introduces RICE, a novel method for visual representation learning that enhances region-level visual and OCR capabilities. - RICE uses a region transformer layer to extract rich regional semantics from a billion-scale candidate region dataset. - A unified region cluster discrimination loss jointly supports object and OCR learning, enabling efficient and scalable distributed training. - Extensive experiments show that RICE consistently outperforms previous methods on segmentation, dense detection, and visual perception for MLLMs. - The pre-trained models have been released at https://github.com/deepglint/MVT. | ['Multimodal', 'Image Feature Extraction', 'Zero-Shot Object Detection', 'Image Segmentation'] | [Link](https://github.com/deepglint/MVT) | N/A |
| [Music Arena: Live Evaluation for Text-to-Music](https://arxiv.org/abs/2507.20900) | Wei-Lin Chiang, Anastasios N. Angelopoulos, Wayne Chi, Yonghyun Kim, chrisdonahue | - The paper introduces Music Arena, an open platform for human preference evaluation of text-to-music (TTM) models.  - Music Arena addresses challenges in TTM evaluation by providing a scalable and standardized approach for collecting human preferences.  - The platform features an LLM-based system for prompt moderation and routing, detailed preference collection, and a rolling data release policy.  - Music Arena's modular architecture allows for easy integration of new TTM systems while maintaining a unified evaluation protocol.  - The authors demonstrate how Music Arena addresses key challenges in the TTM ecosystem and showcases the potential of live evaluation for AI domains with unique characteristics. | ['Audio', 'Text-to-Audio'] | [Link](https://github.com/gclef-cmu/music-arena) | N/A |
| [Beyond Binary Rewards: Training LMs to Reason About Their Uncertainty](https://arxiv.org/abs/2507.16806) | Leshem Choshen, Idan Shenfeld, Stewart Slocum, Isha Puri, Mehul Damani | This paper introduces RLCR, a novel reinforcement learning approach for training language models to reason about their uncertainty.  RLCR augments the standard binary correctness reward with a Brier score, incentivizing calibrated confidence estimates alongside accurate predictions.  Theoretical analysis proves that RLCR optimizes for both accuracy and calibration. Empirical results across diverse datasets demonstrate that RLCR substantially improves calibration without sacrificing accuracy, outperforming both standard RL training and post-hoc calibration methods.  Finally,  the study shows that verbalized confidence scores can be leveraged at test time to further improve model performance. | ['Reinforcement Learning', 'Question Answering'] | N/A | N/A |
| [GenoMAS: A Multi-Agent Framework for Scientific Discovery via
  Code-Driven Gene Expression Analysis](https://arxiv.org/abs/2507.21035) | Haohan Wang, Yijiang Li, Liu-Hy | GenoMAS is a novel multi-agent framework designed for scientific discovery through code-driven gene expression analysis. It leverages six specialized large language models (LLMs) to automate complex workflows and surpasses existing methods by 10.61% and 16.85% on the GenoTEX benchmark in data preprocessing and gene identification, respectively.  The framework integrates autonomous agents and structured workflows for enhanced flexibility and reliability, addressing challenges in handling noisy data and adapting to edge cases.  GenoMAS surfaces biologically plausible gene-phenotype associations, corroborated by the literature, while adjusting for latent confounders.  The framework introduces a novel guided-planning mechanism and uses a typed message-passing protocol for efficient agent collaboration. | ['Natural Language Processing', 'Text Generation', 'Text2Text Generation', 'Other'] | [Link](https://github.com/Liu-Hy/GenoMAS) | N/A |
