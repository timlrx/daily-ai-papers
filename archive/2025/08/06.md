

## Papers for 2025-08-06

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [Seed Diffusion: A Large-Scale Diffusion Language Model with High-Speed
  Inference](https://arxiv.org/abs/2508.02193) | Fan Xia, Pengyang Gao, Cheng Luo, Zheng Zhang, Yuxuan Song | - The paper introduces Seed Diffusion Preview, a large-scale language model based on discrete-state diffusion that offers remarkably fast inference speed. - The model achieves an inference speed of 2,146 tokens/s on H20 GPUs while maintaining competitive performance across various code evaluation benchmarks. - Seed Diffusion Preview's speed is significantly faster than contemporary models like Mercury and Gemini, establishing a new state-of-the-art in speed-quality tradeoff. - The model employs a two-stage curriculum for robust diffusion training, including mask-based and edit-based forward processes. - An on-policy learning paradigm is introduced to unlock parallel processing during inference, further enhancing efficiency. | ['Natural Language Processing', 'Text Generation'] | N/A | N/A |
| [Skywork UniPic: Unified Autoregressive Modeling for Visual Understanding
  and Generation](https://arxiv.org/abs/2508.03320) | Tianyidan Xie, Liang Hu, Yimeng Gan, Yi Peng, Peiyu Wang | - Skywork UniPic is a 1.5-billion parameter unified autoregressive model that combines image understanding, text-to-image generation, and image editing into a single architecture. - The model uses a decoupled encoding strategy with a masked autoregressive encoder for generation and a SigLIP2 encoder for understanding, both feeding into a shared autoregressive decoder. - Skywork UniPic outperforms most existing unified models, achieving a GenEval score of 0.86, a DPG-Bench complex-generation record of 85.5, and high scores on image editing benchmarks. - The model is trained using a progressive, resolution-aware schedule and meticulously curated datasets, achieving high fidelity while maintaining efficiency (under 15 GB GPU memory). - Code and weights are publicly available. | ['Multimodal', 'Text-to-Image', 'Image-to-Text', 'Image-to-Image'] | [Link](https://github.com/SkyworkAI/UniPic) | [Link](https://huggingface.co/Skywork/Skywork-UniPic-1.5B) |
| [CompassVerifier: A Unified and Robust Verifier for LLMs Evaluation and
  Outcome Reward](https://arxiv.org/abs/2508.03686) | Songyang Gao, Linchen Xiao, Junnan Liu, Hongwei Liu, Shudong Liu | CompassVerifier is a lightweight and robust verifier model designed for evaluating and providing outcome rewards for large language models.  It addresses limitations in existing methods by offering comprehensive benchmarks and handling complex edge cases. CompassVerifier demonstrates multi-domain competency across math, knowledge, and reasoning tasks and can process various answer types. The model is enhanced by the VerifierBench benchmark, a dataset of model outputs augmented with manual analysis of error patterns.  Experiments show CompassVerifier outperforms existing models on the VerifierBench benchmark, establishing a new state-of-the-art. | ['Question Answering'] | [Link](https://github.com/open-compass/CompassVerifier) | N/A |
| [LiveMCPBench: Can Agents Navigate an Ocean of MCP Tools?](https://arxiv.org/abs/2508.01780) | Yaojie Lu, Xuanang Chen, Jiawei Chen, Wenliang Zhong, Guozhao Mo | - The paper introduces LiveMCPBench, a comprehensive benchmark for evaluating large language model (LLM) agents' tool-use capabilities within the Model Context Protocol (MCP) ecosystem. - LiveMCPBench features 95 real-world tasks across diverse domains and a curated toolset (LiveMCPTool) encompassing 70 servers and 527 tools. - The benchmark incorporates LiveMCPEval, an LLM-as-a-Judge framework for automated and adaptive evaluation in dynamic task environments. - Evaluation on 10 leading models reveals significant performance variance, with the best-performing model achieving 78.95% success rate, highlighting challenges in meta-tool learning. - The paper also introduces MCP Copilot Agent, a multi-step agent showcasing dynamic planning and API interaction across the entire tool suite. | ['Natural Language Processing'] | [Link](https://github.com/icip-cas/LiveMCPBench) | N/A |
| [AlignGuard-LoRA: Alignment-Preserving Fine-Tuning via Fisher-Guided
  Decomposition and Riemannian-Geodesic Collision Regularization](https://arxiv.org/abs/2508.02079) | Aman Chadha, Vinija Jain, Abhilekh Borah, Amitava Das |  - This paper introduces ALIGNGUARD-LORA, a novel framework for preserving the alignment of large language models (LLMs) during low-rank fine-tuning, mitigating alignment drift. - ALIGNGUARD-LORA decomposes LoRA updates into alignment-critical and task-specific components, using the Fisher Information Matrix to identify and regularize alignment-sensitive directions. - The framework incorporates collision-aware regularization, which blends Riemannian overlap and geodesic separation penalties to ensure structural disentanglement between updates. - Empirical evaluations demonstrate that ALIGNGUARD-LORA mitigates alignment drift by up to 50% on safety-critical benchmarks without sacrificing downstream task performance. - The authors also propose DRIFTCHECK, a targeted diagnostic benchmark for quantifying alignment drift and safety degradation, and validate a scaling law for catastrophic forgetting. | ['Natural Language Processing'] | N/A | N/A |
| [TRACEALIGN -- Tracing the Drift: Attributing Alignment Failures to
  Training-Time Belief Sources in LLMs](https://arxiv.org/abs/2508.02063) | Aman Chadha, Vinija Jain, Amitava Das | *- TRACEALIGN is a novel framework that traces the root causes of unsafe large language model (LLM) outputs back to their training data. - It leverages a suffix-array based index (TRACEINDEX) and a belief conflict index (BCI) to pinpoint and quantify problematic belief fragments. - TRACEALIGN proposes three defense mechanisms: TRACESHIELD (an inference-time safety filter), Contrastive Belief Deconfliction Loss (a contrastive fine-tuning objective), and Prov-Decode (a provenance-aware decoding strategy). - Experiments on a curated Alignment Drift Benchmark (ADB) demonstrate that these defenses reduce alignment failures by up to 85% while maintaining utility. - The study advances alignment research by shifting the focus from surface behavior to the underlying beliefs within the model, enabling the construction of more robust and accountable LLMs. | ['Natural Language Processing'] | [Link](https://anonymous.4open.science/r/tracealign-2DA7) | N/A |
