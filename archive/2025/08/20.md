

## Papers for 2025-08-20

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [Chain-of-Agents: End-to-End Agent Foundation Models via Multi-Agent
  Distillation and Agentic RL](https://arxiv.org/abs/2508.13167) | Liam-Liu, hugteste, kangz, wanwan1212, tianyue818 | This paper introduces Chain-of-Agents (CoA), a novel paradigm for large language model (LLM) reasoning that enables end-to-end complex problem solving.  The CoA paradigm supports multi-agent collaboration within a single model by dynamically activating different tool agents and role-playing agents.  To achieve this, a multi-agent distillation framework is used to transfer capabilities from state-of-the-art multi-agent systems into LLM trajectories for agentic supervised fine-tuning, followed by agentic reinforcement learning.  The resulting models, Agent Foundation Models (AFMs), establish new state-of-the-art performance across diverse benchmarks in web and code agent settings. | ['Reinforcement Learning', 'Question Answering', 'Text Generation'] | [Link](https://github.com/huggingface/Math-Verify) | [Link](https://github.com/huggingface/smolagents) |
| [Prompt Orchestration Markup Language](https://arxiv.org/abs/2508.13948) | Yuqing Yang, Nan Chen, Yuge Zhang, Jiahang | POML is a novel markup language designed for prompt engineering, addressing challenges in prompt structure, data integration, format sensitivity, and tooling.  It offers specialized components for diverse data types (documents, tables, images) and a CSS-like styling system, decoupling content from presentation.  Two case studies (PomLink and TableQA) and a user study demonstrate POML's effectiveness in complex applications and real-world development.  The PomLink application showcases POML's support for multimodal data, while the TableQA case study explores the significant impact of prompt styling on model performance.  | ['Table Question Answering', 'Summarization', 'Text Generation', 'Multimodal'] | [Link](https://github.com/microsoft/poml) | N/A |
| [Mind the Generation Process: Fine-Grained Confidence Estimation During
  LLM Generation](https://arxiv.org/abs/2508.12040) | Xinyi Wang, Jie Shi, Shisong Chen, Tingyun Li, JinyiHan | - This paper introduces FineCE, a novel confidence estimation method that provides fine-grained, continuous confidence scores throughout the text generation process. - FineCE first develops a comprehensive pipeline for constructing training data that effectively captures the underlying probabilistic distribution of LLM responses. - Then, it trains a model to predict confidence scores for arbitrary text sequences in a supervised manner, and proposes a Backward Confidence Integration (BCI) strategy to enhance confidence estimation. - Extensive experiments demonstrate that FineCE consistently outperforms existing confidence estimation methods on multiple benchmark datasets. - FineCE provides three strategies for identifying optimal positions to perform confidence estimation within the generation process, which balances the trade-off between performance and computational efficiency. | ['Text Generation'] | [Link](https://github.com/JinyiHan99/FineCE) | N/A |
| [Evaluating Podcast Recommendations with Profile-Aware LLM-as-a-Judge](https://arxiv.org/abs/2508.08777) | Alice Wang, Edoardo D'Amico, Gustavo Penha, marcodena, frafabbri | - This paper introduces a novel framework that uses Large Language Models (LLMs) as offline judges to evaluate the quality of podcast recommendations. - The framework employs a two-stage profile-aware approach: it first creates natural-language user profiles from listening history, then uses these profiles to provide context for the LLM to judge the recommendations. - In a controlled study with 47 participants, the proposed method matched human judgments with high fidelity and outperformed a variant using raw listening histories. - The framework enables efficient, profile-aware evaluation, which is useful for iterative testing and model selection in recommender systems. - The contributions of this paper include a new evaluation framework, demonstrating the effectiveness of using LLMs as judges and the benefits of incorporating user profiles into the evaluation process. | ['Natural Language Processing'] | N/A | N/A |
| [A Stitch in Time Saves Nine: Proactive Self-Refinement for Language
  Models](https://arxiv.org/abs/2508.12903) | Zishang Jiang, Tingyun li, Haiquan Zhao, Xinyi Wang, JinyiHan | - This paper introduces ProActive Self-Refinement (PASR), a novel method that allows large language models (LLMs) to refine their outputs during the generation process, unlike traditional methods that refine after generation. - PASR uses reinforcement learning to train the LLM to make proactive refinement decisions based on its internal state and context, addressing the limitations of reactive, post-hoc refinement methods. - Experimental results on ten diverse tasks show that PASR significantly improves problem-solving performance, reducing average token consumption and increasing accuracy, particularly on Qwen3-8B. - The method uses a comparison-based reward strategy to encourage effective and timely refinements, avoiding unnecessary refinements and improving efficiency. - PASR demonstrates strong generalization capabilities, outperforming existing self-refinement methods across various tasks and achieving performance gains without external supervision or task-specific training. | ['Natural Language Processing', 'Text Generation', 'Reinforcement Learning'] | [Link](https://github.com/JinyiHan99/Proactive-Self-Refine-in-LLMs/) | N/A |
| [Advances in Speech Separation: Techniques, Challenges, and Future Trends](https://arxiv.org/abs/2508.10830) | Zhuo Chen, Yi Luo, Wendi Sang, Guo Chen, JusperLee | This paper provides a comprehensive survey of deep neural network-based speech separation techniques, covering various learning paradigms, architectural components, evaluation metrics, and datasets.  It offers a unique perspective by considering higher-level learning paradigms, including scenarios with a known or unknown number of speakers, and by evaluating technological trajectories. The authors critically evaluate existing methods, identify emerging trends, and suggest promising research directions.  The work differentiates itself from previous surveys by providing fair quantitative evaluations across datasets, including benchmark results.  Finally, the paper reviews existing open-source toolkits for the benefit of the research community. | ['Audio'] | N/A | N/A |
| [Embodied-R1: Reinforced Embodied Reasoning for General Robotic
  Manipulation](https://arxiv.org/abs/2508.13998) | Fei Ni, Yibin Chen, Yaoting Huang, Haiqin Cui, Yifu Yuan |  - This paper introduces Embodied-R1, a 3B Vision-Language Model (VLM) specifically designed for embodied reasoning and pointing, which bridges the gap between high-level vision-language comprehension and low-level action primitives.  - Embodied-R1 uses a two-stage Reinforced Fine-tuning (RFT) curriculum with a specialized multi-task reward design and achieves state-of-the-art performance on 11 embodied spatial and pointing benchmarks.  - It demonstrates robust zero-shot generalization by achieving a 56.2% success rate in the SIMPLEREnv and 87.5% across 8 real-world XArm tasks without any task-specific fine-tuning.  - The model exhibits high robustness against diverse visual disturbances and uses a pointing-centric representation.  - The core mechanism is to achieve unified anchoring of objects and spatial concepts through “pointing”, thereby mastering general robotic manipulation. | ['Robotics', 'Reinforcement Learning', 'Multimodal'] | [Link](https://github.com/pickxiguapi/Embodied-R1) | [Link](https://huggingface.co/IffYuan) |
| [Copyright Protection for Large Language Models: A Survey of Methods,
  Challenges, and Trends](https://arxiv.org/abs/2508.11548) | Xixiang Zhao, Qichen Liu, Xubin Yue, Zhenhua Xu, BreynaldDva | This paper presents a comprehensive survey of current Large Language Model (LLM) copyright protection technologies, focusing on model fingerprinting. - It clarifies the conceptual connection from text watermarking to model watermarking and fingerprinting, using a unified terminology. - It provides an overview and comparison of diverse text watermarking techniques, highlighting cases where these methods can function as model fingerprinting. - It systematically categorizes and compares existing model fingerprinting approaches for LLM copyright protection. - It presents techniques for fingerprint transfer and fingerprint removal, which are novel contributions in this area. - It summarizes evaluation metrics for model fingerprints. | ['Natural Language Processing'] | [Link](https://github.com/Xuzhenhua55/awesome-llm-copyright-protection) | N/A |
| [Leveraging Large Language Models for Predictive Analysis of Human Misery](https://arxiv.org/abs/2508.12669) | Abhilash Nandy, Aman Bansal, Rahul Seetharaman, Bishanka Seal | - This research paper introduces a novel approach for predicting human misery scores from natural language descriptions using large language models (LLMs). - The study compares different prompting strategies including zero-shot, few-shot, and retrieval-augmented prompting, demonstrating that few-shot and retrieval-based methods significantly outperform zero-shot baselines. - A gamified evaluation framework, "Misery Game Show", is introduced to assess the model's ability to adapt and refine predictions through feedback-driven reasoning; this shows measurable improvement in adaptive learning. - The paper uses a dataset of 516 real-world and imagined scenarios with human-annotated misery scores (0-100) to evaluate the performance of different LLMs. - The findings suggest that LLMs possess significant potential for subjective emotional reasoning tasks but also reveal limitations requiring further refinement of prompting strategies and model calibration. | ['Natural Language Processing', 'Text Classification', 'Zero-Shot Classification', 'Text Generation', 'Text2Text Generation', 'Tabular Regression'] | [Link](https://github.com/abhi1nandy2/Misery_Data_Exps_GitHub) | N/A |
| [CorrSteer: Steering Improves Task Performance and Safety in LLMs through
  Correlation-based Sparse Autoencoder Feature Selection](https://arxiv.org/abs/2508.12535) | Adriano Koshiyama, Zekun Wu, seonglae |  - CorrSteer is a novel method for improving task performance and safety in large language models (LLMs) by leveraging correlation-based sparse autoencoder (SAE) feature selection. - It addresses the limitations of existing SAE-based steering approaches by using only inference-time activations and avoiding the need for contrastive datasets or large activation storage. - CorrSteer demonstrates improved performance on various benchmarks, including question answering, bias mitigation, and safety tasks. - The selected features reveal semantically meaningful patterns that align with each task's requirements, highlighting the approach's interpretability. - The study establishes correlation-based feature selection as an effective and scalable approach for automated SAE steering across LLM applications. | ['Natural Language Processing', 'Text Generation', 'Feature Extraction'] | N/A | [Link](https://huggingface.co/spaces/seonglae/CorrSteer) |
| [Semantic IDs for Joint Generative Search and Recommendation](https://arxiv.org/abs/2508.10478) | Enrico Palumbo, Edoardo D'Amico, Gustavo Penha, frafabbri, marcodena | - This paper introduces a novel approach to constructing semantic IDs for joint generative search and recommendation models, focusing on creating a unified representation that performs well for both tasks. - The proposed method uses a bi-encoder model fine-tuned on both search and recommendation datasets to generate item embeddings, which are then used to create a unified semantic ID space. - Experimental results demonstrate that the proposed method outperforms existing task-specific approaches, achieving a strong performance trade-off between search and recommendation tasks without sacrificing the effectiveness of either task. - The study also explores several ID construction strategies, including task-specific, cross-task, and embedding combination methods, showing that the proposed unified approach is more effective. - The findings suggest that using a shared representation space for semantic IDs can streamline generative model design without sacrificing quality, especially in multi-task systems. | ['Natural Language Processing', 'Text2Text Generation', 'Other'] | N/A | N/A |
| [Describe What You See with Multimodal Large Language Models to Enhance
  Video Recommendations](https://arxiv.org/abs/2508.09789) | Mounia Lalmas, Andreas Damianou, marcodena | - This paper introduces a novel framework that leverages Multimodal Large Language Models (MLLMs) to enhance video recommendations by generating rich natural-language descriptions of video clips. - The framework is model-agnostic and requires zero-finetuning, making it easily adaptable to existing recommendation systems. - Experiments on the MicroLens-100K dataset demonstrate that MLLM-generated features consistently outperform traditional video, audio, and metadata features across various recommendation models. - The findings highlight the promise of using MLLMs as on-the-fly knowledge extractors to build more intent-aware video recommenders. - The authors make their prompts and generated data publicly available to promote reproducibility. | ['Video-Text-to-Text', 'Video Classification', 'Multimodal', 'Feature Extraction', 'Summarization'] | N/A | [Link](https://huggingface.co/datasets/marcodena/video-recs-describe-what-you-see) |
| [MMAU-Pro: A Challenging and Comprehensive Benchmark for Holistic
  Evaluation of Audio General Intelligence](https://arxiv.org/abs/2508.13992) | Fernando López, Vaibhavi Lokegaonkar, Šimon Sedláček, Sonal Kumar, Sreyan88 | - MMAU-Pro, a comprehensive benchmark for evaluating holistic audio intelligence in AI systems, is introduced.  It contains 5,305 instances with expert-generated question-answer pairs spanning speech, sound, and music. - The benchmark assesses auditory intelligence across 49 unique skills and multiple complex dimensions, including long-form audio comprehension and spatial audio reasoning. - Evaluation of 22 leading multimodal AI models reveals significant limitations, with even state-of-the-art models achieving accuracy as low as 51.7%, highlighting areas for future model development. - The benchmark's novel challenges and insights are expected to accelerate the progression of AI systems towards audio general intelligence. - MMAU-Pro surpasses existing benchmarks by including a wider range of audio types, incorporating diverse question formats and requiring more complex reasoning abilities. | ['Audio', 'Audio Classification', 'Question Answering', 'Multimodal'] | [Link](https://sonalkum.github.io/mmau-pro) | N/A |
| [MM-BrowseComp: A Comprehensive Benchmark for Multimodal Browsing Agents](https://arxiv.org/abs/2508.13186) | Jun Dong, Jiaheng Liu, Wenjie Wang, Xingyuan Bu, Shilong Li | This paper introduces MM-BrowseComp, a comprehensive benchmark designed to evaluate the multimodal browsing capabilities of AI agents.  The benchmark includes 224 challenging questions, many incorporating images and videos, requiring agents to retrieve and reason with multimodal content.  MM-BrowseComp reveals that even state-of-the-art models achieve low accuracy (around 29%), highlighting suboptimal multimodal capabilities and limited native multimodal reasoning. The benchmark also features a verified checklist for each question, enabling fine-grained analysis of agent behavior and reasoning paths.  The dataset is designed to address limitations in existing benchmarks that focus primarily on text-based information. | ['Multimodal'] | [Link](https://github.com/MMBrowseComp/MM-BrowseComp) | N/A |
| [Beyond Human Judgment: A Bayesian Evaluation of LLMs' Moral Values
  Understanding](https://arxiv.org/abs/2508.13804) | Alina Landowska, maciejskorski | - This paper introduces a novel Bayesian framework for evaluating large language models' (LLMs) understanding of moral values, addressing limitations of previous deterministic approaches. - The framework models annotator disagreements to capture both aleatoric and epistemic uncertainties, leading to more robust and nuanced evaluations. - A large-scale evaluation across three datasets (MFTC, eMFD, MFRC) with over 250K annotations and 1M+ model queries demonstrates that LLMs consistently outperform human annotators in balanced accuracy. - Interestingly, LLMs exhibit significantly fewer false negatives than humans, suggesting a more sensitive moral detection capability. - These findings have important implications for developing ethically aligned AI systems and highlight the potential of LLMs in moral reasoning tasks. | ['Natural Language Processing', 'Text Classification'] | [Link](https://github.com/maciejskorski/moral-foundations-llm-eval) | N/A |
