

## Papers for 2025-08-25

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [AgentFly: Fine-tuning LLM Agents without Fine-tuning LLMs](https://arxiv.org/abs/2508.16153) | Xue Yan, Siyuan Guo, Yihang Chen, linyiyang2023, Zhouhc | AgentFly is a novel memory-based learning paradigm for Large Language Models that eliminates the need for fine-tuning LLMs.  It leverages online reinforcement learning with a memory-augmented Markov Decision Process (M-MDP), incorporating a neural case-selection policy. AgentFly achieves top performance on various benchmarks, including GAIA, outperforming state-of-the-art methods.  Its continual learning capabilities allow for adaptation without gradient updates, demonstrating efficiency and scalability. The method's performance gains are attributed to case-based reasoning, enhancing adaptability and generalization. | ['Reinforcement Learning', 'Question Answering', 'Natural Language Processing', 'Multimodal'] | [Link](https://github.com/Agent-on-the-Fly/AgentFly) | N/A |
| [CRISP: Persistent Concept Unlearning via Sparse Autoencoders](https://arxiv.org/abs/2508.13650) | Yonatan Belinkov, Martin Tutek, Aaron Mueller, Dana Arad, Tomertech | - This paper introduces CRISP, a novel parameter-efficient method for persistent concept unlearning in large language models (LLMs) that uses sparse autoencoders (SAEs). - CRISP outperforms existing methods on safety-critical unlearning tasks by automatically identifying and suppressing salient SAE features across multiple layers, achieving better trade-offs between unlearning efficacy and preserving model utility. - The method is shown to be effective on two LLMs and outperforms previous approaches on the WMDP benchmark, indicating its robustness and generalizability. - Feature-level analysis demonstrates that CRISP achieves semantically coherent separation between target and benign concepts, ensuring precise suppression of the target features while maintaining coherence. - The method is parameter-efficient and is thus suited for open-source deployment, and it addresses the issue of inference-time interventions that can be bypassed by malicious actors. | ['Natural Language Processing', 'Text Generation', 'Feature Extraction'] | N/A | N/A |
| [AetherCode: Evaluating LLMs' Ability to Win In Premier Programming
  Competitions](https://arxiv.org/abs/2508.16402) | Yidi Du, Markus Mak, Zhicheng Liu, Jiaze Chen, zhwang01 | - AetherCode, a new benchmark for evaluating LLMs' coding and reasoning capabilities, is introduced.  It uses problems from premier programming competitions (IOI and ICPC) offering broader coverage and higher difficulty than existing benchmarks. - The benchmark addresses shortcomings of existing benchmarks by incorporating comprehensive, expert-validated test suites, combining automated generation and human curation to ensure rigorous assessment. - AetherCode's hybrid methodology combines automated test case generation with expert annotation to achieve 100% TPR and 100% TNR, ensuring high-quality test cases. - Evaluation reveals a significant performance gap between reasoning and non-reasoning models, with reasoning models demonstrating superior performance, particularly on complex algorithmic problems. - The results highlight the remaining challenges for LLMs in competitive programming and the need for continued improvement in reasoning and coding capabilities. | ['Natural Language Processing'] | N/A | [Link](https://huggingface.co/datasets/m-a-p/AetherCode) |
| [End-to-End Agentic RAG System Training for Traceable Diagnostic
  Reasoning](https://arxiv.org/abs/2508.15746) | Pengcheng Qiu, Chaoyi Wu, Yuze Sun, Qiaoyu Zheng, Angelakeke | This paper introduces Deep-DxSearch, a novel agentic RAG system for medical diagnosis trained end-to-end with reinforcement learning.  The model uses a large-scale medical retrieval corpus and a tailored reward function to improve diagnostic accuracy and traceability. Deep-DxSearch significantly outperforms several strong baselines across various datasets, achieving substantial gains in both in-distribution and out-of-distribution settings.  The model's performance is further enhanced by its ability to adapt retrieval strategies, perform effective differential diagnosis, and filter out irrelevant information.  The authors provide code and data for reproducibility. | ['Reinforcement Learning', 'Natural Language Processing', 'Question Answering'] | [Link](https://github.com/MAGIC-AI4Med/Deep-DxSearch) | N/A |
| [TPLA: Tensor Parallel Latent Attention for Efficient Disaggregated
  Prefill \& Decode Inference](https://arxiv.org/abs/2508.15881) | Di Yin, Yuxuan Wang, Pingzhi Tang, Fanxu Meng, xiaojuan0920 | - This paper introduces Tensor Parallel Latent Attention (TPLA), a novel technique designed to enhance the efficiency of disaggregated prefill and decode inference in large language models (LLMs). - TPLA addresses the limitations of existing methods like Multi-Head Latent Attention (MLA) in tensor parallel settings by partitioning both the latent representation and each head's input dimension across devices. - The proposed method preserves the benefits of compressed KV caching while achieving significant speedups (1.79x and 1.93x for DeepSeek-V3 and Kimi-K2, respectively) at a 32K-token context length. - TPLA maintains strong performance on commonsense and LongBench benchmarks and is compatible with FlashAttention-3 for end-to-end acceleration. - The authors demonstrate that TPLA is drop-in compatible with MLA pre-trained models and requires minimal retraining. | ['Natural Language Processing'] | [Link](https://github.com/fxmeng/TransMLA) | N/A |
| [AgentScope 1.0: A Developer-Centric Framework for Building Agentic
  Applications](https://arxiv.org/abs/2508.16279) | Liuyi Yao, Weirui Kuang, Yuexiang Xie, Zitao Li, Dawei Gao | - AgentScope 1.0 is a developer-centric framework for building agentic applications that leverages Large Language Models (LLMs). - It introduces improvements in supporting flexible and efficient tool-based agent-environment interactions, abstracting foundational components and providing unified interfaces. - AgentScope incorporates several built-in agents tailored to specific practical scenarios, along with robust engineering support for developer-friendly experiences. - It features a scalable evaluation module with a visual studio interface, a runtime sandbox for safe agent execution, and facilitates rapid deployment in production environments. - The framework is based on the ReAct paradigm and supports parallel tool calls, asynchronous executions, and real-time steering. | ['Natural Language Processing', 'Reinforcement Learning', 'Other'] | [Link](https://github.com/agentscope-ai/agentscope) | N/A |
| [InMind: Evaluating LLMs in Capturing and Applying Individual Human
  Reasoning Styles](https://arxiv.org/abs/2508.16072) | Diping Song, Qi Chen, Yibin Wang, Chuanhao Li, Zizhen Li | InMind is a novel, cognitively grounded evaluation framework designed to assess LLMs' capacity for individualized reasoning.  It uses social deduction games (SDGs) like Avalon, enhancing structured gameplay data with strategy traces and post-game reflections. InMind evaluates LLMs on four cognitively motivated tasks: Player Identification, Reflection Alignment, Trace Attribution, and Role Inference.  The results reveal key limitations in current LLMs' capacity for individualized reasoning, highlighting the need for further research to bridge the gap between human-like reasoning and current AI capabilities. The InMind-Avalon dataset is also introduced, containing detailed annotations of human gameplay. | ['Natural Language Processing'] | [Link](https://github.com/leroy9472/InMind) | N/A |
| [CARFT: Boosting LLM Reasoning via Contrastive Learning with Annotated
  Chain-of-Thought-based Reinforced Fine-Tuning](https://arxiv.org/abs/2508.15868) | Yulun Zhang, Haipang Wu, Rongjuncheng Zhang, Ji Liu, Wenqiao Zhu | - This paper introduces CARFT, a novel contrastive learning approach for enhancing the reasoning capabilities of Large Language Models (LLMs). - CARFT leverages annotated Chain-of-Thought (CoT) and incorporates contrastive signals to guide the fine-tuning process, addressing limitations of existing RL-based methods. - The method uses CoT embeddings to generate contrastive signals, including positive (correct answers) and negative signals (incorrect answers), improving both performance and stability. - Experiments on the SVAMP and GSM8K datasets demonstrate that CARFT significantly outperforms baselines (SFT, ReFT, and Dr.GRPO) in terms of accuracy and robustness, achieving improvements of up to 10.15%. - CARFT's efficiency is also highlighted, showing improvements of up to 30.62% compared to Dr.GRPO. | ['Question Answering'] | [Link](https://github.com/WNQzhu/CARFT) | N/A |
| [Jailbreaking Commercial Black-Box LLMs with Explicitly Harmful Prompts](https://arxiv.org/abs/2508.10390) | Liming Fang, Jiafei Wu, Xiaogang Xu, Lu Zhou, AlienZhang1996 | - This paper introduces MDH, a malicious content detection framework that combines LLM-based annotation with human oversight to improve the accuracy and efficiency of cleaning red-teaming datasets and identifying jailbroken responses. - Two new jailbreaking strategies, D-Attack and DH-CoT, are proposed.  D-Attack leverages context simulation, while DH-CoT incorporates hijacked chains of thought to improve the success rate of jailbreaks. - The MDH framework achieves over 95% accuracy in detecting malicious content across multiple datasets with less than 10% manual effort. - The proposed jailbreaking methods demonstrate significant improvements in attack success rates compared to existing approaches, particularly on reasoning models with the DH-CoT method. - The paper contributes datasets, judgements, and detection results to a GitHub repository for reproducibility and further research. | ['Natural Language Processing', 'Text Classification', 'Text Generation', 'Text2Text Generation'] | [Link](https://github.com/AlienZhang1996/DH-CoT) | N/A |
