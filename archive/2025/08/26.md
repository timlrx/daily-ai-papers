

## Papers for 2025-08-26

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [InternVL3.5: Advancing Open-Source Multimodal Models in Versatility,
  Reasoning, and Efficiency](https://arxiv.org/abs/2508.18265) | jinglinglin, WesKwong, MIASANMIA, gulixin0922, Weiyun1025 |  - InternVL 3.5 is a new family of open-source multimodal models that significantly improves versatility, reasoning, and inference efficiency.  - A key innovation is the Cascade Reinforcement Learning (Cascade RL) framework, which enhances reasoning through a two-stage process: offline RL for stable convergence and online RL for refined alignment.  - To optimize efficiency, a Visual Resolution Router (ViR) dynamically adjusts the resolution of visual tokens and a Decoupled Vision-Language Deployment (DvD) strategy separates the vision encoder and language model across different GPUs.  - InternVL3.5-241B-A28B achieves state-of-the-art results among open-source MLLMs across various tasks and narrows the performance gap with leading commercial models like GPT-5.  - All models and code are publicly released. | ['Multimodal'] | [Link](https://github.com/OpenGVLab/InternVL) | [Link](https://huggingface.co/OpenGVLab/InternVL3_5-241B-A28B) |
| [Beyond Memorization: Extending Reasoning Depth with Recurrence, Memory
  and Test-Time Compute Scaling](https://arxiv.org/abs/2508.16745) | Daniil Orel, mbur, yurakuratov, b1l4lx1, irodkin | - This paper introduces a novel benchmark, 1dCA-Reasoning, for evaluating the multi-step reasoning capabilities of neural models, focusing on rule generalization rather than memorization. - The authors conduct a comprehensive study across diverse neural architectures (Transformers, LSTMs, state-space models, and ARMT), demonstrating that increasing model depth significantly improves multi-step reasoning performance. - They investigate several depth-extension strategies, including recurrence, memory, and test-time compute scaling (ACT), finding that ACT yields a noticeable improvement while preserving parameter efficiency. -  Reinforcement learning with GRPO allows for successful multi-step reasoning without intermediate supervision, and chain-of-thought prompting achieves near-perfect accuracy up to k=4. - The study highlights the importance of both architectural inductive biases and training objectives in determining the reasoning capabilities of neural models. | ['Natural Language Processing'] | [Link](https://github.com/) | [Link](https://huggingface.co/datasets/irodkin/1dCA_r2s20T20) |
| [UQ: Assessing Language Models on Unsolved Questions](https://arxiv.org/abs/2508.17580) | Wei Liu, Rui Sun, Zihao Wang, Fan Nie, kzliu | This paper introduces UQ, a new benchmark for evaluating language models on unsolved questions sourced from Stack Exchange.  UQ addresses the limitations of existing benchmarks by focusing on challenging, open-ended problems with inherent real-world value. The benchmark is composed of 500 questions across diverse topics, curated through a multi-stage pipeline employing rule-based filters, LLM judges, and human review.  The evaluation of models on UQ is performed asynchronously and uses validator strategies that leverage the generator-validator gap to provide evaluation signals before human verification. A platform supports community-driven evaluation and asynchronous verification of solutions. | ['Question Answering'] | [Link](https://github.com/) | [Link](https://huggingface.co/) |
| [MEENA (PersianMMMU): Multimodal-Multilingual Educational Exams for
  N-level Assessment](https://arxiv.org/abs/2508.17290) | Doratossadat Dastgheib, Seyed Mohammad Hadi Hosseini, Marzia Nouri, Arshia Hemmat, omidgh |  - This paper introduces MEENA, a new multimodal-multilingual dataset designed to evaluate Persian VLMs across a wide range of educational tasks.   - MEENA includes approximately 7,500 Persian and 3,000 English questions, covering diverse subjects and educational levels.   - The dataset incorporates various question formats, including multiple-choice, mathematical problem solving and visual reasoning.   - MEENA also includes rich metadata, such as difficulty levels, descriptive answers, and human performance data.   - Experimental results demonstrate the challenges that current VLMs face in handling both reasoning and complex multimodal tasks, especially in Persian. | ['Multimodal', 'Visual Question Answering', 'Question Answering'] | N/A | N/A |
| [Explain Before You Answer: A Survey on Compositional Visual Reasoning](https://arxiv.org/abs/2508.17298) | Xin Zheng, Zixian Ma, Joy Hsu, Fucai Ke, ControlNet | This survey paper comprehensively reviews the field of compositional visual reasoning (CVR), focusing on works from 2023 to 2025.  It identifies key advantages of CVR over monolithic approaches, including improved cognitive alignment, semantic fidelity, robustness, and data efficiency. The paper traces the evolution of CVR paradigms across five stages: prompt-enhanced language-centric methods, tool-enhanced LLMs and VLMs, chain-of-thought reasoning VLMs, and unified agentic VLMs.  It catalogs benchmarks and metrics for evaluating CVR systems, highlighting challenges such as LLM limitations, hallucinations, and bias toward deductive reasoning.  Finally, the survey proposes future directions for CVR research, including world-model integration, human-AI collaborative reasoning, and improved evaluation protocols. | ['Multimodal', 'Visual Question Answering', 'Question Answering'] | N/A | N/A |
| [German4All - A Dataset and Model for Readability-Controlled Paraphrasing
  in German](https://arxiv.org/abs/2508.17973) | Cristian-George Craciun, Maximilian Müller, Eslam Nasrallah, Thanh Mai Pham, Miriam Anschütz | - The paper introduces German4All, the first large-scale German dataset of aligned readability-controlled, paragraph-level paraphrases, spanning five readability levels and comprising over 25,000 samples. - German4All was automatically synthesized using GPT-4 and rigorously evaluated through human and LLM-based judgments to ensure data quality and usefulness. - An open-source, readability-controlled paraphrasing model trained on German4All achieves state-of-the-art performance in German text simplification, allowing for nuanced reader-specific adaptations. - The dataset and model are open-sourced to encourage further research on multi-level paraphrasing and readability control in German. - The study also shows how the model outperforms existing German ATS systems on existing text simplification datasets in terms of SARI scores and FRE, demonstrating its effectiveness in handling different complexity levels. | ['Text2Text Generation'] | [Link](https://github.com/MiriUll/German4All) | N/A |
| [Limitations of Normalization in Attention Mechanism](https://arxiv.org/abs/2508.17821) | Radu State, Tatiana Petrova, mbur, opensapce | - This paper investigates the limitations of normalization in attention mechanisms, focusing on the softmax function. - The authors provide a theoretical framework to analyze the model's selective ability and geometric separation in token selection, deriving explicit bounds on distances and separation criteria. - Through experiments with pre-trained GPT-2 models, they validate their theoretical results and demonstrate that the model's ability to distinguish informative tokens declines as the number of selected tokens increases. - They also show that gradient sensitivity under softmax normalization poses challenges during training, especially at low temperatures. - This work advances the understanding of softmax-based attention mechanisms and motivates the development of more robust normalization and selection strategies for future attention architectures. | ['Natural Language Processing', 'Text Generation'] | N/A | N/A |
| [TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language
  Modeling](https://arxiv.org/abs/2508.16790) | Jiaqi Li, Junan Zhang, Xueyao Zhang, Dekun Chen, Yuancheng Wang | - TaDiCodec, a novel text-aware diffusion speech tokenizer, is proposed to address limitations of existing methods by employing end-to-end optimization for quantization and reconstruction through a diffusion autoencoder, while integrating text guidance.- TaDiCodec achieves an extremely low frame rate of 6.25 Hz and a corresponding bitrate of 0.0875 kbps, outperforming existing methods in terms of compression while maintaining competitive performance on speech generation evaluation metrics.- The model architecture uses a diffusion autoencoder with a single-layer codebook and incorporates text guidance into the diffusion decoder to improve reconstruction quality.- TaDiCodec demonstrates compatibility with language model-based zero-shot text-to-speech using both autoregressive and masked generative modeling, showcasing its effectiveness for speech language modeling.- The authors will open-source the code and model checkpoints, and audio samples are available on the project website. | ['Text-to-Speech'] | [Link](https://github.com/HeCheng0625/Diffusion-Speech-Tokenizer) | N/A |
| [Neither Valid nor Reliable? Investigating the Use of LLMs as Judges](https://arxiv.org/abs/2508.18076) | Golnoosh Farnadi, Jackie Chi Kit Cheung, Mohammed Haddou, Khaoula Chehbouni | This paper investigates the use of Large Language Models (LLMs) as judges for evaluating Natural Language Generation (NLG) systems.  It critically examines four core assumptions underlying the use of LLMs as evaluators: their ability to act as proxies for human judgment, their capabilities as evaluators, their scalability, and their cost-effectiveness. The authors identify and assess challenges to these assumptions, drawing on measurement theory from the social sciences. Three applications of LLMs as judges are explored: text summarization, data annotation, and safety alignment. Finally, the paper highlights the need for more responsible evaluation practices to ensure that the growing role of LLMs in NLG evaluation supports, rather than undermines, progress in the field. | ['Natural Language Processing'] | N/A | N/A |
