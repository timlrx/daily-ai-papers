

## Papers for 2025-08-27

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [CMPhysBench: A Benchmark for Evaluating Large Language Models in
  Condensed Matter Physics](https://arxiv.org/abs/2508.18124) | Dongchen Huang, komusama0930, BoringMarsh, di-zhang-fdu, weidawang | CMPhysBench is a new benchmark for evaluating large language models (LLMs) in condensed matter physics.  It comprises over 520 graduate-level physics problems, meticulously designed to require comprehensive solutions and deep understanding.  The benchmark introduces a novel evaluation metric, SEED (Scalable Expression Edit Distance), which provides fine-grained accuracy assessment.  Experimental results reveal a substantial performance gap between current LLMs and human-level expertise in this complex domain. The code and dataset are publicly available. | ['Question Answering'] | [Link](https://github.com/CMPhysBench/CMPhysBench) | N/A |
| [VibeVoice Technical Report](https://arxiv.org/abs/2508.19205) | Yaoyao Chang, Wenhui Wang, Jianwei Yu, Zhiliang Peng, unilm | - This paper introduces VIBEVOICE, a novel model for synthesizing long-form speech with multiple speakers using a next-token diffusion approach. - The model employs a novel continuous speech tokenizer that improves data compression by 80 times compared to Encodec, enhancing computational efficiency for long sequences. - VIBEVOICE can generate long-form speech of up to 90 minutes, supporting up to 4 speakers, and outperforms existing open-source and proprietary dialogue models in subjective evaluations of preference, realism, and richness. - The model architecture integrates a Large Language Model (LLM) with specialized audio encoding and diffusion-based decoding modules for scalable, high-fidelity multi-speaker speech synthesis. - Experiments demonstrate VIBEVOICE's superior performance on both long conversational speech and short utterances, showcasing its versatility and effectiveness. | ['Text-to-Speech'] | [Link](github.com/microsoft/VibeVoice) | [Link](microsoft/VibeVoice) |
| [UltraMemV2: Memory Networks Scaling to 120B Parameters with Superior
  Long-Context Learning](https://arxiv.org/abs/2508.18756) | Ran Guo, Siyan Chen, Qiyang Min, Yu Bao, FetchFortune | - UltraMemV2 is a redesigned memory-layer architecture that improves upon previous memory-layer architectures by achieving performance parity with 8-expert Mixture of Experts (MoE) models while maintaining significantly lower memory access costs. - The model introduces five key improvements: integrating memory layers into every transformer block, simplifying value expansion with single linear projections, adopting FFN-based value processing from PEER, implementing principled parameter initialization, and rebalancing memory-to-FFN computation ratios. - UltraMemV2 demonstrates superior performance on memory-intensive tasks, showing improvements of +1.6 points on long-context memorization, +6.2 points on multi-round memorization, and +7.9 points on in-context learning compared to 8-expert MoE models. - The model scales effectively to 120B parameters, with 2.5B activated parameters, establishing that activation density has a greater impact on performance than total sparse parameter count. - The research validates the effectiveness of UltraMemV2 as a compelling alternative to state-of-the-art MoE models for efficient sparse computation. | ['Natural Language Processing'] | [Link](https://github.com/ZihaoHuang-notabot/Ultra-Sparse-Memory-Network) | N/A |
| [Pixie: Fast and Generalizable Supervised Learning of 3D Physics from
  Pixels](https://arxiv.org/abs/2508.17437) | Dinesh Jayaraman, Chuhao Chen, Chen Wang, Ryan Lucas, vlongle |  - PIXIE is a novel method for supervised learning of 3D physics from pixels, using a feed-forward U-Net architecture with CLIP features to predict material properties and a physics solver (e.g., MPM) for simulation. - The model predicts both discrete material types and continuous values (Young's modulus, Poisson's ratio, density) and is significantly faster than test-time optimization methods. - PIXIE outperforms previous state-of-the-art methods by 1.46-4.39x in terms of realism scores evaluated by a vision-language model while being three orders of magnitude faster. - The model generalizes to real-world scenes despite being trained solely on synthetic data. - The PIXIEVERSE dataset, containing 1624 3D assets with material annotations, is also introduced to support the research. | ['Image-to-3D', 'Computer Vision', 'Multimodal'] | [Link](https://pixie-3d.github.io/) | N/A |
| [Autoregressive Universal Video Segmentation Model](https://arxiv.org/abs/2508.19242) | Albert Gu, Yu-Chiang Frank Wang, Sukjun Hwang, Miran Heo, cmhungsteve | - This paper introduces the Autoregressive Universal Segmentation Model (AUSM), a novel model that unifies both prompted and unprompted video segmentation tasks. - AUSM employs a fixed-size spatial state and scales to video streams of arbitrary length, addressing limitations of previous methods. - The model outperforms existing universal streaming video segmentation methods on several benchmark datasets, achieving up to 2.5x faster training on 16-frame sequences. - AUSM's architecture incorporates components like History Marker and History Compressor, specialized for handling streaming videos and preserving fine-grained spatio-temporal details. - The training of AUSM is designed for parallelism across frames, resulting in significant speedups compared to iterative training approaches. | ['Image Segmentation', 'Video Classification', 'Multimodal'] | N/A | N/A |
| [Wan-S2V: Audio-Driven Cinematic Video Generation](https://arxiv.org/abs/2508.18621) | Chaonan Ji, Mingyang Huang, Siqi Hu, Li Hu, Xin Gao | - This paper introduces Wan-S2V, a novel audio-driven model for generating cinematic videos, which significantly outperforms existing state-of-the-art methods in terms of expressiveness and realism, as demonstrated by experimental results. - The model architecture leverages a hybrid training strategy combining FSDP with Context Parallel, enabling large-scale, full-parameter model training and improving training efficiency. - Wan-S2V incorporates both text and audio inputs to control the video generation process; text guides the overall scene dynamics, while audio controls the fine-grained details of character actions and expressions. - The model addresses the challenge of long video generation by employing a FramePack module to reduce computational costs and improve the consistency of long-term video generation. - Extensive experiments on a comprehensive dataset consisting of both public and internally collected data demonstrate that Wan-S2V surpasses existing methods in terms of various quantitative metrics (e.g., FID, FVD, SSIM, PSNR) and qualitative evaluations. | ['Audio-to-Audio', 'Text-to-Video', 'Multimodal'] | N/A | N/A |
| [ReportBench: Evaluating Deep Research Agents via Academic Survey Tasks](https://arxiv.org/abs/2508.15804) | Kai Jia, Cong Ma, Zhihao Cheng, Ying Zeng, Minghao Li | - ReportBench is a novel benchmark designed to evaluate the content quality of research reports generated by LLMs, focusing on the quality of cited literature and the faithfulness of generated statements. - It leverages high-quality published survey papers available on arXiv as gold-standard references, applying reverse prompt engineering to derive prompts and create a comprehensive evaluation corpus. - ReportBench uses an agent-based automated framework to analyze reports, extracting citations and statements, verifying cited content against original sources, and validating non-cited claims using web-based resources. - Evaluations show that commercial Deep Research agents generate more comprehensive and reliable reports than standalone LLMs. - The complete code and data are available at https://github.com/ByteDance-BandAI/ReportBench. | ['Natural Language Processing', 'Text Classification'] | [Link](https://github.com/ByteDance-BandAI/ReportBench) | N/A |
| [ThinkDial: An Open Recipe for Controlling Reasoning Effort in Large
  Language Models](https://arxiv.org/abs/2508.18773) | Jiangjie Chen, Mingxuan Wang, Xuefeng Li, Siyu Yuan, Qianyu He | - This paper introduces ThinkDial, the first open-source framework that implements controllable reasoning in large language models (LLMs) through discrete operational modes, similar to the proprietary gpt-oss series. - ThinkDial enables seamless switching between three reasoning regimes: High (full capability), Medium (50% token reduction with <10% performance degradation), and Low (75% token reduction with <15% performance degradation). - The framework employs an end-to-end training paradigm that integrates budget-mode control throughout the pipeline, including budget-mode supervised fine-tuning and two-phase budget-aware reinforcement learning with adaptive reward shaping. - Extensive experiments demonstrate ThinkDial's ability to achieve target compression-performance trade-offs while maintaining performance thresholds and exhibiting strong generalization on out-of-distribution tasks. - The authors' main contribution is the creation of an open recipe for controlling reasoning effort, moving beyond existing approaches that primarily rely on explicit token budget specification or adaptive mode switching. | ['Natural Language Processing'] | N/A | N/A |
| [Optimal Sparsity of Mixture-of-Experts Language Models for Reasoning
  Tasks](https://arxiv.org/abs/2508.18672) | Daisuke Nohara, Takumi Okamoto, Masaki Kawamura, Satoki Ishikawa, Taishi-N324 |  - This paper investigates the optimal sparsity of Mixture-of-Experts (MoE) language models for reasoning tasks.   - The authors train families of MoE Transformers with varying parameters, active parameters, and top-k routing, while holding the compute budget fixed.   - Their findings show that reasoning performance saturates and can regress despite continued gains in total parameters and training loss, unlike memorization performance which improves monotonically.   - They also find that changing top-k alone has little effect when active parameters are constant and that classic hyperparameters such as learning rate and initialization modulate the generalization gap in the same direction as sparsity.   - The authors conclude that finding the optimal sparsity of MoE during pre-training is crucial for training a reasoning model under a fixed compute budget. | ['Natural Language Processing'] | [Link](https://github.com/rioyokotalab/optimal-sparsity) | N/A |
| [QueryBandits for Hallucination Mitigation: Exploiting Semantic Features
  for No-Regret Rewriting](https://arxiv.org/abs/2508.16697) | Manuela Veloso, Sumitra Ganesh, Alec Koppel, William Watson, Nicole Cho | This paper introduces QueryBandits, a novel bandit framework designed to mitigate hallucinations in Large Language Models (LLMs) by strategically rewriting queries.  The framework leverages 17 linguistic features to predict hallucination propensity and employs Thompson Sampling to select optimal query rewrites.  Empirical results across 13 diverse QA benchmarks show that QueryBandits significantly outperforms both a no-rewrite baseline and existing static prompting strategies, achieving an 87.5% win rate over the no-rewrite baseline.  The study also reveals that no single rewrite strategy is universally optimal and highlights the importance of context-aware rewriting for hallucination mitigation. | ['Question Answering'] | N/A | N/A |
| [Demystifying Scientific Problem-Solving in LLMs by Probing Knowledge and
  Reasoning](https://arxiv.org/abs/2508.19202) | Arman Cohan, Doug Downey, Arpan Sarkar, Yixin Liu, Alan Li |  - This paper introduces SCIREAS, a unified benchmark suite for evaluating scientific reasoning in LLMs, and SCIREAS-PRO, a challenging subset that better differentiates weak and strong reasoners. - It proposes KRUX, a probing framework to study the distinct roles of knowledge and reasoning in scientific tasks. - The findings reveal that retrieving task-relevant knowledge from model parameters is a critical bottleneck for LLMs in scientific reasoning. - The study shows reasoning models consistently benefit from external knowledge added in-context. - Finally, it introduces SCILIT01, a strong 8B baseline for scientific reasoning. | ['Question Answering'] | [Link](https://github.com/yale-nlp/SciReas-Eval) | N/A |
| [Unraveling the cognitive patterns of Large Language Models through
  module communities](https://arxiv.org/abs/2508.18192) | Jianxi Gao, Pin-Yu Chen, KBhandari11 | This paper introduces a novel network-based framework to study the cognitive patterns of large language models (LLMs) by connecting cognitive skills, LLM architectures, and datasets.  The framework reveals that LLMs exhibit modular structures with communities of modules whose emergent skill patterns partially mirror the distributed organization seen in avian and small mammalian brains.  However, it highlights a key divergence from biological systems, where skill acquisition benefits substantially from cross-regional interactions and neural plasticity, unlike the rigid modularity of LLMs.  The results suggest that effective fine-tuning strategies should leverage distributed learning dynamics rather than modular interventions.  Further, the findings are validated using community-based fine-tuning strategies. | ['Natural Language Processing'] | [Link](https://github.com/KBhandari11/LLMNeuron) | [Link](https://huggingface.co/KBhandari11/collections) |
