

## Papers for 2025-09-02

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [UI-Level Evaluation of ALLaM 34B: Measuring an Arabic-Centric LLM via
  HUMAIN Chat](https://arxiv.org/abs/2508.17378) | Omartificial-Intelligence-Space | - This paper presents an expanded UI-level evaluation of the ALLaM-34B Arabic language model, using a prompt pack covering various aspects of Arabic language and culture. - The evaluation involved three frontier LLMs (GPT-5, Gemini 2.5 Pro, Claude Sonnet-4) as judges, rating 115 outputs on accuracy, fluency, instruction following, safety, and dialect fidelity. - ALLaM-34B demonstrated high performance in code-switching and generation tasks, as well as strong results in MSA handling and reasoning. - Dialect fidelity varied across regions, with Najdi, Hijazi, and Egyptian dialects showing better results than Levantine and Moroccan. - The model showed robustness and reliability in safety-related prompts, demonstrating its readiness for real-world deployment. | ['Natural Language Processing', 'Text Generation'] | N/A | N/A |
| [How Can Input Reformulation Improve Tool Usage Accuracy in a Complex
  Dynamic Environment? A Study on τ-bench](https://arxiv.org/abs/2508.20931) | Jayanth Srinivasa, Mutsumi Nakamura, Satyam Raj, Amir Saeidi, Venkatesh Mishra | - This paper introduces the Input Reformulation Multi-Agent (IRMA) framework to improve the accuracy of tool-using language agents in complex dynamic environments. - IRMA enhances agent decision-making by reformulating user prompts with structured context, including domain rules and tool suggestions. - Experimental results on the τ-bench benchmark demonstrate that IRMA significantly outperforms existing methods (ReAct, Function Calling, and Self-Reflection) across various metrics, achieving a 43% pass^5 score. - The framework is shown to be more robust to errors (like hallucination) compared to baselines. - The improvements achieved by IRMA highlight the potential of context engineering to improve the reliability of LLM agents. | ['Natural Language Processing'] | N/A | N/A |
