

## Papers for 2025-09-03

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [LLaVA-Critic-R1: Your Critic Model is Secretly a Strong Policy Model](https://arxiv.org/abs/2509.00676) | Jianwei Yang, Chunyuan Li, Benjamin-eecs, drogozhang, russwang |  - This paper introduces LLaVA-Critic-R1, a multimodal model trained via reinforcement learning on a critic dataset. Unlike typical critic models that only score responses, LLaVA-Critic-R1 directly produces responses, achieving competitive performance against specialized reasoning models.  - LLaVA-Critic-R1 outperforms existing methods on 26 visual reasoning and understanding benchmarks by an average of +5.7%, achieving state-of-the-art results on some benchmarks.  -  The improved critic capabilities enhance inference: test-time self-critique boosts performance by an average of +13.8% on five reasoning tasks without additional training.  - The model's enhanced critic capability comes from RL training and two factors: improved visual perception, and structured reasoning through a "think-then-answer" generation pattern.  - The study validates the effectiveness of RL critic training on other strong reasoning models and shows that the dual ability benefits test-time scaling. | ['Multimodal', 'Reinforcement Learning'] | [Link](https://github.com/LLaVA-VL/LLaVA-NeXT/LLaVA-Critic-R1) | [Link](https://huggingface.co/collections/lmms-lab/llava-critic-r1) |
| [Baichuan-M2: Scaling Medical Capability with Large Verifier System](https://arxiv.org/abs/2509.02208) | Jayok6, yuanshuai, sdujq, anselcmy, fairyang |  - Baichuan-M2 is a 32B parameter medical augmented reasoning model that outperforms other open-source and many closed-source models on HealthBench, achieving a score above 32 on the challenging HealthBench Hard benchmark.  - The model is trained using a novel dynamic verification framework that simulates real-world clinical scenarios with a Patient Simulator and a Clinical Rubrics Generator, moving beyond static answer verification.  - The framework incorporates multi-stage reinforcement learning with an improved Group Relative Policy Optimization algorithm, enhancing various capabilities such as medical knowledge, reasoning, and patient interaction.  - The model achieves a new Pareto front in the performance-parameter trade-off for medical AI deployment, making it more feasible in resource-constrained healthcare settings.  - The results underscore the critical role of a robust validation system in integrating model capabilities with practical applications. | ['Reinforcement Learning', 'Natural Language Processing', 'Question Answering'] | N/A | N/A |
| [Kwai Keye-VL 1.5 Technical Report](https://arxiv.org/abs/2509.01563) | SXxtyz, Chengru, bhsc24, dingboyang, biaoYang |  -  This paper introduces Keye-VL-1.5, an 8-billion parameter multimodal foundation model that improves video understanding capabilities.  - The model architecture uses a novel Slow-Fast video encoding strategy that dynamically allocates computational resources based on inter-frame similarity.  - Keye-VL-1.5 employs a four-stage pre-training methodology that systematically extends the model's context length from 8K to 128K tokens.  -  The model also incorporates a post-training pipeline focusing on reasoning enhancement and human preference alignment.  - Keye-VL-1.5 demonstrates significant improvements over existing models across various benchmarks, particularly excelling in video understanding tasks. | ['Video-Text-to-Text', 'Multimodal', 'Visual Question Answering'] | [Link](https://github.com/Kwai-Keye/Keye) | [Link](https://huggingface.co/Kwai-Keye) |
| [Reasoning Vectors: Transferring Chain-of-Thought Capabilities via Task
  Arithmetic](https://arxiv.org/abs/2509.01363) | Bernard Ghanem, Mohammad Zbeeb, hammh0a | - This paper introduces the concept of reasoning vectors, which are compact representations of reasoning capabilities learned by large language models (LLMs). - Reasoning vectors are extracted by comparing two identically initialized LLMs: one fine-tuned with supervised fine-tuning (SFT) and the other with group relative policy optimization (GRPO). - The reasoning vector is then added to compatible instruction-tuned models using simple arithmetic to enhance their reasoning capabilities, which is demonstrated on various reasoning benchmarks, showing consistent improvements. - This approach allows for transferring reasoning abilities between models without requiring additional training, making it a cost-effective method for enhancing LLMs. - The paper also demonstrates the robustness and generalizability of the reasoning vector through several experiments and ablation studies. | ['Natural Language Processing'] | N/A | N/A |
| [GenCompositor: Generative Video Compositing with Diffusion Transformer](https://arxiv.org/abs/2509.02460) | Lingen Li, Guangzhi Wang, Xiaodong Cun, Xiaoyu521, Ysz2022 | - The paper introduces GenCompositor, a novel generative video compositing method that uses a Diffusion Transformer (DiT) to seamlessly integrate dynamic foreground elements into background videos. - GenCompositor consists of three main components: a lightweight DiT-based background preservation branch, a DiT fusion block with full self-attention, and a novel position embedding method called Extended Rotary Position Embedding (EROPE). - The model is trained on a new dataset called VideoComp, containing 61K video sets with high-quality target videos and complete dynamic elements. - Experiments demonstrate that GenCompositor outperforms existing solutions in terms of fidelity and consistency, achieving state-of-the-art results on video harmonization and trajectory-controlled generation tasks. - The authors also showcase the model's generalizability by applying it to video inpainting and object removal tasks. | ['Image-to-Video', 'Video Classification', 'Text-to-Video', 'Multimodal'] | [Link](https://gencompositor.github.io/) | N/A |
| [Jointly Reinforcing Diversity and Quality in Language Model Generations](https://arxiv.org/abs/2509.02534) | Tianlu, jcklcn, spermwhale, danyaljj, dogtooth | This paper introduces DARLING, a novel framework that jointly optimizes for response quality and semantic diversity in language model generations.  DARLING uses a learned partition function to measure semantic diversity and combines this signal with a quality reward during online reinforcement learning. Experiments show that DARLING consistently outperforms existing quality-only RL baselines across multiple model families and sizes on both non-verifiable (instruction following, creative writing) and verifiable (competition math) tasks.  Most strikingly, optimizing for diversity improves exploration, which leads to higher-quality responses. The code is available on GitHub. | ['Natural Language Processing', 'Reinforcement Learning', 'Text Generation'] | [Link](https://github.com/facebookresearch/darling) | N/A |
| [OpenVision 2: A Family of Generative Pretrained Visual Encoders for
  Multimodal Learning](https://arxiv.org/abs/2509.01644) | Zirui Wang, Letian Zhang, Xianhang Li, Yanqing Liu, cihangxie | - This paper introduces OpenVision 2, a simplified version of OpenVision that uses only a captioning loss for training, removing the text encoder and contrastive loss. - OpenVision 2 achieves competitive performance with the original OpenVision model while significantly reducing training time and memory consumption (e.g., 1.5x faster training time and 1.8x less memory usage with ViT-L/14). - The model's superior training efficiency allows for scaling beyond the largest vision encoders previously used in OpenVision, reaching over 1 billion parameters. - OpenVision 2's performance is evaluated on a range of multimodal benchmarks, consistently matching or exceeding the performance of the original OpenVision and other CLIP variants. - The results demonstrate that a purely generative, caption-only training objective can rival contrastive methods in multimodal performance while substantially lowering computational and memory requirements. | ['Multimodal'] | [Link](https://github.com/UCSC-VLAA/OpenVision) | [Link](https://huggingface.co/UCSC-VLAA) |
| [M3Ret: Unleashing Zero-shot Multimodal Medical Image Retrieval via
  Self-Supervision](https://arxiv.org/abs/2509.01360) | Yan-Jie Zhou, Heng Guo, Chengyu Fang, Zheng Jiang, Che Liu | - This paper introduces M³Ret, a unified visual encoder for zero-shot multimodal medical image retrieval, trained on a large-scale hybrid-modality dataset comprising 867,653 medical images. - M³Ret uses both generative (MAE) and contrastive (SimDINO) self-supervised learning paradigms, achieving state-of-the-art results in zero-shot image-to-image retrieval across various modalities (X-rays, ultrasound, endoscopy, and CT scans). - The model demonstrates strong cross-modal alignment without paired data and generalizes to unseen MRI tasks, showcasing the effectiveness of purely visual self-supervision. - Comprehensive analyses validate the scalability of M³Ret across different model and data sizes, demonstrating its robustness and potential as a foundation model for visual self-supervised learning in multimodal medical image understanding. - The paper highlights three key contributions: unified training across diverse medical modalities without modality-specific modifications, superior zero-shot image retrieval performance across various datasets, and analysis validating that performance gains are primarily driven by scaling data, model capacity, and compute. | ['Image-to-Image', 'Image Feature Extraction', 'Zero-Shot Image Classification', 'Multimodal'] | N/A | N/A |
| [Attributes as Textual Genes: Leveraging LLMs as Genetic Algorithm
  Simulators for Conditional Synthetic Data Generation](https://arxiv.org/abs/2509.02040) | Xiaolei Huang, Weisi Liu, kwangju | - This paper introduces Genetic Prompt, a novel framework that uses genetic algorithms with LLMs to generate high-quality and diverse synthetic data for NLP tasks. - The framework treats semantic text attributes as gene sequences and leverages LLMs to simulate crossover and mutation operations, enhancing data quality and diversity. - Experiments show that Genetic Prompt significantly outperforms state-of-the-art baselines on multiple NLP tasks, demonstrating robustness and scalability across various generator model sizes. - The approach also integrates an active learning scheme to optimize parent selection and expand the offspring search space. - The results validate that Genetic Prompt is an effective method for producing high-quality synthetic data for NLP applications. | ['Natural Language Processing', 'Text Generation'] | [Link](https://github.com/trust-nlp/Genetic-Prompt) | N/A |
| [Benchmarking Optimizers for Large Language Model Pretraining](https://arxiv.org/abs/2509.01440) | mjaggi, MatPag, Andron00e | This paper presents a comprehensive benchmarking of 11 optimization methods across various LLM pretraining scenarios.  The study systematically varies model size, batch size, and training duration to provide guidance on which optimizer is best suited for each scenario.  A key finding is that AdEMAMix and MARS consistently outperform other optimizers across different scales and training lengths, challenging the long-standing dominance of AdamW.  Furthermore, the authors open-source their full benchmarking toolkit, including training scripts and evaluation pipelines, enabling fully reproducible research. Finally, the paper provides a set of best practices for LLM pretraining. | ['Natural Language Processing'] | [Link](https://github.com/epfml/llm-optimizer-benchmark) | [Link](https://huggingface.co/datasets/HuggingFaceFW/fineweb) |
| [The Gold Medals in an Empty Room: Diagnosing Metalinguistic Reasoning in
  LLMs with Camlang](https://arxiv.org/abs/2509.00425) | Solomon Tsai, Zhujun Jin, Yixuan Liu, Fenghua Liu, yulongchen |  - This paper introduces Camlang, a novel constructed language designed to evaluate metalinguistic reasoning in LLMs.  - Camlang includes explicit resources like a grammar book and a bilingual dictionary, enabling a controlled assessment of LLM competence.  - Experiments reveal a significant performance gap between LLMs and humans on Camlang tasks, highlighting limitations in metalinguistic reasoning.  - Human verification shows that most LLM successes are from shallow lexical alignment, not systematic grammatical mastery.  - Camlang establishes a cognitively grounded evaluation paradigm for assessing the fundamental gaps between current LLMs and human capabilities. | ['Natural Language Processing'] | N/A | N/A |
| [Fantastic Pretraining Optimizers and Where to Find Them](https://arxiv.org/abs/2509.02046) | Percy Liang, Tengyu Ma, David Hall, Kaiyue Wen |  - This paper conducts a systematic study of ten deep learning optimizers for large language model pretraining, addressing previous methodological shortcomings.  - It finds that fair comparisons require rigorous hyperparameter tuning and end-of-training evaluations across various model scales and data-to-model ratios.  - The study reveals that the speedup of many optimizers over well-tuned AdamW baselines is lower than previously claimed and diminishes with model size.  - Matrix-based optimizers consistently outperform scalar-based optimizers, although the speedup decreases with model scale.  - The optimal choice of optimizer depends on data-to-model ratios, highlighting the complexity of optimizer selection for large language model training. | ['Natural Language Processing'] | [Link](https://github.com/marin-community/marin/tree/kaiyue/optimizers) | N/A |
| [Universal Deep Research: Bring Your Own Model and Strategy](https://arxiv.org/abs/2509.00244) | Pavlo Molchanov, Peter Belcak | - The paper introduces Universal Deep Research (UDR), a generalist agentic system that allows users to create custom deep research strategies using any language model without requiring additional training or fine-tuning. - UDR addresses limitations of existing deep research tools by enabling users to define resource hierarchies, automate cross-validation, and manage search expenses. - The system converts user-defined research strategies into executable code, ensuring transparent and deterministic behavior.  - UDR employs language models for localized tasks like summarization and ranking, while maintaining control logic in generated code for efficiency and reliability. - The research demonstrates UDR's flexibility and capability through various examples, highlighting its potential to automate complex research workflows. | ['Natural Language Processing', 'Question Answering'] | N/A | N/A |
| [FlashAdventure: A Benchmark for GUI Agents Solving Full Story Arcs in
  Diverse Adventure Games](https://arxiv.org/abs/2509.01052) | Dongmin Park, Jaehyeon Son, Heeseung Yun, Junseo Kim, ahnpersie |  - This paper introduces FlashAdventure, a benchmark of 34 Flash-based adventure games designed to evaluate GUI agents' ability to solve full story arcs.  - It proposes CUA-as-a-Judge, an automated gameplay evaluator, and COAST, an agentic framework that leverages long-term clue memory to improve planning and problem-solving in adventure games.  - Experiments show that current GUI agents struggle with full story arcs, while COAST improves milestone completion by bridging the observation-behavior gap.  - The benchmark includes diverse subgenres (mystery/detective, hidden object, room escape, visual novel, simulation) to evaluate agents' generalizability.  -  The results highlight a significant performance gap between humans and state-of-the-art GUI agents, suggesting opportunities for future research. | ['Multimodal', 'Reinforcement Learning'] | [Link](https://ahnjaewoo.github.io/flashadventure) | N/A |
| [AMBEDKAR-A Multi-level Bias Elimination through a Decoding Approach with
  Knowledge Augmentation for Robust Constitutional Alignment of Language Models](https://arxiv.org/abs/2509.02133) | Rahul Karthikeyan, Shivam Dubey, Aryan Kasat, Snehasis Mukhopadhyay, amanchadha | This paper introduces AMBEDKAR, a novel framework for mitigating bias in Large Language Models (LLMs).  AMBEDKAR employs a two-stage approach, using a smaller, potentially biased model to generate text and a larger, constitutionally-aligned verifier model to evaluate fairness.  It uses a speculative decoding algorithm that prioritizes outputs aligned with fairness principles and reduces casteist and communal bias by up to 26.41%. This framework operates at inference time and reduces the computational overhead compared to retraining. The results demonstrate improved fairness without significantly sacrificing text quality. | ['Natural Language Processing', 'Text Generation', 'Text Classification'] | [Link](https://anonymous.4open.science/r/AMBEDKAR-983B/) | N/A |
| [Improving Large Vision and Language Models by Learning from a Panel of
  Peers](https://arxiv.org/abs/2509.01610) | Simon Jenni, Jing Shi, Jefferson Hernandez, kushalkafle, vicenteor | - This paper introduces a novel Panel-of-Peers (PoP) learning framework for improving Large Vision and Language Models (LVLMs). - The PoP framework leverages a panel of LVLMs that iteratively evaluate and learn from each other's outputs through a simulated peer-review system. - Experiments demonstrate that PoP enhances model performance across multiple benchmarks without extensive human-labeled data, increasing average scores on fifteen benchmarks from 48% to 57%. - The methodology is shown to enable knowledge transfer between models with different capabilities, such as those with and without OCR abilities. - Ablation studies analyze the impact of various design choices on PoP's performance. | ['Multimodal'] | N/A | N/A |
| [SQL-of-Thought: Multi-agentic Text-to-SQL with Guided Error Correction](https://arxiv.org/abs/2509.00581) | bindsch, amanchadha, shollercoaster | - This paper introduces SQL-of-Thought, a novel multi-agent framework for Natural Language to SQL (NL2SQL) that uses a chain-of-thought prompting approach for query planning and guided error correction. - The framework decomposes the NL2SQL task into schema linking, subproblem identification, query planning, SQL generation, and a guided correction loop, using specialized agents for each subtask. - Unlike previous methods that rely on execution-based feedback alone, SQL-of-Thought incorporates a taxonomy-guided dynamic error modification mechanism, informed by in-context learning, which leads to state-of-the-art results on the Spider dataset and its variants. - The paper demonstrates that the combination of reasoning-based query planning and taxonomy-guided error correction is superior to methods that rely solely on execution feedback. - Experimental results show that SQL-of-Thought achieves state-of-the-art execution accuracy (91.59% on Spider, 90.16% on Spider-Realistic) and a high valid SQL generation rate (94%-99%). | ['Natural Language Processing'] | N/A | N/A |
| [Metis: Training Large Language Models with Advanced Low-Bit Quantization](https://arxiv.org/abs/2509.00404) | Hengjie Cao, wenzi001, ZhouJixian, cnyangyifeng, ChenMengyi | - This paper introduces Metis, a novel training framework designed to enhance the training of large language models (LLMs) using low-bit quantization. - Metis addresses the inherent anisotropy in parameter distributions, a key obstacle in low-bit quantization, by combining spectral decomposition with random embedding to create quantization-friendly narrow distributions. - The framework incorporates adaptive learning rates within the spectral domain to amplify underrepresented directions and a dual-range regularizer that jointly constrains numerical precision and parameter range distribution for stable training. - Metis demonstrates significant improvements in training stability and accuracy, achieving FP8 performance that surpasses FP32 baselines and FP4 accuracy comparable to FP32. - The proposed method is validated on moderately sized models (1B parameters) and shows potential to scale to larger models, paving the way for efficient and scalable LLM training under advanced low-bit quantization. | ['Natural Language Processing'] | [Link](https://github.com/typename-yyf/Metis-quantization) | N/A |
