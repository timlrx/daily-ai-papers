

## Papers for 2025-09-08

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [Why Language Models Hallucinate](https://arxiv.org/abs/2509.04664) | Edwin Zhang, Santosh S. Vempala, Ofir Nachum, Adam Tauman Kalai | This paper investigates the causes of hallucinations in large language models (LLMs).  The authors argue that current training and evaluation methods reward guessing over acknowledging uncertainty, leading to the generation of plausible but incorrect statements.  They introduce a novel reduction from the problem of hallucination to binary classification, providing a theoretical framework to analyze the statistical origins of hallucinations and why they persist in post-training. The paper concludes by suggesting that modifying existing benchmarks to better align with trustworthy AI systems is key to mitigating this issue.  This involves modifying existing benchmarks and leaderboards to reduce the penalization of uncertainty. | ['Natural Language Processing'] | [Link](null) | [Link](null) |
| [Symbolic Graphics Programming with Large Language Models](https://arxiv.org/abs/2509.05208) | Kaipeng Zhang, Zeju Qiu, Haoquan Zhang, Yamei Chen, YangyiH | This paper introduces a novel method for training large language models (LLMs) to generate symbolic graphics programs (SGPs) from natural language descriptions.  The method utilizes reinforcement learning with a custom reward function that incorporates both format validity and cross-modal alignment using vision encoders. The resulting model achieves performance comparable to state-of-the-art proprietary models on a new benchmark, SGP-GenBench, which evaluates object fidelity, scene fidelity, and compositionality of generated SVGs.  Furthermore, analysis reveals emergent behaviors, such as finer decomposition of objects and the generation of semantically relevant contextual details. The proposed approach facilitates efficient and effective symbolic graphics programming by directly leveraging the knowledge encoded in pre-trained vision models without requiring extensive paired data. | ['Multimodal', 'Text-to-Image', 'Reinforcement Learning'] | N/A | N/A |
| [Set Block Decoding is a Language Model Inference Accelerator](https://arxiv.org/abs/2509.04185) | Jeremy Reizenstein, Daniel Haziza, Marton Havasi, Heli Ben-Hamu, Itai Gat | - This paper introduces Set Block Decoding (SBD), a novel method to accelerate language model inference by integrating next token prediction (NTP) and masked token prediction (MATP). - SBD allows the model to sample multiple tokens in parallel, unlike previous acceleration methods. - The method uses advanced solvers from the discrete diffusion literature to achieve significant speedups without accuracy loss. - Experiments on Llama-3.1 8B and Qwen-3 8B show that SBD achieves a 3-5x reduction in the number of forward passes required for generation. - SBD maintains compatibility with exact KV-caching and can be implemented by fine-tuning existing NTP models. | ['Text Generation'] | N/A | N/A |
| [WildScore: Benchmarking MLLMs in-the-Wild Symbolic Music Reasoning](https://arxiv.org/abs/2509.04744) | Amit Namburi, Yash Vishe, Gagan Mundada, ZacharyNovack, XinXuNLPer | - WildScore, a novel benchmark dataset for evaluating multimodal large language models (MLLMs) on symbolic music reasoning tasks, is introduced.  The dataset is unique in that it uses real-world music scores paired with user-generated questions and discussions, offering a significant step towards evaluating the true capabilities of models. - The dataset creation process is detailed, including data collection from online forums, multimodal filtering, and the transformation of user queries into multiple choice questions for a standardized evaluation. - A comprehensive taxonomy is proposed, covering multiple high-level and fine-grained musicological ontologies, allowing for a rigorous and interpretable assessment of model performance across different reasoning categories. - Experimental results reveal that state-of-the-art MLLMs exhibit inconsistent accuracy across various music reasoning tasks, with certain models struggling significantly more than others, showing the existing challenges in this area. - Further analysis highlights the importance of visual context for accurate reasoning, with some models showing improved performance when provided with symbolic score images, while others perform less well or even worse with images than without. | ['Multimodal', 'Visual Question Answering'] | [Link](https://github.com/GaganVM/WildScore) | [Link](https://huggingface.co/datasets/GM77/WildScore) |
| [On Robustness and Reliability of Benchmark-Based Evaluation of LLMs](https://arxiv.org/abs/2509.04013) | Kevin Roitero, Stefano Mizzaro, Vincenzo Della Mea, Riccardo Lunardi | - This paper investigates the robustness and reliability of benchmark-based evaluations for Large Language Models (LLMs) by systematically assessing their performance on paraphrased benchmark questions. - The study finds that while LLM rankings remain relatively stable across paraphrased inputs, absolute effectiveness scores decline significantly, suggesting LLMs struggle with linguistic variability. - The results challenge the reliability of current benchmark-based evaluations, indicating that high benchmark scores may not fully reflect a model's real-world robustness. - The authors emphasize the need for robustness-aware benchmarks that better reflect practical deployment scenarios and incorporate linguistic variability. - The findings have implications for LLM evaluation methodologies and highlight the limitations of relying solely on fixed, standardized question formats. | ['Question Answering'] | N/A | N/A |
| [MedVista3D: Vision-Language Modeling for Reducing Diagnostic Errors in
  3D CT Disease Detection, Understanding and Reporting](https://arxiv.org/abs/2509.03800) | Vanessa Wildman, Jike Zhong, Yuxiang Lai, Yenho Chen, Yuheng Li | - MedVista3D is a novel multi-scale semantic-enriched vision-language model for 3D CT analysis that performs local and global image-text alignment for fine-grained representation learning within full-volume context. - It addresses the challenges of under-reading, inattentional blindness, and communication failures in radiology by jointly performing local detection and global understanding of diseases. - The model uses a multi-scale loss function that simultaneously aligns CT volumes and organ-level features with their corresponding text descriptions to maximize mutual information. - MedVista3D achieves state-of-the-art performance on zero-shot disease classification, report retrieval, and medical visual question answering, and transfers well to organ segmentation and prognosis prediction. - The model addresses the variability of radiology reports by using language model rewrites and introducing a Radiology Semantic Matching Bank for semantics-aware alignment. | ['Multimodal', 'Image-to-Text', 'Image-to-3D', 'Zero-Shot Image Classification', 'Image Segmentation', 'Visual Question Answering'] | N/A | N/A |
| [Behavioral Fingerprinting of Large Language Models](https://arxiv.org/abs/2509.04504) | Xing Li, Zhiyuan Yang, Ying Zhang, Hui-Ling Zhen, Zehua Pei | - This paper introduces a novel framework called "Behavioral Fingerprinting" to evaluate Large Language Models (LLMs) by assessing their nuanced behavioral characteristics beyond traditional performance metrics. - The framework uses a curated Diagnostic Prompt Suite and an automated evaluation pipeline where a powerful LLM acts as an impartial judge to analyze models across various dimensions such as reasoning, biases, and robustness. - Eighteen models were evaluated, revealing convergence in core capabilities like reasoning but significant divergence in alignment-related behaviors like sycophancy and semantic robustness. - A cross-model default persona clustering was observed, suggesting that interactive nature of models is a consequence of developer alignment strategies rather than an emergent property of model size or reasoning power. - The framework provides a reproducible and scalable methodology for uncovering deep behavioral differences in LLMs, offering insights into alignment strategies and model development. | ['Natural Language Processing', 'Text Generation'] | [Link](https://github.com/JarvisPei/Behavioral-Fingerprinting) | N/A |
