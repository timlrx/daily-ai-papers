

## Papers for 2025-09-09

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [Reverse-Engineered Reasoning for Open-Ended Generation](https://arxiv.org/abs/2509.06160) | Wangchunshu Zhou, Minghao Liu, Qixin Xu, Haoran Que, Haozhe Wang | - This paper introduces Reverse-Engineered Reasoning (REER), a novel paradigm that recovers latent reasoning processes from known good outputs to overcome limitations of traditional methods like reinforcement learning and instruction distillation for open-ended generation. - REER is operationalized as a gradient-free search problem, iteratively refining an initial thinking process to discover a trajectory that best explains a high-quality output, using perplexity as a proxy for quality. - DeepWriting-20K, a large-scale dataset of 20,000 deep reasoning trajectories for open-ended tasks, is created and open-sourced. - The DeepWriter-8B model, trained on DeepWriting-20K, outperforms strong open-source baselines and achieves performance competitive with leading proprietary models on various benchmarks, demonstrating the effectiveness of REER. - Experiments show the contribution of each component, indicating that synthesized deep thinking trajectories and iterative refinement are crucial for success. | ['Text Generation'] | N/A | N/A |
| [WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents](https://arxiv.org/abs/2509.06501) | Aili Chen, Jingyang Li, Chi Zhang, Yunji Li, Junteng Liu | - This paper introduces WebExplorer, a novel method for training long-horizon web agents that uses model-based exploration and iterative query evolution to generate a challenging dataset of query-answer pairs. - WebExplorer-8B, an 8B parameter model trained using this dataset, achieves state-of-the-art performance on several information-seeking benchmarks, outperforming larger models in many cases. - The method uses supervised fine-tuning followed by reinforcement learning to improve the model's reasoning capabilities and ability to handle longer contexts. - The dataset, WebExplorer-QA, contains approximately 40K query-answer pairs that require multi-step reasoning and complex web navigation. - The results demonstrate the effectiveness of the proposed approach for training advanced web agents capable of complex information seeking. | ['Reinforcement Learning', 'Question Answering'] | [Link](https://github.com/hkust-nlp/WebExplorer) | N/A |
| [Revolutionizing Reinforcement Learning Framework for Diffusion Large
  Language Models](https://arxiv.org/abs/2509.06949) | Ke Shen, Ye Tian, Bowen Li, Ling Yang, Yinjie Wang | - This paper introduces TraceRL, a novel trajectory-aware reinforcement learning framework for diffusion language models (DLMs). - TraceRL incorporates preferred inference trajectories into post-training, improving reasoning performance on complex tasks such as math and coding. - The framework is applicable across different DLM architectures, including full-attention and block-attention models, and enhances sampling flexibility. -  Employing TraceRL, the authors developed a series of state-of-the-art diffusion language models, TraDo, which outperform existing AR models on various benchmarks. - A comprehensive open-source framework is released, facilitating reproducible research and practical applications of diffusion LLMs. | ['Reinforcement Learning', 'Natural Language Processing', 'Text Generation'] | [Link](https://github.com/Gen-Verse/dLLM-RL) | N/A |
| [Reinforced Visual Perception with Tools](https://arxiv.org/abs/2509.01656) | Mingyang Fu, Zhihan Hu, Zixian Ma, Dongping Chen, Zetong Zhou | - This paper introduces REVPT, a novel two-stage framework that enhances multi-modal language models' visual perception capabilities by integrating visual processing tools as reasoning steps. - REVPT uses a novel RL algorithm based on GRPO to train models to reason with four visual tools (object detection, depth estimation, edge detection, and zoom). - Experimental results show that REVPT achieves state-of-the-art performance on several perception-heavy benchmarks, outperforming supervised and text-based RL finetuning baselines. - Notably, REVPT-3B and REVPT-7B outperform instruct models by 9.03% and 9.44% on CV-Bench. - The authors provide extensive ablations and insights into RL-based visual tool usage. | ['Multimodal', 'Visual Question Answering', 'Reinforcement Learning', 'Object Detection', 'Depth Estimation'] | [Link](https://github.com/ls-kelvin/REVPT) | N/A |
| [UniVerse-1: Unified Audio-Video Generation via Stitching of Experts](https://arxiv.org/abs/2509.06155) | Xinyao Liao, Ling-Hao Chen, Aojie Li, Wei Zuo, Duomin Wang | - This paper introduces UniVerse-1, a novel unified audio-video generation model that leverages a stitching of experts technique to combine pre-trained video and audio generation models. - UniVerse-1 uses an online annotation pipeline for accurate data alignment, and addresses cross-modal noise correlation by employing independent noise sampling. - The model is evaluated using a new benchmark dataset called Verse-Bench, demonstrating good performance on both audio-visual and unimodal generation tasks. - The model and code are publicly available, closing the gap between closed-source and open-source research in this area.  - UniVerse-1 achieves high-quality video and audio generation, showing strong alignment between both modalities. | ['Text-to-Video', 'Audio', 'Text-to-Audio', 'Multimodal'] | [Link](https://dorniwang.github.io/UniVerse-1/) | N/A |
| [Llama-GENBA-10B: A Trilingual Large Language Model for German, English
  and Bavarian](https://arxiv.org/abs/2509.05668) | Hoi-Fong Mak, Gokul Ramakrishnan, Stefan Schweter, Jophin John, Michael Hoffmann | - This paper introduces Llama-GENBA-10B, a 10B parameter trilingual large language model trained on a balanced corpus of English, German, and Bavarian. - The model addresses the challenge of English-centric bias in LLMs by balancing resources across languages and includes Bavarian to support low-resource languages. - Four key challenges were addressed during development: multilingual corpus curation, a unified tokenizer, optimized architecture and language ratios, and a standardized trilingual evaluation suite. - Llama-GENBA-10B achieves strong cross-lingual performance, surpassing existing models in Bavarian and matching or exceeding performance in English and German according to the benchmark used in this paper. - The model's training on a single Cerebras CS-2 system is highlighted as an example of efficient large-scale multilingual pretraining. | ['Natural Language Processing', 'Text Generation', 'Translation'] | N/A | N/A |
| [Test-Time Scaling in Reasoning Models Is Not Effective for
  Knowledge-Intensive Tasks Yet](https://arxiv.org/abs/2509.06861) | See-Kiong Ng, Bryan Hooi, James Xu Zhao | - This paper explores the effectiveness of test-time scaling (TTS) in improving the performance of reasoning models on knowledge-intensive tasks. - The authors conduct a comprehensive evaluation of 12 reasoning models on two benchmarks, SimpleQA and FRAMES, to assess how increasing test-time computation affects accuracy and hallucination rates. - The findings reveal that increasing test-time computation does not consistently improve accuracy and often leads to more hallucinations, challenging the common assumption that more thinking leads to better performance. - Through analysis, the authors identify that reduced hallucinations frequently result from model abstention rather than factual recall improvements, while increased hallucinations often stem from models attempting previously unanswered questions. - The study concludes that despite some benefits of enabling the models to think before answering, increasing test-time computation is not yet a reliable strategy to improve factual accuracy and reduce hallucinations in knowledge-intensive tasks. | ['Question Answering'] | [Link](https://github.com/XuZhao0/tts-knowledge) | N/A |
| [Saturation-Driven Dataset Generation for LLM Mathematical Reasoning in
  the TPTP Ecosystem](https://arxiv.org/abs/2509.06809) | Damien Sileo, Valentin Quesnel | - This paper introduces a novel framework for generating a large-scale, high-quality dataset for training LLMs in mathematical reasoning. - The framework leverages the TPTP library and E-prover to generate a massive corpus of mathematically valid theorems, eliminating factual errors. - It generates three types of tasks: entailment verification, premise selection, and proof graph reconstruction, each with controllable difficulty levels. - Experiments on several LLMs reveal that performance significantly decreases with increased task complexity, particularly for tasks requiring deep structural reasoning. - The authors make the code and data publicly available to facilitate further research on LLM mathematical reasoning. | ['Natural Language Processing'] | [Link](https://github.com/sileod/reasoning_core) | [Link](https://hf.co/datasets/reasoning-core/rc1) |
| [D-HUMOR: Dark Humor Understanding via Multimodal Open-ended Reasoning](https://arxiv.org/abs/2509.06771) | Dhanvin Sanjay Namboodiri, Rishi Bharat Junghare, Shahid Shafi Dar, Mohammad Zia Ur Rehman, Sai Kartheek Reddy Kasu | - This paper introduces D-HUMOR, a novel dataset comprising 4,379 Reddit memes annotated for dark humor detection, target categories, and intensity levels. - A Tri-stream Cross-Reasoning Network (TCRNet) is proposed, which fuses textual, visual, and reasoning features via pairwise attention mechanisms. - The TCRNet incorporates an iterative reasoning refinement via Role-Reversal Self-Loop to enhance the model's understanding of implicit cues in dark humor. - Experimental results demonstrate that the proposed method outperforms strong baselines across three tasks: dark humor detection, target identification, and intensity prediction. - The dataset, annotations, and code are publicly released to facilitate further research in multimodal humor understanding and content moderation. | ['Multimodal'] | [Link](https://github.com/Sai-Kartheek-Reddy/D-Humor-Dark-Humor-Understanding-via-Multimodal-Open-ended-Reasoning) | N/A |
