

## Papers for 2025-09-12

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for
  Speech-to-Speech LLMs](https://arxiv.org/abs/2509.09174) | Kaiqi Kou, Xiangnan Ma, Zhanchen Dai, Yuhao Du, Yuhao Zhang | - EchoX is a novel speech-to-speech large language model (SLLM) designed to mitigate the acoustic-semantic gap, a common limitation in existing SLLMs. - It leverages semantic representations and dynamically generates speech training targets via an "echo training" approach, integrating acoustic and semantic learning. - The model architecture comprises three stages: speech-to-text, text-to-codec, and echo training, utilizing a unit language for efficient speech token construction. - Experimental results show that EchoX achieves advanced performance on multiple knowledge-based question-answering benchmarks, surpassing existing methods with significantly less training data. - The project is available on Github, demonstrating the effectiveness and efficiency of the proposed method. | ['Audio', 'Text-to-Speech', 'Automatic Speech Recognition'] | [Link](https://github.com/FreedomIntelligence/EchoX) | N/A |
| [Can Understanding and Generation Truly Benefit Together -- or Just
  Coexist?](https://arxiv.org/abs/2509.09666) | Hui Han, Junyan Ye, Zongjian Li, Kaiqing Lin, Zhiyuan Yan | - This paper introduces UAE, a novel framework for unified multimodal learning that uses an auto-encoder approach to unify image understanding and generation.  - The model uses reconstruction fidelity as a unified training objective, enforcing coherent bidirectional information flow between encoding and decoding processes.  - The UAE architecture consists of an encoder (I2T) that compresses images into text and a decoder (T2I) that reconstructs images from text.   - Unified-GRPO, a reinforcement learning approach, is proposed to maximize a unified score and drive the co-evolution of the encoder and decoder.  - Experiments on Unified-Bench, a new benchmark tailored to assess the degree of unification of UMMs, show that UAE outperforms existing models, demonstrating compelling evidence for genuine multimodal unification and intelligence. | ['Multimodal', 'Image-to-Text', 'Text-to-Image', 'Image-to-Image', 'Text Generation', 'Reinforcement Learning'] | [Link](https://github.com/PKU-YuanGroup/UAE) | N/A |
| [Visual Programmability: A Guide for Code-as-Thought in Chart
  Understanding](https://arxiv.org/abs/2509.09286) | Ethan Chern, Jiadi Su, Fei Zhang, Yan Ma, Bohao Tang | - This paper introduces Visual Programmability, a novel concept that determines whether a chart question pair is best addressed using code-based reasoning or direct visual analysis. - An adaptive framework is proposed that uses reinforcement learning to dynamically select between code-based reasoning and direct visual analysis. - The model is trained using a dual-reward system that combines data accuracy and decision rewards, preventing mode collapse. - Experiments demonstrate superior performance across diverse benchmarks, showcasing the model's ability to dynamically select the most effective reasoning strategy. - Ablation studies verify the importance of the dual reward mechanism and visual programmability in achieving improved performance and generalization. | ['Multimodal', 'Visual Question Answering', 'Reinforcement Learning'] | [Link](https://github.com/Aphelios-Tang/Code-as-Thought) | N/A |
| [Gradient-Attention Guided Dual-Masking Synergetic Framework for Robust
  Text-based Person Retrieval](https://arxiv.org/abs/2509.09118) | Kaicheng Yang, Ziyong Feng, Xiang An, Yifan Zhang, Tianlu Zheng | - This paper introduces a novel large-scale dataset called WebPerson, containing 5 million high-quality person-centric image-text pairs, which addresses the data scarcity issue in text-based person retrieval. - A new model architecture named GA-DMS (Gradient-Attention Guided Dual-Masking Synergetic) is proposed, which enhances cross-modal alignment and fine-grained semantic representation learning through dual masking and masked token prediction. - The GA-DMS model outperforms state-of-the-art methods on multiple benchmarks for text-based person retrieval, achieving new state-of-the-art performance across multiple benchmarks. - The WebPerson dataset is constructed using a novel pipeline that leverages the in-context learning capabilities of large language models (LLMs) to filter and annotate web-sourced images, ensuring high quality and scale. - Extensive experiments demonstrate the effectiveness of the proposed GA-DMS framework and WebPerson dataset, showcasing superior performance in text-based person retrieval. | ['Multimodal'] | [Link](https://github.com/Multimodal-Representation-Learning-MRL/GA-DMS) | [Link](https://huggingface.co/datasets/Kaichengalex/WebPerson-5M) |
| [LoCoBench: A Benchmark for Long-Context Large Language Models in Complex
  Software Engineering](https://arxiv.org/abs/2509.09614) | Jianguo Zhang, Rithesh Murthy, Zhiwei Liu, Zuxin Liu, Jielin Qiu |  - LoCoBench is a novel benchmark designed for evaluating the long-context capabilities of large language models (LLMs) in complex software engineering tasks.  - It offers 8,000 evaluation scenarios spanning 10 programming languages and 36 domains with context lengths ranging from 10K to 1M tokens.  - LoCoBench introduces 8 new evaluation metrics for assessing long-context capabilities, including architectural understanding, cross-file refactoring, and multi-session development.  - Evaluation of state-of-the-art models reveals significant performance gaps, highlighting the challenges of long-context understanding in complex software engineering tasks.  - The benchmark is publicly available on GitHub, providing a valuable resource for the community. | ['Natural Language Processing', 'Text Generation'] | [Link](https://github.com/SalesforceAIResearch/LoCoBench) | N/A |
| [Modality Alignment with Multi-scale Bilateral Attention for Multimodal
  Recommendation](https://arxiv.org/abs/2509.09114) | Dong-Ho Lee, Chan-Yang Ju, renkelin | - The paper introduces MambaRec, a novel framework for multimodal recommendation that integrates local feature alignment and global distribution regularization via attention-guided learning. - MambaRec uses a Dilated Refinement Attention Module (DREAM) to align fine-grained semantic patterns between visual and textual modalities by employing multi-scale dilated convolutions with channel-wise and spatial attention. - The model uses Maximum Mean Discrepancy (MMD) and contrastive loss functions to constrain global modality alignment, enhancing semantic consistency and reducing mode-specific deviations. - Experiments on real-world e-commerce datasets demonstrate that MambaRec outperforms existing methods in fusion quality, generalization, and efficiency. - The code for MambaRec is publicly available on GitHub. | ['Multimodal'] | [Link](https://github.com/rkl71/MambaRec) | N/A |
| [Reasoning Introduces New Poisoning Attacks Yet Makes Them More
  Complicated](https://arxiv.org/abs/2509.05739) | Jamie Hayes, Harsh Chaudhari, Yiren Zhao, Ilia Shumailov, Hanna Foerster | This paper introduces a novel data poisoning attack against large language models (LLMs) that leverages the intermediate chain-of-thought (CoT) reasoning process.  The attack, termed "decomposed reasoning poison," modifies only the reasoning path, leaving the prompts and final answers unchanged, which makes it more stealthy than previous approaches.  However, the authors find that reliably activating these decomposed poisons is surprisingly difficult due to the model's self-correction capabilities and the inherent unfaithfulness of CoT generation.  The emergent robustness of LLMs to these attacks highlights the complexity introduced by reasoning capabilities. The study's results suggest that enhancing the model's reasoning robustness inadvertently improves its resistance to this type of poisoning attack. | ['Natural Language Processing'] | [Link](null) | [Link](null) |
