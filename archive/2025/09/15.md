

## Papers for 2025-09-15

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [IntrEx: A Dataset for Modeling Engagement in Educational Conversations](https://arxiv.org/abs/2509.06652) | Gabriele Pergola, Chiara Gambi, Mahathi Parvatham, XingweiT | - This paper introduces IntrEx, the first large-scale dataset annotated for interestingness and expected interestingness in teacher-student interactions, built upon the Teacher-Student Chatroom Corpus (TSCC). - IntrEx incorporates sequence-level annotations, enabling the study of engagement beyond isolated turns and capturing how interest evolves over dialogues. - The dataset employs a rigorous annotation process with over 100 second-language learners and utilizes a comparison-based rating approach, improving inter-annotator agreement. - Experiments show that LLMs fine-tuned on IntrEx outperform larger proprietary models in predicting human interestingness judgments. - Finally, the paper analyzes linguistic and cognitive factors such as concreteness, comprehensibility, and uptake to determine their influence on engagement in educational dialogues. | ['Natural Language Processing'] | N/A | [Link](https://huggingface.co/collections/XingweiT/intrex-68a8f2c97688157066860ae2) |
| [The Illusion of Diminishing Returns: Measuring Long Horizon Execution in
  LLMs](https://arxiv.org/abs/2509.09677) | Jonas Geiping, Steffen Staab, Shashwat Goel, arvindh75, viciousa3gis | - This paper introduces a novel methodology for evaluating the long-horizon execution capabilities of Large Language Models (LLMs). - The authors demonstrate that even with perfect single-step accuracy, LLMs struggle with long sequences of steps due to a self-conditioning effect; models make more mistakes when their context contains past errors.  - They find that increasing model size non-diminishingly improves the number of steps LLMs can execute but does not mitigate the self-conditioning effect. - Interestingly, incorporating "thinking" mechanisms, such as chain-of-thought prompting, significantly improves performance on long-horizon tasks.  - The study provides benchmarks of several leading LLMs on the number of steps they can execute in a single turn, highlighting the benefits of scaling model size and test-time compute. | ['Natural Language Processing'] | N/A | N/A |
| [HANRAG: Heuristic Accurate Noise-resistant Retrieval-Augmented
  Generation for Multi-hop Question Answering](https://arxiv.org/abs/2509.09713) | Zhehao Tan, Yihan Jiao, Yue Shen, Dan Yang, Duolin Sun | - This paper introduces HANRAG, a novel heuristic-based framework for multi-hop question answering that addresses challenges like excessive iterative retrieval and noise accumulation. - HANRAG uses a "Revelator" agent to route queries, decompose them into sub-queries, and filter noise from retrieved documents, improving adaptability and noise resistance. - The framework incorporates a noise-resistant one-step retrieval method called ANRAG. - Experimental results on various benchmarks demonstrate HANRAG's superior performance in single-hop and multi-hop question answering tasks compared to other leading methods. - The results show improvements in both effectiveness (EM, F1, Accuracy) and efficiency (number of retrieval steps) across multiple datasets. | ['Question Answering'] | N/A | N/A |
| [VStyle: A Benchmark for Voice Style Adaptation with Spoken Instructions](https://arxiv.org/abs/2509.09716) | Dong Zhang, Chen Wang, Yuxuan Xie, Mingyang Han, Jun Zhan | - This paper introduces VStyle, a new benchmark dataset for evaluating voice style adaptation (VSA) in spoken language models (SLMs). - VStyle is a bilingual (Chinese and English) benchmark covering four categories of speech generation tasks: acoustic attributes, natural language instructions, role play, and implicit empathy. - The paper also introduces a novel evaluation framework called LALM-as-a-Judge, which uses large audio language models to automatically assess the generated speech outputs. - Experiments on commercial and open-source SLMs demonstrate the challenges of controllable style adaptation and highlight the novelty of this task. - The VStyle dataset and evaluation toolkit are publicly available to facilitate future research in human-centered spoken interaction. | ['Audio', 'Text-to-Speech'] | N/A | N/A |
| [Virtual Agent Economies](https://arxiv.org/abs/2509.10147) | William A. Cunningham, Julian Jacobs, Joel Z. Leibo, Matija Franklin, Nenad Tomasev |  - This research paper proposes the concept of a 'sandbox economy' for analyzing the emergent economic layer where autonomous AI agents transact and coordinate.  - The framework characterizes this system along two dimensions: origins (emergent vs. intentional) and its separateness from the established human economy (permeable vs. impermeable). - The authors discuss design choices for safely steerable AI agent markets, including auction mechanisms for fair resource allocation, the design of AI mission economies, and socio-technical infrastructure for ensuring trust and accountability.  - They investigate the potential of market-based mechanisms for resolving conflicts among agents, using AI-driven auctions to coordinate resource allocation, and examine the use of AI mission economies. - The paper explores the potential for establishing steerable agent markets, arguing for proactive design to ensure that technological shift aligns with humanityâ€™s long-term collective flourishing. | ['Reinforcement Learning', 'Robotics', 'Natural Language Processing', 'Other'] | N/A | N/A |
| [QuantAgent: Price-Driven Multi-Agent LLMs for High-Frequency Trading](https://arxiv.org/abs/2509.09995) | Chenyu You, Siqi Sun, Aosong Feng, Xiang Zhang, Fei Xiong | - QuantAgent is a novel multi-agent large language model (LLM) framework specifically designed for high-frequency algorithmic trading. - The model decomposes trading into four specialized agents (Indicator, Pattern, Trend, and Risk), each equipped with domain-specific tools and structured reasoning capabilities to capture distinct aspects of market dynamics. - In zero-shot evaluations across various financial instruments, QuantAgent outperforms strong neural and rule-based baselines in terms of predictive accuracy and cumulative return. - The framework integrates classical technical analysis with prompt-structured LLM reasoning, facilitating modular and interpretable financial intelligence. - QuantAgent offers a browser-based interface that enables users to visualize market dynamics and interact with LLM-generated analyses, emphasizing transparency and interpretability. | ['Time Series Forecasting', 'Reinforcement Learning', 'Multimodal'] | [Link](https://github.com/Y-Research-SBU/QuantAgent) | N/A |
| [MCP-AgentBench: Evaluating Real-World Language Agent Performance with
  MCP-Mediated Tools](https://arxiv.org/abs/2509.09734) | Xiaorui Wang, Wentao Hong, Chiwei Zhu, Benfeng Xu, Zikang Guo | - MCP-AgentBench, a comprehensive benchmark for evaluating real-world language agent performance with MCP-mediated tools, is introduced. - The benchmark includes a robust MCP testbed with 33 operational servers and 188 distinct tools, along with 600 systematically designed queries across 6 categories. - MCP-Eval, a novel outcome-oriented evaluation methodology that prioritizes real-world task success, is presented. - Extensive empirical evaluations of leading language agents provide foundational insights into current capabilities and challenges. - The benchmark aims to equip the research community with a standardized and reliable framework to advance agents capable of fully leveraging MCP's benefits. | ['Natural Language Processing'] | N/A | N/A |
| [CMHG: A Dataset and Benchmark for Headline Generation of Minority
  Languages in China](https://arxiv.org/abs/2509.09990) | XU Han, Jianing Liu, Ziyin Zhang, Zeli Su, Guixian Xu | - This paper introduces CMHG, a new dataset for headline generation in three minority Chinese languages: Tibetan, Uyghur, and Mongolian. - CMHG contains 100,000 Tibetan entries and 50,000 entries each for Uyghur and Mongolian, specifically curated for headline generation. - A high-quality test set, annotated by native speakers, is included to serve as a benchmark for future research. - The dataset addresses the scarcity of resources for headline generation in minority languages, promoting research and development in this area. - The paper contributes to advancing natural language processing research on underrepresented languages. | ['Text Generation'] | N/A | [Link](https://huggingface.co/KEVVVV/CMHG) |
