

## Papers for 2025-09-17

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for
  Open-Ended Deep Research](https://arxiv.org/abs/2509.13312) | Houquan Zhou, Shen Huang, Bo Zhang, Xin Guan, Zijian Li | WebWeaver is a novel dual-agent framework for open-ended deep research (OEDR) that uses a dynamic research cycle to iteratively interleave evidence acquisition with outline optimization.  The planner dynamically refines the outline using human-like reasoning, and the writer composes the report section-by-section, mitigating long-context issues.  WebWeaver outperforms existing methods on major OEDR benchmarks, including DeepResearch Bench, DeepConsult, and DeepResearchGym.  The model's architecture consists of a planner agent and a writer agent that work together to generate comprehensive, source-grounded reports. A high-quality SFT dataset was created to improve the smaller models' performance. | ['Natural Language Processing', 'Text Generation', 'Text2Text Generation', 'Question Answering', 'Summarization'] | [Link](https://github.com/Alibaba-NLP/DeepResearch) | [Link](https://tongyi-agent.github.io/blog) |
| [Scaling Agents via Continual Pre-training](https://arxiv.org/abs/2509.13310) | Chenxi Wang, Zhuo Chen, Guangyu Li, Zhen Zhang, Liangcai Su | AgentFounder-30B is a novel deep research agent model that leverages Agentic Continual Pre-training (Agentic CPT).  Agentic CPT addresses the limitations of post-training approaches by incorporating agentic behaviors into the model's foundation.  AgentFounder-30B achieves state-of-the-art performance on 10 benchmark tasks, significantly outperforming existing open-source models and demonstrating comparable results to closed-source models.  The model's strong tool-use abilities and impressive scaling properties highlight the effectiveness of Agentic CPT. | ['Natural Language Processing'] | [Link](https://github.com/Alibaba-NLP/DeepResearch) | [Link](https://huggingface.co/Qwen/Qwen3-30B-A3B-Base) |
| [WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon
  Agents](https://arxiv.org/abs/2509.13309) | Wenbiao Yin, Donglei Yu, Xuanzhong Chen, Guoxin Chen, Zile Qiao | - This paper introduces WebResearcher, a novel framework for building AI agents capable of autonomous deep research. - WebResearcher uses two key components: IterResearch, an iterative deep-research paradigm that reformulates deep research as a Markov Decision Process, and WebFrontier, a scalable data synthesis engine that generates high-quality training data. - IterResearch overcomes the context limitations of existing methods by periodically consolidating findings into reports, maintaining focused workspaces, and enabling sustained reasoning. - WebFrontier generates training data through tool-augmented complexity escalation, bridging the gap between passive knowledge recall and active knowledge construction. - Experiments demonstrate WebResearcher's state-of-the-art performance on several challenging benchmarks, exceeding existing methods including open-source and proprietary systems. | ['Question Answering'] | [Link](https://github.com/Alibaba-NLP/DeepResearch) | N/A |
| [ReSum: Unlocking Long-Horizon Search Intelligence via Context
  Summarization](https://arxiv.org/abs/2509.13313) | Litu Ou, Liwen Zhang, Yida Zhao, Kuan Li, Xixi Wu |  - This paper introduces ReSum, a novel paradigm for long-horizon web search that uses periodic context summarization to overcome context window limitations of large language models.  - ReSum converts growing interaction histories into compact reasoning states, maintaining awareness of prior discoveries while bypassing context constraints.  - ReSum-GRPO, integrating GRPO with segmented trajectory training and advantage broadcasting, is proposed to familiarize agents with summary-conditioned reasoning.  - Experiments on web agents of varying scales across three benchmarks demonstrate that ReSum delivers an average absolute improvement of 4.5% over ReAct, with further gains of up to 8.2% following ReSum-GRPO training.  - ReSumTool-30B, a specialized summarization model, is fine-tuned to excel at extracting key clues and evidence from lengthy interactions for web search tasks. | ['Reinforcement Learning', 'Question Answering', 'Summarization'] | [Link](https://github.com/Alibaba-NLP/DeepResearch) | [Link](https://tongyi-agent.github.io/blog) |
| [Hunyuan3D Studio: End-to-End AI Pipeline for Game-Ready 3D Asset
  Generation](https://arxiv.org/abs/2509.12815) | Lixin Xu, Shuhui Yang, Xinhai Liu, Yang Li, Biwen Lei | - This paper introduces Hunyuan3D Studio, an end-to-end AI pipeline for generating game-ready 3D assets from images or text. - The pipeline consists of seven core modules: Controllable Image Generation, High-Fidelity Geometry Generation, Part-level 3D Generation, Polygon Generation, Semantic UV Unwrapping, Texture Synthesis and Editing, and Animation. - Hunyuan3D Studio integrates several advanced neural modules, including ShapeVAE and DiT for geometry generation, P3-SAM and X-Part for part-level generation and decomposition, and an auto-regressive model for polygon generation. - The results demonstrate that the assets generated by Hunyuan3D Studio meet the technical requirements of game engines and exhibit high visual fidelity. - The modular design of the pipeline allows for seamless automation, artistic control, and efficient integration with game engines. | ['Image-to-3D', 'Text-to-3D', 'Multimodal'] | N/A | N/A |
| [3D Aware Region Prompted Vision Language Model](https://arxiv.org/abs/2509.13317) | Xiaolong Li, Zhijian Liu, Yukang Chen, Yang Fu, An-Chieh Cheng | - This paper introduces SR-3D, a novel vision-language model that unifies 2D and 3D representations to enhance spatial reasoning capabilities. - SR-3D employs a dynamic tiling-based region extractor and integrates 3D positional embeddings to allow flexible region prompting and robust spatial reasoning across frames. - The model achieves state-of-the-art performance on various benchmarks, including general 2D and 3D vision-language tasks and specialized 3D spatial benchmarks, demonstrating its effectiveness in both image and video scenarios. - SR-3D shows strong zero-shot generalization capabilities, accurately inferring spatial relationships and metric measurements in videos without 3D inputs or annotations. - The model's unified architecture allows for seamless integration of spatial reasoning at different levels, leveraging both single-view and multi-view inputs. | ['Multimodal', 'Visual Question Answering', 'Video-Text-to-Text', 'Image-to-3D', 'Image Feature Extraction', 'Question Answering', 'Zero-Shot Classification'] | N/A | N/A |
| [EconProver: Towards More Economical Test-Time Scaling for Automated
  Theorem Proving](https://arxiv.org/abs/2509.12603) | Shansan Gong, Jiahao Xu, Zhenwen Liang, Linfeng Song, Mukai Li | - This paper introduces EconProver, a novel framework for more economical test-time scaling in automated theorem proving (ATP). - EconProver integrates two complementary methods: dynamic Chain-of-Thought (CoT) switching and diverse parallel-scaled reinforcement learning (RL), to reduce token usage and enhance efficiency. - The dynamic CoT switching mechanism dynamically chooses to apply extended reasoning only when necessary for complex problems, thus avoiding unnecessary token consumption. - The diverse parallel-scaled RL utilizes specialized reasoning heads trained on difficulty-partitioned data to improve solution diversity and parallel scaling efficiency. - Experiments demonstrate that EconProver achieves comparable performance to SOTA methods while reducing token consumption to 12%, highlighting significant efficiency gains without sacrificing accuracy. | ['Reinforcement Learning', 'Natural Language Processing'] | N/A | N/A |
| [Multimodal Reasoning for Science: Technical Report and 1st Place
  Solution to the ICML 2025 SeePhys Challenge](https://arxiv.org/abs/2509.06079) | Wentao Zhang, Junbo Niu, Bohan Zeng, Ruitao Wu, Hao Liang | - The paper introduces a caption-assisted reasoning framework that effectively bridges visual and textual modalities for multimodal reasoning in scientific scenarios. - This framework achieved first place in the ICML 2025 AI for Math Workshop & Challenge 2: SeePhys, outperforming state-of-the-art methods. - The approach addresses key limitations of current multimodal reasoning methods, such as unstable integration between visual perception and logical inference, restricted generalization, and dependence on costly fine-tuning. - The framework's effectiveness is validated through generalization on the MathVerse benchmark for geometric reasoning, demonstrating its versatility. - The code for this method is publicly available on Github. | ['Multimodal', 'Visual Question Answering'] | [Link](https://github.com/OpenDCAI/SciReasoner) | N/A |
| [Optimal Brain Restoration for Joint Quantization and Sparsification of
  LLMs](https://arxiv.org/abs/2509.11177) | Luca Benini, Yawei Li, Hang Guo | - This paper introduces Optimal Brain Restoration (OBR), a novel training-free framework for jointly quantizing and sparsifying large language models (LLMs). - OBR addresses the conflicting requirements of these compression techniques by using error compensation between pruning and quantization, minimizing performance degradation. - The framework uses a second-order Hessian objective and surrogate approximation to arrive at a closed-form solution for optimal weight adjustments. - Experiments demonstrate that OBR enables aggressive W4A4KV4 quantization with 50% sparsity, resulting in up to 4.72x speedup and 6.4x memory reduction compared to the FP16-dense baseline. - The method is applied to Llama2, Llama3, and Qwen2.5 LLMs, showing consistent improvements across various tasks and achieving perplexity comparable to full-precision models. | ['Natural Language Processing'] | [Link](https://github.com/csguoh/OBR) | [Link](https://huggingface.co/HangGuo/OBR) |
