

## Papers for 2025-09-18

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [SAIL-VL2 Technical Report](https://arxiv.org/abs/2509.14033) | Zijian Kang, Yue Liao, Fangxun Shu, Yongjie Ye, Weijie Yin |  - This paper introduces SAIL-VL2, a comprehensive multimodal vision-language foundation model (LVM).  - SAIL-VL2 improves upon its predecessor, SAIL-VL, by incorporating three key innovations: large-scale data curation, a progressive training framework, and architectural advances using sparse Mixture-of-Experts (MoE) designs.  - SAIL-VL2 achieves state-of-the-art performance across diverse image and video benchmarks at the 2B and 8B parameter scales, demonstrating strong capabilities in fine-grained perception and complex reasoning.  - The model's effectiveness is validated through extensive experiments across 106 datasets and on challenging reasoning benchmarks such as MMMU and Math-Vista.  - On the OpenCompass leaderboard, SAIL-VL2-2B ranks first among officially released open-source models under the 4B parameter scale. | ['Multimodal'] | [Link](https://github.com/BytedanceDouyinContent) | [Link](https://huggingface.co/BytedanceDouyinContent) |
| [Scrub It Out! Erasing Sensitive Memorization in Code Language Models via
  Machine Unlearning](https://arxiv.org/abs/2509.13755) | Zhou Yang, Di Wang, Zhikun Zhang, Yao Wan, Zhaoyang Chu | - This paper introduces CODEERASER, a novel machine unlearning technique designed to selectively erase sensitive information memorized by Code Language Models (CLMs) without requiring full model retraining. - CODEERASER achieves this by utilizing a selective gradient ascent-based approach, targeting only sensitive segments within code while preserving the functionality of the surrounding code. - Experiments on three families of CLMs (CodeParrot, CodeGen-Mono, and Qwen2.5-Coder) demonstrate that CODEERASER effectively reduces memorization of sensitive data by up to 93.89% while maintaining high model utility. - The study also includes the creation of a new dataset containing 50,000 sensitive memorized samples, which serves as a benchmark for evaluating sensitive memorization erasure techniques. - The results suggest CODEERASER outperforms existing methods like vanilla and constraint-based unlearning in terms of both effectiveness and efficiency. | ['Natural Language Processing', 'Text Generation', 'Text2Text Generation'] | [Link](https://github.com/CGCL-codes/naturalcc/tree/main/examples/code-unlearning) | N/A |
| [THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical
  Reasoning](https://arxiv.org/abs/2509.13761) | Yicheng Pan, Jiefeng Ma, Pengfei Hu, Zhenrong Zhang, Qikai Chang | - This paper introduces THOR, a novel framework that enhances the mathematical reasoning capabilities of LLMs by integrating external tools. - THOR leverages a hierarchical reinforcement learning strategy, optimizing both at the trajectory and step levels for improved efficiency. - A key contribution is TIRGen, a multi-agent pipeline for constructing high-quality tool-integrated reasoning datasets. - THOR incorporates a self-correction mechanism that uses immediate feedback from tools to dynamically rectify erroneous reasoning steps during inference. - The results demonstrate that THOR achieves state-of-the-art performance on various mathematical benchmarks, generalizing effectively across reasoning models. | ['Reinforcement Learning', 'Natural Language Processing', 'Question Answering'] | [Link](https://github.com/JingMog/THOR) | N/A |
| [Improving Context Fidelity via Native Retrieval-Augmented Reasoning](https://arxiv.org/abs/2509.13683) | Xiangru Tang, Shiqi Li, Xinyu Wang, Jinlin Wang, Suyuchen Wang | - This paper introduces CARE, a novel native retrieval-augmented reasoning framework that enhances context fidelity in LLMs. - CARE teaches LLMs to integrate in-context evidence into their reasoning process using the model's own retrieval capabilities, eliminating the need for expensive supervised fine-tuning or external retrieval mechanisms. - The framework consists of two phases: supervised fine-tuning (SFT) to establish the evidence integration pattern and reinforcement learning (RL) to refine the self-retrieval mechanism. - Extensive experiments on multiple benchmarks demonstrate that CARE significantly outperforms existing methods, including supervised fine-tuning, traditional RAG methods, and external retrieval solutions. - The proposed approach is fundamentally different from existing methods as it leverages the LLM's inherent language understanding capabilities for in-context retrieval, making LLMs more accurate and efficient. | ['Question Answering'] | N/A | N/A |
| [SteeringControl: Holistic Evaluation of Alignment Steering in LLMs](https://arxiv.org/abs/2509.13450) | Zhun Wang, Nathan W. Henry, David Park, Nicholas Crispino, Vincent Siu |  - This paper introduces STEERINGCONTROL, a benchmark for evaluating representation steering methods in LLMs.    - The benchmark focuses on core alignment objectives (bias, harmful generation, and hallucination) and their effects on secondary behaviors (sycophancy and commonsense morality).  - STEERINGCONTROL includes a dataset of safety-relevant primary and secondary behaviors and a modular steering framework to evaluate five popular steering methods.  - Experiments on Qwen-2.5-7B and Llama-3.1-8B show that strong steering performance depends on method, model, and behavior, and entanglement can be severe.   - The code for STEERINGCONTROL is publicly available. | ['Natural Language Processing', 'Text Generation'] | [Link](https://github.com/wang-research-lab/SteeringControl.git) | N/A |
| [MARS2 2025 Challenge on Multimodal Reasoning: Datasets, Methods,
  Results, Discussion, and Outlook](https://arxiv.org/abs/2509.14142) | Bowen Zhou, Yaxiong Chen, Jiajun Zhang, Shengwu Xiong, Peng Xu | This paper introduces the MARS2 2025 challenge, focusing on multimodal reasoning using large language models (LLMs).  The challenge features two new datasets, Lens and AdsQA, designed for general and domain-specific reasoning tasks, respectively.  Three competition tracks (Visual Grounding in Real-world Scenarios, Visual Question Answering with Spatial Awareness, and Visual Reasoning in Creative Advertisement Videos) were introduced to assess the models' performance.  The paper presents the results from 76 teams and discusses the strengths and weaknesses of the submitted methods, highlighting the challenges in multimodal reasoning and areas for future research. | ['Multimodal'] | [Link](https://github.com/mars2workshop/) | N/A |
