

## Papers for 2025-09-25

| Title | Authors | Summary | Classification | GitHub URLs | HuggingFace URLs |
|-------|---------|---------|----------------|-------------|-----------------|
| [SIM-CoT: Supervised Implicit Chain-of-Thought](https://arxiv.org/abs/2509.20317) | Yuhang Cao, Xiaoyi Dong, Yuhang Zang, LiuXR, Wiselnn | - This paper introduces SIM-CoT, a novel training module designed to enhance implicit Chain-of-Thought (CoT) reasoning in Large Language Models (LLMs). - SIM-CoT addresses the latent instability issue in existing implicit CoT methods by introducing step-level supervision, which stabilizes the training process and enriches the latent reasoning space. - The method employs an auxiliary decoder during training to align each implicit token with its corresponding explicit reasoning step, which is removed during inference to maintain efficiency. - Experimental results demonstrate that SIM-CoT significantly improves both the in-domain accuracy and out-of-domain stability of various implicit CoT methods, outperforming existing baselines on various benchmarks. - SIM-CoT exhibits strong scalability, surpassing the explicit CoT baseline on certain models while maintaining greater token efficiency. | ['Question Answering'] | [Link](https://github.com/InternLM/SIM-COT) | N/A |
| [LLMs4All: A Review on Large Language Models for Research and
  Applications in Academic Disciplines](https://arxiv.org/abs/2509.19580) | Yanfang, lalor, Sweson, ZehongWang, mtybilly | This paper reviews the applications of large language models (LLMs) across multiple academic disciplines, including arts, letters, and law; economics and business; and science and engineering.  It discusses the integration of LLMs into existing research workflows and practices, highlighting key observations and insights. The paper also addresses the limitations of LLMs and the challenges for future research.  The authors find that while LLMs show promise across various disciplines, there are still challenges regarding robustness, accuracy, and ethical considerations.  Overall, the review provides useful guidance for researchers and practitioners who are interested in exploiting LLMs to advance their work in diverse real-world applications. | ['Natural Language Processing'] | N/A | N/A |
| [EditVerse: Unifying Image and Video Editing and Generation with
  In-Context Learning](https://arxiv.org/abs/2509.20360) | Tianyu Wang, sooyek, Shaldon, CaiYuanhao, juxuan27 | - The paper introduces EditVerse, a unified framework for image and video generation and editing, leveraging a transformer architecture with self-attention for robust in-context learning. - EditVerse represents all modalities (text, image, video) as a unified token sequence, enabling cross-modal knowledge transfer and flexible handling of arbitrary resolutions and durations. - To address the scarcity of video editing data, the authors design a scalable data pipeline, curating 232K video editing samples and combining them with large-scale image and video datasets for training. - EditVerse achieves state-of-the-art performance on the introduced benchmark, EditVerseBench, and surpasses existing open-source and commercial models. - The model demonstrates emergent editing and generation abilities across modalities, showcasing its ability to perform tasks beyond those explicitly seen during training. | ['Multimodal', 'Image-to-Video', 'Text-to-Video', 'Video-Text-to-Text', 'Image-to-Image', 'Text-to-Image'] | N/A | N/A |
| [EmbeddingGemma: Powerful and Lightweight Text Representations](https://arxiv.org/abs/2509.20354) | Marksherwood, osanseviero, ssmoot, SindhuRaghuram97, hschechter | - The paper introduces EmbeddingGemma, a lightweight text embedding model based on the Gemma 3 language model family. - EmbeddingGemma uses an encoder-decoder architecture and incorporates several techniques, including encoder-decoder initialization, geometric embedding distillation, a spread-out regularizer, and model souping (merging checkpoints from varied, optimized mixtures), to improve model robustness and expressiveness. - Evaluated on the Massive Text Embedding Benchmark (MTEB), EmbeddingGemma (300M parameters) achieves state-of-the-art results, outperforming existing models with fewer than 500M parameters, and providing performance comparable to models double its size. - The model demonstrates exceptional performance even when model weights are quantized or embedding outputs are truncated, making it well-suited for low-latency, high-throughput use cases. - The authors release EmbeddingGemma to the research community. | ['Natural Language Processing', 'Sentence Similarity', 'Feature Extraction'] | N/A | [Link](https://ai.google.dev/gemma/docs/embeddinggemma) |
| [Logics-Parsing Technical Report](https://arxiv.org/abs/2509.19760) | Fan Yang, Shuzhao Li, Xiangyang Chen, ZjuCv, xiuwenzhu | - This paper introduces Logics-Parsing, a novel end-to-end large vision-language model (LVLM) for layout-aware document parsing that incorporates reinforcement learning. - The model architecture consists of a two-stage training process: supervised fine-tuning (SFT) followed by layout-centric reinforcement learning (LC-RL) using a multi-component reward function that evaluates text accuracy, layout precision, and logical reading order. - The LogicsParsingBench, a new benchmark dataset with 1078 pages, is introduced to rigorously evaluate the model's performance, focusing on complex layouts and diverse document types. - Experiments on LogicsParsingBench demonstrate that Logics-Parsing achieves state-of-the-art (SOTA) performance across various metrics compared to existing methods, particularly excelling in complex document scenarios with intricate layouts and diverse content types. - The approach showcases the effectiveness of combining SFT and RL for layout-aware document parsing, leading to improved accuracy and efficiency. | ['Multimodal', 'Image-to-Text', 'Document Question Answering', 'Reinforcement Learning'] | [Link](https://github.com/alibaba/Logics-Parsing) | N/A |
| [Lavida-O: Elastic Large Masked Diffusion Models for Unified Multimodal
  Understanding and Generation](https://arxiv.org/abs/2509.19244) | Zhe Lin, xternalz, kl3141, JoshuaGu, jacklishufan |  - Lavida-O is a novel unified Masked Diffusion Model (MDM) for multimodal understanding and generation, incorporating an Elastic Mixture-of-Transformers (Elastic-MoT) architecture. - Unlike existing multimodal MDMs, Lavida-O supports high-resolution image generation (1024px) and various tasks including image editing and object grounding. - Lavida-O incorporates planning and iterative self-reflection in image generation and editing tasks, improving the quality and efficiency of generation. - Extensive experiments demonstrate that Lavida-O achieves state-of-the-art performance on multiple benchmarks (RefCOCO, GenEval, and ImgEdit), outperforming existing autoregressive and continuous diffusion models. - Lavida-O introduces several efficient training and inference techniques, including token compression, universal text conditioning, and stratified sampling, for efficient scaling and high-quality generation. | ['Multimodal', 'Text-to-Image', 'Image-to-Text', 'Image-to-Image', 'Image-to-Video', 'Text-to-Video'] | N/A | N/A |
| [On the Use of Agentic Coding: An Empirical Study of Pull Requests on
  GitHub](https://arxiv.org/abs/2509.14745) | Hajimu Iida, Brittany Reid, Yutaro Kashiwa, Miku Watanabe, hao-li | - This paper presents an empirical study on the use of agentic coding tools for generating pull requests on GitHub, focusing on Claude Code. - The study analyzes 567 pull requests generated by Claude Code across 157 open-source projects to investigate the acceptance rate, revision frequency, and reasons for rejection. - Results show that 83.8% of agentic pull requests are accepted, with 54.9% merged without modifications;  when revisions are required, they primarily address bug fixes, documentation updates, and code style improvements. - The findings suggest that agentic coding is largely acceptable, but human oversight is still essential for maintaining code quality and project standards. - The authors propose future research directions focusing on quantifying the socio-technical costs of building trust in AI-generated code and developing PR-centric benchmarks. | ['Natural Language Processing', 'Text Classification'] | [Link](https://github.com/mmikuu/OnTheUseOfAgenticCoding) | [Link](https://huggingface.co/google/flan-t5-xxl) |
