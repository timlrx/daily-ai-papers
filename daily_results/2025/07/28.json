[
    {
        "title": "The Geometry of LLM Quantization: GPTQ as Babai's Nearest Plane\n  Algorithm",
        "authors": "Dan Alistarh, Torsten Hoefler, softmax",
        "link": "https://arxiv.org/abs/2507.18553",
        "github_repo": null,
        "summary": "- This paper presents a novel geometric interpretation of the GPTQ algorithm for post-training quantization of large language models.\n- It establishes a mathematical equivalence between GPTQ and Babai's nearest plane algorithm for the closest vector problem (CVP) in lattice theory.\n- This equivalence provides a geometric interpretation of GPTQ's error propagation step and allows for the inheritance of Babai's algorithm's error bound under specific conditions.\n- The findings are used to develop a new quantization order heuristic, the \"min-pivot\" order, which aims to improve the accuracy of the algorithm.\n- The paper's theoretical contributions provide a firmer foundation for the understanding and improvement of post-training quantization methods for large language models.",
        "classification": [
            "Natural Language Processing"
        ],
        "github_urls": [],
        "huggingface_urls": [],
        "date": "2025-07-28"
    },
    {
        "title": "Deep Researcher with Test-Time Diffusion",
        "authors": "Guan Sun, Lesly Miculicich, Zoey CuiZhu, Yanfei Chen, Rujun Han",
        "link": "https://arxiv.org/abs/2507.16075",
        "github_repo": null,
        "summary": "- This paper introduces Test-Time Diffusion Deep Researcher (TTD-DR), a novel framework that conceptualizes research report generation as a diffusion process, inspired by the iterative nature of human research.\n- TTD-DR enhances report quality through two mechanisms: (1) Report-Level Refinement via Denoising with Retrieval, and (2) Component-wise Optimization via Self-Evolution.\n- The framework significantly outperforms existing deep research agents on various benchmarks requiring intensive search and multi-hop reasoning, as evidenced by the superior results achieved in Table 1 (Win Rate, Correctness).\n- The model's performance is further enhanced by a Self-Evolutionary Algorithm, which is implemented in parallel, with several stages including Initialization, Feedback, Revision, and Crossover.\n- Despite its notable achievements, the current work primarily focuses on search tools and may not be applicable to other scenarios due to the lack of integration with browsing or coding tools. ",
        "classification": [
            "Natural Language Processing",
            "Text Generation",
            "Text2Text Generation",
            "Question Answering"
        ],
        "github_urls": [],
        "huggingface_urls": [],
        "date": "2025-07-28"
    },
    {
        "title": "Specification Self-Correction: Mitigating In-Context Reward Hacking\n  Through Test-Time Refinement",
        "authors": "vicgalle",
        "link": "https://arxiv.org/abs/2507.18742",
        "github_repo": "https://github.com/vicgalle/specification-self-correction",
        "summary": "- This paper introduces Specification Self-Correction (SSC), a novel test-time framework that allows language models to identify and correct flaws in their own guiding specifications.\n- SSC employs a multi-step inference process: initial response generation, self-critique, specification revision, and final response generation.\n- Experiments across creative writing and agentic coding tasks demonstrate that SSC reduces the vulnerability to reward hacking by over 90%.\n- The method requires no weight modification and operates at inference time, leading to more robustly aligned model behavior.\n- The authors empirically demonstrate the effectiveness of SSC across diverse domains and language models.",
        "classification": [
            "Natural Language Processing",
            "Text Generation"
        ],
        "github_urls": [
            "https://github.com/vicgalle/specification-self-correction"
        ],
        "huggingface_urls": [],
        "date": "2025-07-28"
    },
    {
        "title": "PRIX: Learning to Plan from Raw Pixels for End-to-End Autonomous Driving",
        "authors": "Patric Jensfelt, Yixi Cai, Lianhang Liu, maciejw94",
        "link": "https://arxiv.org/abs/2507.17596",
        "github_repo": null,
        "summary": "- This paper introduces PRIX, a novel camera-only end-to-end autonomous driving architecture that operates without explicit BEV representation or LiDAR.- PRIX uses a visual feature extractor and generative planning head to predict trajectories directly from raw pixel inputs.- The model incorporates a Context-aware Recalibration Transformer (CaRT) to enhance visual features for robust planning.- PRIX achieves state-of-the-art performance on NavSim and nuScenes benchmarks, outperforming or matching larger, multimodal diffusion planners while being significantly more efficient.- The efficiency gains are attributed to the camera-only design and avoidance of computationally intensive BEV representations, allowing for real-world deployment.",
        "classification": [
            "Robotics"
        ],
        "github_urls": [
            "https://maxiuw.github.io/prix"
        ],
        "huggingface_urls": [],
        "date": "2025-07-28"
    },
    {
        "title": "Chat with AI: The Surprising Turn of Real-time Video Communication from\n  Human to AI",
        "authors": "Xinggong Zhang, Liming Liu, Zhiyuan Ren, keyonN",
        "link": "https://arxiv.org/abs/2507.10510",
        "github_repo": null,
        "summary": "- This paper introduces Artic, a novel framework for AI-oriented real-time communication (RTC) that addresses the latency challenges of current AI Video Chat systems.\n- Artic incorporates Context-Aware Video Streaming, which allocates bitrate based on video regions' importance in the current chat context to reduce bitrate usage while maintaining MLLM accuracy.\n- Loss-Resilient Adaptive Frame Rate is also proposed, utilizing redundant frames to substitute lost frames, thereby enhancing loss resilience and lowering latency.\n- The first benchmark for AI Video Chat, Degraded Video Understanding Benchmark (DeViBench), is introduced for measuring the impact of video streaming quality on MLLM accuracy.\n- Through experiments, Artic shows significant improvement in latency reduction and efficiency, allowing for AI Video Chat that is more responsive and realistic.",
        "classification": [
            "Video-Text-to-Text"
        ],
        "github_urls": [],
        "huggingface_urls": [],
        "date": "2025-07-28"
    }
]